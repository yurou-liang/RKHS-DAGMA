{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CASTLE_BACKEND'] = 'pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 18:51:20,829 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\__init__.py[line:36] - INFO: You are using ``pytorch`` as the backend.\n"
     ]
    }
   ],
   "source": [
    "from castle.common import GraphDAG\n",
    "from castle.metrics import MetricsDAG\n",
    "from castle.datasets import DAG, IIDSimulation\n",
    "from castle.algorithms import Notears, NotearsNonlinear\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning causality of self generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "x = np.random.normal(0,1, 800)\n",
    "\n",
    "np.random.seed(24)\n",
    "l = np.random.normal(0,1, 800) \n",
    "y = [0.5*a + b for a, b in zip(x, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = list(zip(x,y))\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 19:06:11,439 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:195] - INFO: [start]: n=800, d=2, iter_=100, h_=1e-08, rho_=1e+16\n",
      "2023-11-16 19:06:11,455 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 0] h=6.591e-03, loss=1.120, rho=1.0e+00\n",
      "2023-11-16 19:06:11,460 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=6.574e-03, loss=0.991, rho=1.0e+00\n",
      "2023-11-16 19:06:11,465 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=6.422e-03, loss=0.992, rho=1.0e+01\n",
      "2023-11-16 19:06:11,472 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=5.412e-03, loss=0.994, rho=1.0e+02\n",
      "2023-11-16 19:06:11,481 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=3.041e-03, loss=1.013, rho=1.0e+03\n",
      "2023-11-16 19:06:11,490 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=1.194e-03, loss=1.209, rho=1.0e+04\n",
      "2023-11-16 19:06:11,507 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 2] h=7.582e-04, loss=1.028, rho=1.0e+04\n",
      "2023-11-16 19:06:11,523 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 2] h=2.838e-04, loss=1.092, rho=1.0e+05\n",
      "2023-11-16 19:06:11,525 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 3] h=1.567e-04, loss=1.042, rho=1.0e+05\n",
      "2023-11-16 19:06:11,543 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 3] h=5.563e-05, loss=1.078, rho=1.0e+06\n",
      "2023-11-16 19:06:11,558 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 4] h=3.175e-05, loss=1.047, rho=1.0e+06\n",
      "2023-11-16 19:06:11,575 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 4] h=1.163e-05, loss=1.061, rho=1.0e+07\n",
      "2023-11-16 19:06:11,575 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 5] h=6.727e-06, loss=1.049, rho=1.0e+07\n",
      "2023-11-16 19:06:11,594 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 5] h=2.486e-06, loss=1.055, rho=1.0e+08\n",
      "2023-11-16 19:06:11,608 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 6] h=1.443e-06, loss=1.050, rho=1.0e+08\n",
      "2023-11-16 19:06:11,626 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 6] h=5.346e-07, loss=1.053, rho=1.0e+09\n",
      "2023-11-16 19:06:11,645 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 7] h=3.107e-07, loss=1.050, rho=1.0e+09\n",
      "2023-11-16 19:06:11,657 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 7] h=1.151e-07, loss=1.052, rho=1.0e+10\n",
      "2023-11-16 19:06:11,657 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 8] h=6.701e-08, loss=1.050, rho=1.0e+10\n",
      "2023-11-16 19:06:11,676 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 8] h=2.482e-08, loss=1.051, rho=1.0e+11\n",
      "2023-11-16 19:06:11,691 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 9] h=1.442e-08, loss=1.051, rho=1.0e+11\n",
      "2023-11-16 19:06:11,709 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 9] h=5.343e-09, loss=1.051, rho=1.0e+12\n",
      "2023-11-16 19:06:11,709 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:222] - INFO: FINISHED\n"
     ]
    }
   ],
   "source": [
    "nt = Notears()\n",
    "nt.learn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[0, 1],\n",
       "        [0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt.causal_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning causality of package generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 19:33:29,517 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\datasets\\simulator.py[line:270] - INFO: Finished synthetic dataset\n"
     ]
    }
   ],
   "source": [
    "weighted_random_dag = DAG.erdos_renyi(n_nodes=2, n_edges=1, weight_range=(0.5, 2.0), seed = 1)\n",
    "dataset = IIDSimulation(W=weighted_random_dag, n=2000, method='linear', sem_type='gauss')\n",
    "true_dag, X = dataset.B, dataset.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 19:33:30,201 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:195] - INFO: [start]: n=2000, d=2, iter_=100, h_=1e-08, rho_=1e+16\n",
      "2023-11-13 19:33:30,215 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 0] h=6.395e-02, loss=1.416, rho=1.0e+00\n",
      "2023-11-13 19:33:30,228 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=6.011e-02, loss=0.898, rho=1.0e+00\n",
      "2023-11-13 19:33:30,242 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=4.383e-02, loss=0.916, rho=1.0e+01\n",
      "2023-11-13 19:33:30,257 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=2.017e-02, loss=1.100, rho=1.0e+02\n",
      "2023-11-13 19:33:30,285 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=6.395e-03, loss=2.941, rho=1.0e+03\n",
      "2023-11-13 19:33:30,298 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 2] h=3.435e-03, loss=1.035, rho=1.0e+03\n",
      "2023-11-13 19:33:30,318 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 2] h=1.192e-03, loss=1.219, rho=1.0e+04\n",
      "2023-11-13 19:33:30,338 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 3] h=6.717e-04, loss=1.055, rho=1.0e+04\n",
      "2023-11-13 19:33:30,362 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 3] h=2.437e-04, loss=1.119, rho=1.0e+05\n",
      "2023-11-13 19:33:30,378 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 4] h=1.404e-04, loss=1.064, rho=1.0e+05\n",
      "2023-11-13 19:33:30,407 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 4] h=5.172e-05, loss=1.091, rho=1.0e+06\n",
      "2023-11-13 19:33:30,433 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 5] h=3.000e-05, loss=1.068, rho=1.0e+06\n",
      "2023-11-13 19:33:30,463 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 5] h=1.110e-05, loss=1.080, rho=1.0e+07\n",
      "2023-11-13 19:33:30,486 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 6] h=6.449e-06, loss=1.070, rho=1.0e+07\n",
      "2023-11-13 19:33:30,520 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 6] h=2.389e-06, loss=1.076, rho=1.0e+08\n",
      "2023-11-13 19:33:30,530 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 7] h=1.390e-06, loss=1.071, rho=1.0e+08\n",
      "2023-11-13 19:33:30,553 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 7] h=5.146e-07, loss=1.074, rho=1.0e+09\n",
      "2023-11-13 19:33:30,570 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 8] h=2.993e-07, loss=1.072, rho=1.0e+09\n",
      "2023-11-13 19:33:30,591 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 8] h=1.108e-07, loss=1.073, rho=1.0e+10\n",
      "2023-11-13 19:33:30,607 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 9] h=6.448e-08, loss=1.072, rho=1.0e+10\n",
      "2023-11-13 19:33:30,630 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 9] h=2.391e-08, loss=1.072, rho=1.0e+11\n",
      "2023-11-13 19:33:30,648 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 10] h=1.390e-08, loss=1.072, rho=1.0e+11\n",
      "2023-11-13 19:33:30,663 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 10] h=5.150e-09, loss=1.072, rho=1.0e+12\n",
      "2023-11-13 19:33:30,664 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:222] - INFO: FINISHED\n"
     ]
    }
   ],
   "source": [
    "nt = Notears()\n",
    "nt.learn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[0, 0],\n",
       "        [1, 0]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt.causal_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'shd': 0, 'nnz': 1, 'precision': 1.0, 'recall': 1.0, 'F1': 1.0, 'gscore': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\metrics\\evaluation.py:193: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  num_tp =  (W_p + W_true).applymap(lambda elem:1 if elem==2 else 0).sum(axis=1).sum()\n",
      "c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\metrics\\evaluation.py:195: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  num_fn_r = (W_p - W_true).applymap(lambda elem:1 if elem==1 else 0).sum(axis=1).sum()\n",
      "c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\metrics\\evaluation.py:221: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  TP = (W_p + W_true).applymap(lambda elem:1 if elem==2 else 0).sum(axis=1).sum()\n"
     ]
    }
   ],
   "source": [
    "met = MetricsDAG(nt.causal_matrix, true_dag)\n",
    "print(met.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = './Data/pair0001.txt'\n",
    "\n",
    "X = np.loadtxt(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.050e+02,  9.700e+00],\n",
       "       [ 4.600e+01,  8.200e+00],\n",
       "       [ 7.940e+02,  6.400e+00],\n",
       "       [ 3.250e+02,  8.100e+00],\n",
       "       [ 5.000e+02,  6.200e+00],\n",
       "       [ 2.150e+02,  9.400e+00],\n",
       "       [ 3.830e+02,  7.800e+00],\n",
       "       [ 5.400e+01,  8.300e+00],\n",
       "       [ 6.300e+02,  6.600e+00],\n",
       "       [ 4.130e+02,  8.300e+00],\n",
       "       [ 4.810e+02,  7.500e+00],\n",
       "       [ 4.200e+01,  7.900e+00],\n",
       "       [ 2.420e+02,  8.400e+00],\n",
       "       [ 1.640e+02,  8.500e+00],\n",
       "       [ 4.620e+02,  8.000e+00],\n",
       "       [ 5.600e+02,  7.600e+00],\n",
       "       [ 4.000e+00,  8.400e+00],\n",
       "       [ 6.220e+02,  7.200e+00],\n",
       "       [ 2.390e+02,  8.500e+00],\n",
       "       [ 4.000e+01,  8.600e+00],\n",
       "       [ 3.300e+02,  7.700e+00],\n",
       "       [ 7.890e+02,  6.600e+00],\n",
       "       [ 4.500e+02,  8.000e+00],\n",
       "       [ 4.000e+01,  8.800e+00],\n",
       "       [ 2.520e+02,  9.800e+00],\n",
       "       [ 4.450e+02,  7.000e+00],\n",
       "       [ 6.000e+01,  8.800e+00],\n",
       "       [ 5.800e+01,  8.900e+00],\n",
       "       [ 3.600e+01,  9.300e+00],\n",
       "       [ 4.900e+01,  9.400e+00],\n",
       "       [ 8.400e+01,  9.200e+00],\n",
       "       [ 1.200e+02,  1.010e+01],\n",
       "       [ 3.630e+02,  8.800e+00],\n",
       "       [ 2.900e+02,  7.700e+00],\n",
       "       [ 4.120e+02,  7.500e+00],\n",
       "       [ 8.000e+01,  1.000e+01],\n",
       "       [ 2.100e+01,  9.400e+00],\n",
       "       [ 4.500e+01,  8.300e+00],\n",
       "       [ 1.500e+01,  8.400e+00],\n",
       "       [ 6.200e+01,  1.020e+01],\n",
       "       [ 8.750e+02,  6.800e+00],\n",
       "       [ 5.000e+00,  9.100e+00],\n",
       "       [ 3.730e+02,  8.300e+00],\n",
       "       [ 1.000e+00,  8.800e+00],\n",
       "       [ 9.000e+00,  8.100e+00],\n",
       "       [ 6.070e+02,  5.900e+00],\n",
       "       [ 8.800e+01,  8.800e+00],\n",
       "       [ 5.000e+00,  8.800e+00],\n",
       "       [ 7.000e+00,  9.000e+00],\n",
       "       [ 1.142e+03,  2.900e+00],\n",
       "       [ 5.490e+02,  7.800e+00],\n",
       "       [ 3.100e+02,  7.800e+00],\n",
       "       [ 3.400e+02,  8.100e+00],\n",
       "       [ 7.700e+01,  7.800e+00],\n",
       "       [ 6.800e+01,  9.200e+00],\n",
       "       [ 3.900e+01,  8.900e+00],\n",
       "       [ 3.960e+02,  7.900e+00],\n",
       "       [ 4.180e+02,  7.900e+00],\n",
       "       [ 5.660e+02,  6.200e+00],\n",
       "       [ 6.900e+01,  8.900e+00],\n",
       "       [ 5.000e+00,  8.900e+00],\n",
       "       [ 1.330e+02,  1.000e+01],\n",
       "       [ 4.800e+02,  7.900e+00],\n",
       "       [ 6.960e+02,  7.400e+00],\n",
       "       [ 9.700e+01,  8.500e+00],\n",
       "       [ 6.770e+02,  7.000e+00],\n",
       "       [ 2.270e+02,  8.900e+00],\n",
       "       [ 1.920e+02,  8.300e+00],\n",
       "       [ 6.920e+02,  6.900e+00],\n",
       "       [ 3.700e+01,  1.030e+01],\n",
       "       [ 3.700e+01,  1.030e+01],\n",
       "       [ 1.230e+02,  8.800e+00],\n",
       "       [ 1.460e+02,  8.500e+00],\n",
       "       [ 4.600e+02,  7.700e+00],\n",
       "       [ 8.500e+01,  9.800e+00],\n",
       "       [ 1.200e+01,  9.100e+00],\n",
       "       [ 0.000e+00,  8.800e+00],\n",
       "       [ 1.440e+02,  8.600e+00],\n",
       "       [ 7.050e+02,  6.800e+00],\n",
       "       [ 6.000e+02,  6.800e+00],\n",
       "       [ 4.436e+02,  7.800e+00],\n",
       "       [ 1.800e+01,  8.300e+00],\n",
       "       [ 3.160e+02,  7.900e+00],\n",
       "       [ 4.080e+02,  8.800e+00],\n",
       "       [ 2.700e+02,  8.600e+00],\n",
       "       [ 2.340e+02,  1.010e+01],\n",
       "       [ 1.500e+02,  9.600e+00],\n",
       "       [ 1.486e+03,  3.300e+00],\n",
       "       [ 1.213e+03,  2.900e+00],\n",
       "       [ 4.500e+01,  8.200e+00],\n",
       "       [ 1.120e+02,  9.700e+00],\n",
       "       [ 1.250e+02,  9.700e+00],\n",
       "       [ 4.800e+01,  8.700e+00],\n",
       "       [ 4.810e+02,  9.100e+00],\n",
       "       [ 2.000e+00,  8.400e+00],\n",
       "       [ 7.970e+02,  6.600e+00],\n",
       "       [ 9.280e+02,  5.900e+00],\n",
       "       [ 5.230e+02,  6.700e+00],\n",
       "       [ 3.940e+02,  9.100e+00],\n",
       "       [ 8.000e+00,  8.700e+00],\n",
       "       [ 2.550e+02,  8.000e+00],\n",
       "       [ 4.700e+01,  8.500e+00],\n",
       "       [ 7.190e+02,  6.500e+00],\n",
       "       [ 1.180e+02,  9.900e+00],\n",
       "       [ 3.500e+01,  8.600e+00],\n",
       "       [ 3.110e+02,  7.800e+00],\n",
       "       [ 9.000e+01,  1.000e+01],\n",
       "       [ 1.860e+02,  9.100e+00],\n",
       "       [ 2.000e+00,  8.500e+00],\n",
       "       [ 2.380e+02,  8.200e+00],\n",
       "       [ 1.730e+02,  8.700e+00],\n",
       "       [ 5.800e+01,  8.100e+00],\n",
       "       [ 2.700e+01,  8.300e+00],\n",
       "       [ 6.000e+00,  8.100e+00],\n",
       "       [ 4.000e+01,  7.800e+00],\n",
       "       [ 4.200e+01,  8.700e+00],\n",
       "       [ 1.436e+03,  2.700e+00],\n",
       "       [ 5.500e+01,  7.900e+00],\n",
       "       [ 3.000e+02,  7.400e+00],\n",
       "       [ 5.670e+02,  6.100e+00],\n",
       "       [ 9.300e+01,  9.100e+00],\n",
       "       [ 1.100e+01,  8.600e+00],\n",
       "       [ 2.200e+01,  9.400e+00],\n",
       "       [ 1.800e+01,  9.000e+00],\n",
       "       [ 5.900e+01,  8.900e+00],\n",
       "       [ 2.690e+02,  8.500e+00],\n",
       "       [ 4.040e+02,  6.800e+00],\n",
       "       [ 1.110e+02,  1.060e+01],\n",
       "       [ 5.000e+02,  6.800e+00],\n",
       "       [ 4.960e+02,  7.700e+00],\n",
       "       [ 4.000e+00,  9.100e+00],\n",
       "       [ 1.400e+02,  8.900e+00],\n",
       "       [ 2.000e+00,  8.200e+00],\n",
       "       [ 7.700e+01,  9.300e+00],\n",
       "       [ 3.500e+02,  8.500e+00],\n",
       "       [ 5.300e+02,  6.900e+00],\n",
       "       [ 2.720e+02,  8.700e+00],\n",
       "       [ 1.053e+03,  5.900e+00],\n",
       "       [ 8.830e+02,  5.600e+00],\n",
       "       [ 1.008e+03,  6.100e+00],\n",
       "       [ 5.670e+02,  6.400e+00],\n",
       "       [ 2.420e+02,  7.700e+00],\n",
       "       [ 9.770e+02,  6.500e+00],\n",
       "       [ 1.700e+01,  8.000e+00],\n",
       "       [ 1.280e+02,  8.900e+00],\n",
       "       [ 4.400e+02,  6.900e+00],\n",
       "       [ 1.125e+03,  4.800e+00],\n",
       "       [ 4.380e+02,  7.600e+00],\n",
       "       [ 3.000e+00,  8.200e+00],\n",
       "       [ 3.700e+01,  7.800e+00],\n",
       "       [ 7.120e+02,  6.800e+00],\n",
       "       [ 1.550e+02,  9.300e+00],\n",
       "       [ 7.000e+00,  8.600e+00],\n",
       "       [ 9.100e+01,  9.600e+00],\n",
       "       [ 7.500e+01,  8.700e+00],\n",
       "       [ 8.390e+02,  4.900e+00],\n",
       "       [ 2.700e+02,  9.400e+00],\n",
       "       [ 5.050e+02,  7.300e+00],\n",
       "       [ 4.870e+02,  6.700e+00],\n",
       "       [ 3.740e+02,  7.800e+00],\n",
       "       [ 1.120e+02,  1.030e+01],\n",
       "       [ 2.310e+02,  8.500e+00],\n",
       "       [ 5.850e+02,  7.400e+00],\n",
       "       [ 7.050e+02,  6.900e+00],\n",
       "       [ 2.700e+01,  8.500e+00],\n",
       "       [ 4.000e+00,  8.300e+00],\n",
       "       [ 2.820e+02,  8.600e+00],\n",
       "       [ 8.050e+02,  5.600e+00],\n",
       "       [ 4.600e+01,  9.600e+00],\n",
       "       [ 9.730e+02,  6.200e+00],\n",
       "       [ 9.200e+01,  9.600e+00],\n",
       "       [ 7.540e+02,  6.600e+00],\n",
       "       [ 4.170e+02,  7.800e+00],\n",
       "       [ 8.500e+02,  6.900e+00],\n",
       "       [ 4.430e+02,  9.200e+00],\n",
       "       [ 7.760e+02,  6.500e+00],\n",
       "       [ 1.020e+02,  9.500e+00],\n",
       "       [ 5.200e+02,  7.700e+00],\n",
       "       [ 4.360e+02,  8.100e+00],\n",
       "       [ 7.470e+02,  6.700e+00],\n",
       "       [ 5.000e+00,  8.700e+00],\n",
       "       [ 1.190e+02,  8.900e+00],\n",
       "       [ 3.000e+02,  7.500e+00],\n",
       "       [ 3.445e+02,  8.100e+00],\n",
       "       [ 7.000e+00,  7.900e+00],\n",
       "       [ 9.000e+00,  8.200e+00],\n",
       "       [ 3.650e+02,  7.800e+00],\n",
       "       [ 3.560e+02,  7.500e+00],\n",
       "       [ 1.380e+02,  9.100e+00],\n",
       "       [ 1.410e+02,  8.800e+00],\n",
       "       [ 7.580e+02,  7.200e+00],\n",
       "       [ 8.180e+02,  6.100e+00],\n",
       "       [ 4.400e+01,  1.080e+01],\n",
       "       [ 2.840e+02,  8.900e+00],\n",
       "       [ 1.850e+02,  9.300e+00],\n",
       "       [ 9.800e+01,  8.600e+00],\n",
       "       [ 3.410e+02,  9.400e+00],\n",
       "       [ 2.200e+01,  9.400e+00],\n",
       "       [ 1.570e+02,  8.900e+00],\n",
       "       [ 9.200e+01,  9.300e+00],\n",
       "       [ 2.600e+01,  8.400e+00],\n",
       "       [ 2.200e+01,  9.000e+00],\n",
       "       [ 1.610e+02,  8.600e+00],\n",
       "       [ 5.000e+00,  8.100e+00],\n",
       "       [ 1.700e+01,  8.600e+00],\n",
       "       [ 4.440e+02,  7.900e+00],\n",
       "       [ 5.800e+01,  9.400e+00],\n",
       "       [ 1.100e+01,  8.900e+00],\n",
       "       [ 7.600e+01,  8.700e+00],\n",
       "       [ 4.190e+02,  7.800e+00],\n",
       "       [ 9.600e+01,  1.020e+01],\n",
       "       [ 1.860e+02,  8.900e+00],\n",
       "       [ 5.470e+02,  6.800e+00],\n",
       "       [ 4.500e+02,  6.900e+00],\n",
       "       [ 7.700e+01,  8.000e+00],\n",
       "       [ 3.130e+02,  7.700e+00],\n",
       "       [ 6.210e+02,  7.500e+00],\n",
       "       [ 4.200e+01,  8.400e+00],\n",
       "       [ 4.050e+02,  8.000e+00],\n",
       "       [ 2.730e+02,  9.700e+00],\n",
       "       [ 6.300e+01,  8.300e+00],\n",
       "       [ 5.150e+02,  8.100e+00],\n",
       "       [ 5.280e+02,  7.800e+00],\n",
       "       [ 5.150e+02,  9.100e+00],\n",
       "       [ 6.200e+01,  9.200e+00],\n",
       "       [ 8.100e+01,  7.900e+00],\n",
       "       [ 1.110e+02,  9.800e+00],\n",
       "       [ 5.000e+02,  7.200e+00],\n",
       "       [ 2.600e+01,  8.400e+00],\n",
       "       [ 3.800e+01,  8.500e+00],\n",
       "       [ 1.250e+02,  1.010e+01],\n",
       "       [ 6.400e+01,  8.000e+00],\n",
       "       [ 2.600e+01,  9.000e+00],\n",
       "       [ 4.250e+02,  8.000e+00],\n",
       "       [ 1.100e+01,  9.000e+00],\n",
       "       [ 6.270e+02,  6.700e+00],\n",
       "       [ 3.140e+02,  8.800e+00],\n",
       "       [ 2.800e+02,  8.800e+00],\n",
       "       [ 4.900e+02,  7.700e+00],\n",
       "       [ 8.060e+02,  6.100e+00],\n",
       "       [ 2.760e+02,  9.100e+00],\n",
       "       [ 1.100e+02,  1.030e+01],\n",
       "       [ 1.500e+02,  8.600e+00],\n",
       "       [ 9.500e+01,  9.100e+00],\n",
       "       [ 4.090e+02,  8.000e+00],\n",
       "       [ 4.350e+02,  7.600e+00],\n",
       "       [ 2.460e+02,  9.100e+00],\n",
       "       [ 3.860e+02,  7.500e+00],\n",
       "       [ 2.400e+01,  8.400e+00],\n",
       "       [ 8.100e+01,  8.700e+00],\n",
       "       [ 4.000e+01,  7.900e+00],\n",
       "       [ 1.230e+02,  8.800e+00],\n",
       "       [ 1.640e+03,  3.400e+00],\n",
       "       [ 1.090e+02,  9.600e+00],\n",
       "       [ 3.660e+02,  8.200e+00],\n",
       "       [ 4.700e+02,  8.000e+00],\n",
       "       [ 6.900e+02,  6.200e+00],\n",
       "       [ 1.310e+02,  9.700e+00],\n",
       "       [ 2.870e+02,  1.000e+01],\n",
       "       [ 1.160e+02,  9.800e+00],\n",
       "       [ 4.440e+02,  8.300e+00],\n",
       "       [ 4.000e+00,  8.400e+00],\n",
       "       [ 8.700e+01,  9.000e+00],\n",
       "       [ 7.470e+02,  6.800e+00],\n",
       "       [ 5.880e+02,  7.300e+00],\n",
       "       [ 6.920e+02,  6.000e+00],\n",
       "       [ 3.200e+02,  8.900e+00],\n",
       "       [ 1.930e+02,  1.040e+01],\n",
       "       [ 3.330e+02,  7.200e+00],\n",
       "       [ 1.350e+02,  9.200e+00],\n",
       "       [ 7.950e+02,  6.200e+00],\n",
       "       [ 5.000e+00,  8.500e+00],\n",
       "       [ 1.550e+02,  9.200e+00],\n",
       "       [ 1.550e+02,  8.600e+00],\n",
       "       [ 6.090e+02,  5.300e+00],\n",
       "       [ 4.300e+01,  8.000e+00],\n",
       "       [ 1.700e+02,  9.200e+00],\n",
       "       [ 9.930e+02,  5.600e+00],\n",
       "       [ 9.370e+02,  4.400e+00],\n",
       "       [ 6.350e+02,  7.400e+00],\n",
       "       [ 6.160e+02,  7.200e+00],\n",
       "       [ 2.650e+02,  8.200e+00],\n",
       "       [ 5.040e+02,  6.200e+00],\n",
       "       [ 3.650e+02,  8.600e+00],\n",
       "       [ 4.440e+02,  7.700e+00],\n",
       "       [ 7.920e+02,  6.800e+00],\n",
       "       [ 5.900e+01,  8.400e+00],\n",
       "       [ 2.100e+01,  8.500e+00],\n",
       "       [ 1.860e+02,  8.500e+00],\n",
       "       [ 6.110e+02,  6.200e+00],\n",
       "       [ 3.600e+02,  8.000e+00],\n",
       "       [ 7.700e+01,  8.400e+00],\n",
       "       [ 3.650e+02,  7.400e+00],\n",
       "       [ 1.470e+02,  8.800e+00],\n",
       "       [ 8.700e+01,  8.900e+00],\n",
       "       [ 7.340e+02,  6.800e+00],\n",
       "       [ 3.500e+02,  8.300e+00],\n",
       "       [ 2.860e+02,  1.010e+01],\n",
       "       [ 3.110e+02,  9.500e+00],\n",
       "       [ 4.010e+02,  8.700e+00],\n",
       "       [ 8.370e+02,  7.400e+00],\n",
       "       [ 4.600e+01,  8.100e+00],\n",
       "       [ 6.100e+01,  8.800e+00],\n",
       "       [ 3.960e+02,  8.400e+00],\n",
       "       [ 8.700e+02,  5.700e+00],\n",
       "       [ 8.460e+02,  5.600e+00],\n",
       "       [ 7.810e+02,  6.200e+00],\n",
       "       [ 6.400e+02,  7.200e+00],\n",
       "       [ 8.000e+01,  8.700e+00],\n",
       "       [ 9.000e+00,  8.600e+00],\n",
       "       [ 7.000e+02,  7.100e+00],\n",
       "       [ 1.440e+02,  9.900e+00],\n",
       "       [ 2.650e+02,  9.100e+00],\n",
       "       [ 4.900e+02,  8.700e+00],\n",
       "       [ 5.000e+01,  8.500e+00],\n",
       "       [ 5.710e+02,  7.900e+00],\n",
       "       [ 4.710e+02,  8.000e+00],\n",
       "       [ 2.910e+02,  8.200e+00],\n",
       "       [ 2.400e+02,  8.200e+00],\n",
       "       [ 5.100e+01,  8.800e+00],\n",
       "       [ 2.230e+02,  1.010e+01],\n",
       "       [ 1.760e+02,  8.400e+00],\n",
       "       [ 3.800e+02,  8.100e+00],\n",
       "       [ 9.400e+02,  5.600e+00],\n",
       "       [ 7.000e+01,  8.100e+00],\n",
       "       [ 9.210e+02,  4.800e+00],\n",
       "       [ 4.380e+02,  7.400e+00],\n",
       "       [ 4.700e+02,  7.500e+00],\n",
       "       [ 1.460e+02,  9.600e+00],\n",
       "       [ 5.530e+02,  7.800e+00],\n",
       "       [ 4.400e+02,  8.700e+00],\n",
       "       [ 2.190e+02,  9.600e+00],\n",
       "       [ 4.220e+02,  8.100e+00],\n",
       "       [ 1.832e+03,  2.100e+00],\n",
       "       [ 1.400e+02,  9.100e+00],\n",
       "       [ 3.000e+00,  8.300e+00],\n",
       "       [ 1.420e+02,  9.800e+00],\n",
       "       [ 7.400e+02,  7.200e+00],\n",
       "       [ 5.800e+02,  6.400e+00],\n",
       "       [ 6.810e+02,  5.900e+00],\n",
       "       [ 1.050e+02,  8.700e+00],\n",
       "       [ 1.330e+02,  8.700e+00],\n",
       "       [ 4.640e+02,  7.500e+00],\n",
       "       [ 2.910e+02,  9.400e+00],\n",
       "       [ 1.000e+00,  8.400e+00],\n",
       "       [ 2.680e+02,  9.100e+00],\n",
       "       [ 8.770e+02,  4.300e+00],\n",
       "       [ 2.960e+03, -4.800e+00],\n",
       "       [ 6.150e+02,  6.200e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 2)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning causality of real data (contrary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 19:37:31,713 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:195] - INFO: [start]: n=721, d=2, iter_=100, h_=1e-08, rho_=1e+16\n",
      "2023-11-13 19:37:31,724 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 0] h=6.455e-02, loss=80409.127, rho=1.0e+00\n",
      "2023-11-13 19:37:31,729 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=6.451e-02, loss=51511.375, rho=1.0e+00\n",
      "2023-11-13 19:37:31,736 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=6.412e-02, loss=51511.394, rho=1.0e+01\n",
      "2023-11-13 19:37:31,743 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=6.124e-02, loss=51511.582, rho=1.0e+02\n",
      "2023-11-13 19:37:31,750 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=4.508e-02, loss=51513.457, rho=1.0e+03\n",
      "2023-11-13 19:37:31,763 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=1.916e-02, loss=51532.207, rho=1.0e+04\n",
      "2023-11-13 19:37:31,775 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 1] h=5.535e-03, loss=51719.708, rho=1.0e+05\n",
      "2023-11-13 19:37:31,786 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 2] h=2.930e-03, loss=51523.369, rho=1.0e+05\n",
      "2023-11-13 19:37:31,809 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 2] h=1.031e-03, loss=51537.158, rho=1.0e+06\n",
      "2023-11-13 19:37:31,816 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 3] h=5.880e-04, loss=51524.831, rho=1.0e+06\n",
      "2023-11-13 19:37:31,828 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 3] h=2.153e-04, loss=51529.611, rho=1.0e+07\n",
      "2023-11-13 19:37:31,840 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 4] h=1.248e-04, loss=51525.547, rho=1.0e+07\n",
      "2023-11-13 19:37:31,844 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 4] h=4.610e-05, loss=51527.633, rho=1.0e+08\n",
      "2023-11-13 19:37:31,855 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 5] h=2.677e-05, loss=51525.881, rho=1.0e+08\n",
      "2023-11-13 19:37:31,866 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 5] h=9.915e-06, loss=51526.837, rho=1.0e+09\n",
      "2023-11-13 19:37:31,873 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 6] h=5.738e-06, loss=51526.036, rho=1.0e+09\n",
      "2023-11-13 19:37:31,883 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 6] h=2.137e-06, loss=51526.478, rho=1.0e+10\n",
      "2023-11-13 19:37:31,887 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 7] h=1.244e-06, loss=51526.108, rho=1.0e+10\n",
      "2023-11-13 19:37:31,904 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 7] h=4.684e-07, loss=51526.313, rho=1.0e+11\n",
      "2023-11-13 19:37:31,906 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 8] h=2.643e-07, loss=51526.142, rho=1.0e+11\n",
      "2023-11-13 19:37:31,924 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 8] h=9.889e-08, loss=51526.241, rho=1.0e+12\n",
      "2023-11-13 19:37:31,924 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 9] h=5.630e-08, loss=51526.157, rho=1.0e+12\n",
      "2023-11-13 19:37:31,940 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 9] h=2.094e-08, loss=51526.201, rho=1.0e+13\n",
      "2023-11-13 19:37:31,952 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 10] h=1.252e-08, loss=51526.164, rho=1.0e+13\n",
      "2023-11-13 19:37:31,958 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:206] - INFO: [iter 10] h=5.223e-09, loss=51526.183, rho=1.0e+14\n",
      "2023-11-13 19:37:31,958 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\linear.py[line:222] - INFO: FINISHED\n"
     ]
    }
   ],
   "source": [
    "nt = Notears(w_threshold=0.2)\n",
    "nt.learn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[0, 1],\n",
       "        [0, 0]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt.causal_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non-linear SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 19:38:16,077 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\torch\\nonlinear.py[line:137] - INFO: GPU is unavailable.\n",
      "2023-11-13 19:38:16,079 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\torch\\nonlinear.py[line:237] - INFO: [start]: n=721, d=2, iter_=100, h_=1e-08, rho_=1e+16\n",
      "2023-11-13 19:38:28,391 - c:\\Users\\yurou\\anaconda3\\envs\\NOTEARS\\Lib\\site-packages\\castle\\algorithms\\gradient\\notears\\torch\\nonlinear.py[line:249] - INFO: FINISHED\n"
     ]
    }
   ],
   "source": [
    "nt = NotearsNonlinear()\n",
    "nt.learn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[0, 1],\n",
       "        [0, 0]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = nt.causal_matrix\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NOTEARS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
