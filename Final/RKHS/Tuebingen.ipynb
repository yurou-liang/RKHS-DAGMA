{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7be96dea-4eaa-402d-96f5-324842ffdbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils, RKHS_DAGMA_extractj\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1265f912-65b3-4f3d-a5ef-9274d7ac4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_tuebingen_causality(index, lambda1 = 1e-3, tau = 1e-4, gamma = 1, T=6, lr = 0.03):\n",
    "    result = {}\n",
    "    # load data\n",
    "    url = 'https://webdav.tuebingen.mpg.de/cause-effect/pair' + str(index).zfill(4) + '.txt'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    causality_df = pd.read_csv('causality_df.csv')\n",
    "    index_list = causality_df['index'].tolist()\n",
    "\n",
    "    if index not in index_list:\n",
    "        raise ValueError(\"invalid index.\")\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Read the content of the file\n",
    "        content = response.text\n",
    "        \n",
    "        # Turn the string content into a file-like object\n",
    "        content_as_file = StringIO(content)\n",
    "        \n",
    "        # Read into a DataFrame assuming the delimiter is a tab. Adjust if necessary.\n",
    "        df = pd.read_csv(content_as_file, sep=' ', header=None, names=['X', 'Y'])\n",
    "        scaler = StandardScaler()\n",
    "        df['X'] = scaler.fit_transform(df[['X']])\n",
    "        df['Y'] = scaler.fit_transform(df[['Y']])\n",
    "        # Convert the DataFrame into a NumPy array\n",
    "        data_array = df.to_numpy()\n",
    "    \n",
    "        # Now 'array' is a NumPy array with the data from the text file\n",
    "        X = torch.tensor(data_array)\n",
    "    else:\n",
    "        raise ValueError(f'Failed to retrieve the file: Status code {response.status_code}')\n",
    "\n",
    "    torch.set_default_dtype(torch.float64)\n",
    "    device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.set_default_device(device)\n",
    "    \n",
    "    X = X.to(device)\n",
    "    eq_model = RKHS_DAGMA_extractj.DagmaRKHS(X, gamma = gamma).to(device)\n",
    "    model = RKHS_DAGMA_extractj.DagmaRKHS_nonlinear(eq_model)\n",
    "    W_est_no_thresh, output = model.fit(X, lambda1=lambda1, tau=tau, T = T, mu_init = 1.0, lr=lr, w_threshold=0.0)\n",
    "    result['W_est_no_thresh'] = W_est_no_thresh.tolist()\n",
    "    thresh_values = [0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "    for thresh in thresh_values:\n",
    "        W_est_dagma = (abs(W_est_no_thresh) > thresh)\n",
    "        causality = causality_df[causality_df['index'] == index][\"causality\"].item()\n",
    "        if causality == 0:\n",
    "            if W_est_dagma[0, 1] == 1 and W_est_dagma[1, 0] == 0:\n",
    "                valid = 'yes'\n",
    "            else:\n",
    "                valid = 'no'\n",
    "        else:\n",
    "            if W_est_dagma[0, 1] == 0 and W_est_dagma[1, 0] == 1:\n",
    "                valid = 'yes'\n",
    "            else:\n",
    "                valid = 'no' \n",
    "        key = f'threshold_{thresh}'\n",
    "        result[key] = valid\n",
    "    filename = f'{index}th_data_results.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(result, file, indent=4)\n",
    "\n",
    "    y_hat = output[:, 1].cpu().detach().numpy()\n",
    "    plt.figure(figsize=(10, 6))  # Optional: specifies the figure size\n",
    "    plt.scatter(df.iloc[:, 0], df.iloc[:, 1], label='y', color='blue', marker='o')  # Plot x vs. y1\n",
    "    plt.scatter(df.iloc[:, 0], y_hat, label='y_est', color='red', marker='s') \n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    # save the plot\n",
    "    plt.savefig(f'{index}.png')\n",
    "    plt.clf()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49c44892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8503a4ad04b4c19a3f9e04e24e404ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "est_tuebingen_causality(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e584d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
