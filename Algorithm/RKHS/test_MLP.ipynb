{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from notears.locally_connected import LocallyConnected\n",
    "from lbfgsb_scipy import LBFGSBScipy\n",
    "from trace_expm import trace_expm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from locally_connected import LocallyConnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotearsMLP(nn.Module):\n",
    "    def __init__(self, dims, bias=True):\n",
    "        super(NotearsMLP, self).__init__()\n",
    "        assert len(dims) >= 2\n",
    "        assert dims[-1] == 1 # output dim of last layer must be 1\n",
    "        d = dims[0]\n",
    "        self.dims = dims\n",
    "        # fc1: variable splitting for l1\n",
    "        self.fc1_pos = nn.Linear(d, d * dims[1], bias=bias)\n",
    "        self.fc1_neg = nn.Linear(d, d * dims[1], bias=bias)\n",
    "        \n",
    "        self.fc1_pos.weight.bounds = self._bounds()\n",
    "        self.fc1_neg.weight.bounds = self._bounds()\n",
    "        # fc2: local linear layers\n",
    "        layers = []\n",
    "        for l in range(len(dims) - 2):\n",
    "            layers.append(LocallyConnected(d, dims[l + 1], dims[l + 2], bias=bias))\n",
    "        self.fc2 = nn.ModuleList(layers)\n",
    "\n",
    "    def _bounds(self):\n",
    "        d = self.dims[0]\n",
    "        bounds = []\n",
    "        for j in range(d):\n",
    "            for m in range(self.dims[1]):\n",
    "                for i in range(d):\n",
    "                    if i == j:\n",
    "                        bound = (0, 0) # self loop not allowed\n",
    "                    else:\n",
    "                        bound = (0, None)\n",
    "                    bounds.append(bound)\n",
    "        return bounds\n",
    "\n",
    "    def forward(self, x):  # [n, d] -> [n, d]\n",
    "        x = self.fc1_pos(x) - self.fc1_neg(x)  # [n, d * m1] pass linear layer through input x\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, self.dims[0], self.dims[1])  # [n, d, m1]\n",
    "        for fc in self.fc2:\n",
    "            x = torch.sigmoid(x)  # [n, d, m1]\n",
    "            x = fc(x)  # [n, d, m2]\n",
    "            #print(x.shape)\n",
    "        x = x.squeeze(dim=2)  # [n, d]\n",
    "        return x\n",
    "\n",
    "    def h_func(self):\n",
    "        \"\"\"Constrain 2-norm-squared of fc1 weights along m1 dim to be a DAG\"\"\"\n",
    "        d = self.dims[0]\n",
    "        fc1_weight = self.fc1_pos.weight - self.fc1_neg.weight  # [j * m1, i]\n",
    "        fc1_weight = fc1_weight.view(d, -1, d)  # [j, m1, i]\n",
    "        A = torch.sum(fc1_weight * fc1_weight, dim=1).t()  # [i, j]\n",
    "        h = trace_expm(A) - d  # (Zheng et al. 2018)\n",
    "        # A different formulation, slightly faster at the cost of numerical stability\n",
    "        # M = torch.eye(d) + A / d  # (Yu et al. 2019)\n",
    "        # E = torch.matrix_power(M, d - 1)\n",
    "        # h = (E.t() * M).sum() - d\n",
    "        return h\n",
    "\n",
    "    def l2_reg(self):\n",
    "        \"\"\"Take 2-norm-squared of all parameters\"\"\"\n",
    "        reg = 0.\n",
    "        fc1_weight = self.fc1_pos.weight - self.fc1_neg.weight  # [j * m1, i]\n",
    "        reg += torch.sum(fc1_weight ** 2)\n",
    "        for fc in self.fc2:\n",
    "            reg += torch.sum(fc.weight ** 2)\n",
    "        return reg\n",
    "\n",
    "    def fc1_l1_reg(self):\n",
    "        \"\"\"Take l1 norm of fc1 weight\"\"\"\n",
    "        reg = torch.sum(self.fc1_pos.weight + self.fc1_neg.weight)\n",
    "        return reg\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def fc1_to_adj(self) -> np.ndarray:  # [j * m1, i] -> [i, j]\n",
    "        \"\"\"Get W from fc1 weights, take 2-norm over m1 dim\"\"\"\n",
    "        d = self.dims[0]\n",
    "        fc1_weight = self.fc1_pos.weight - self.fc1_neg.weight  # [j * m1, i]\n",
    "        fc1_weight = fc1_weight.view(d, -1, d)  # [j, m1, i]\n",
    "        A = torch.sum(fc1_weight * fc1_weight, dim=1).t()  # [i, j]\n",
    "        W = torch.sqrt(A)  # [i, j]\n",
    "        W = W.cpu().detach().numpy()  # [i, j]\n",
    "        return W\n",
    "\n",
    "\n",
    "def squared_loss(output, target):\n",
    "    n = target.shape[0]\n",
    "    loss = 0.5 / n * torch.sum((output - target) ** 2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def dual_ascent_step(model, X, lambda1, lambda2, rho, alpha, h, rho_max):\n",
    "    \"\"\"Perform one step of dual ascent in augmented Lagrangian.\"\"\"\n",
    "    h_new = None\n",
    "    optimizer = LBFGSBScipy(model.parameters())\n",
    "    for idx, param in enumerate(model.parameters()):\n",
    "        print('layer:',idx,'shape:',param.shape)\n",
    "    #print(model.parameters().shape)\n",
    "    #print(\"model.parameters(): \", model.parameters().data())\n",
    "    X_torch = torch.from_numpy(X)\n",
    "    while rho < rho_max:\n",
    "        print(\"rho: \", rho)\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            X_hat = model(X_torch)\n",
    "            loss = squared_loss(X_hat, X_torch)\n",
    "            h_val = model.h_func()\n",
    "            print(\"h_val: \", h_val)\n",
    "            penalty = 0.5 * rho * h_val * h_val + alpha * h_val\n",
    "            l2_reg = 0.5 * lambda2 * model.l2_reg()\n",
    "            l1_reg = lambda1 * model.fc1_l1_reg()\n",
    "            primal_obj = loss + penalty + l2_reg + l1_reg\n",
    "            primal_obj.backward()\n",
    "            print('squared loss:', loss.item())\n",
    "            print('loss:', primal_obj.item())\n",
    "            print('penalty:', penalty.item())\n",
    "            return primal_obj\n",
    "        optimizer.step(closure)  # NOTE: updates model in-place\n",
    "        with torch.no_grad():\n",
    "            h_new = model.h_func().item()\n",
    "            print(\"h_new: \", h_new)\n",
    "        if h_new > 0.25 * h:\n",
    "            rho *= 10\n",
    "        else:\n",
    "            break\n",
    "    alpha += rho * h_new\n",
    "    return rho, alpha, h_new\n",
    "\n",
    "\n",
    "def notears_nonlinear(model: nn.Module,\n",
    "                      X: np.ndarray,\n",
    "                      lambda1: float = 0.,\n",
    "                      lambda2: float = 0.,\n",
    "                      max_iter: int = 100,\n",
    "                      h_tol: float = 1e-8,\n",
    "                      rho_max: float = 1e+16,\n",
    "                      w_threshold: float = 0.3):\n",
    "    rho, alpha, h = 1.0, 0.0, np.inf\n",
    "    for _ in range(max_iter):\n",
    "        rho, alpha, h = dual_ascent_step(model, X, lambda1, lambda2,\n",
    "                                         rho, alpha, h, rho_max)\n",
    "        if h <= h_tol or rho >= rho_max:\n",
    "            break\n",
    "    W_est = model.fc1_to_adj()\n",
    "    print(W_est)\n",
    "    W_est[np.abs(W_est) < w_threshold] = 0\n",
    "    W_est[np.abs(W_est) >= w_threshold] = 1\n",
    "    X_torch = torch.from_numpy(X)\n",
    "    output = model.forward(X_torch)\n",
    "    return W_est, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_true:  [[0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "X.dtype:  float64\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "[[0.000e+00 2.911e+00 0.000e+00 0.000e+00]\n",
      " [1.657e-05 0.000e+00 0.000e+00 0.000e+00]\n",
      " [3.007e+00 1.860e-01 0.000e+00 0.000e+00]\n",
      " [2.108e-01 2.370e+00 0.000e+00 0.000e+00]]\n",
      "W_est [[0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "import utils as ut\n",
    "ut.set_random_seed(123)\n",
    "\n",
    "n, d, s0, graph_type, sem_type = 100, 4, 3, 'ER', 'mim'\n",
    "B_true = ut.simulate_dag(d, s0, graph_type)\n",
    "#np.savetxt('W_true.csv', B_true, delimiter=',')\n",
    "print(\"W_true: \", B_true)\n",
    "\n",
    "X = ut.simulate_nonlinear_sem(B_true, n, sem_type)\n",
    "#np.savetxt('X.csv', X, delimiter=',')\n",
    "print(\"X.dtype: \", X.dtype)\n",
    "\n",
    "model = NotearsMLP(dims=[d, 10, 1], bias=True)\n",
    "W_est = notears_nonlinear(model, X, lambda1=0.01, lambda2=0.01)\n",
    "#np.savetxt('W_est.csv', W_est, delimiter=',')\n",
    "print(\"W_est\", W_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "3\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "[[0.000e+00 3.445e+00 1.147e+00]\n",
      " [1.803e-05 0.000e+00 4.444e-02]\n",
      " [5.936e-05 4.221e-04 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "x = np.random.normal(10,2, 100)\n",
    "\n",
    "np.random.seed(24)\n",
    "l = np.random.normal(0,1, 100) \n",
    "\n",
    "\n",
    "np.random.seed(25)\n",
    "b = np.random.normal(0,1, 100) \n",
    "\n",
    "\n",
    "y = [8*x + l for x, l in zip(x, l)]\n",
    "z = [3*x + b for x, b in zip(x, b)]\n",
    "\n",
    "X = np.column_stack((x, y, z))\n",
    "n = X.shape[0]\n",
    "d = X.shape[1]\n",
    "\n",
    "print(n)\n",
    "print(d)\n",
    "\n",
    "model = NotearsMLP(dims=[d, 10, 1], bias=True)\n",
    "W_est = notears_nonlinear(model, X, lambda1=0.01, lambda2=0.01)\n",
    "# worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "2\n",
      "layer: 0 shape: torch.Size([20, 2])\n",
      "layer: 1 shape: torch.Size([20])\n",
      "layer: 2 shape: torch.Size([20, 2])\n",
      "layer: 3 shape: torch.Size([20])\n",
      "layer: 4 shape: torch.Size([2, 10, 1])\n",
      "layer: 5 shape: torch.Size([2, 1])\n",
      "rho:  1.0\n",
      "h_val:  tensor(1.4787, grad_fn=<SubBackward0>)\n",
      "squared loss: 5905.827733332536\n",
      "loss: 5907.031154997175\n",
      "penalty: 1.0932550882931038\n",
      "h_val:  tensor(2.3852, grad_fn=<SubBackward0>)\n",
      "squared loss: 5707.517100784814\n",
      "loss: 5710.493434007071\n",
      "penalty: 2.8445114420423203\n",
      "h_val:  tensor(73.0420, grad_fn=<SubBackward0>)\n",
      "squared loss: 5251.345326810472\n",
      "loss: 7919.171499616669\n",
      "penalty: 2667.569940455434\n",
      "h_val:  tensor(6.3179, grad_fn=<SubBackward0>)\n",
      "squared loss: 5532.759046691448\n",
      "loss: 5552.8816584162905\n",
      "penalty: 19.957633440263237\n",
      "h_val:  tensor(42.1343, grad_fn=<SubBackward0>)\n",
      "squared loss: 5295.318429855154\n",
      "loss: 6183.203041423506\n",
      "penalty: 887.6477375642581\n",
      "h_val:  tensor(10.5317, grad_fn=<SubBackward0>)\n",
      "squared loss: 5459.23516071929\n",
      "loss: 5514.8772519515205\n",
      "penalty: 55.45834858911025\n",
      "h_val:  tensor(12.3214, grad_fn=<SubBackward0>)\n",
      "squared loss: 5372.841040816149\n",
      "loss: 5448.949491689682\n",
      "penalty: 75.90829815350209\n",
      "h_val:  tensor(30.8230, grad_fn=<SubBackward0>)\n",
      "squared loss: 5009.275738159264\n",
      "loss: 5484.585991534726\n",
      "penalty: 475.0281598149872\n",
      "h_val:  tensor(18.3786, grad_fn=<SubBackward0>)\n",
      "squared loss: 5191.169281961179\n",
      "loss: 5360.293578142606\n",
      "penalty: 168.88628023211265\n",
      "h_val:  tensor(98.7574, grad_fn=<SubBackward0>)\n",
      "squared loss: 4468.967858526304\n",
      "loss: 9345.928224425199\n",
      "penalty: 4876.508051415226\n",
      "h_val:  tensor(22.7223, grad_fn=<SubBackward0>)\n",
      "squared loss: 4935.488801324305\n",
      "loss: 5193.933223724618\n",
      "penalty: 258.1516314171406\n",
      "h_val:  tensor(15.3020, grad_fn=<SubBackward0>)\n",
      "squared loss: 4673.230161547017\n",
      "loss: 4790.665569594271\n",
      "penalty: 117.07617759079989\n",
      "h_val:  tensor(18.5654, grad_fn=<SubBackward0>)\n",
      "squared loss: 4470.313749164352\n",
      "loss: 4643.081702562597\n",
      "penalty: 172.33719530497936\n",
      "h_val:  tensor(26.0116, grad_fn=<SubBackward0>)\n",
      "squared loss: 3914.410874713246\n",
      "loss: 4253.370408988164\n",
      "penalty: 338.3024363900142\n",
      "h_val:  tensor(5.2578, grad_fn=<SubBackward0>)\n",
      "squared loss: 3803.505674762243\n",
      "loss: 3818.021546523994\n",
      "penalty: 13.822283007807089\n",
      "h_val:  tensor(14.2211, grad_fn=<SubBackward0>)\n",
      "squared loss: 3461.2338593526138\n",
      "loss: 3563.246816453911\n",
      "penalty: 101.11985931426938\n",
      "h_val:  tensor(17.5928, grad_fn=<SubBackward0>)\n",
      "squared loss: 3177.601281347543\n",
      "loss: 3333.4364701247264\n",
      "penalty: 154.7535265567642\n",
      "h_val:  tensor(115.6553, grad_fn=<SubBackward0>)\n",
      "squared loss: 1456.2915415273915\n",
      "loss: 8148.666692008059\n",
      "penalty: 6688.072303822037\n",
      "h_val:  tensor(18.1383, grad_fn=<SubBackward0>)\n",
      "squared loss: 2116.084525910399\n",
      "loss: 2282.670134777384\n",
      "penalty: 164.49899628154236\n",
      "h_val:  tensor(22.3808, grad_fn=<SubBackward0>)\n",
      "squared loss: 1315.3288885865425\n",
      "loss: 1570.181164185264\n",
      "penalty: 250.44981698601768\n",
      "h_val:  tensor(3.9633, grad_fn=<SubBackward0>)\n",
      "squared loss: 983.4936135176868\n",
      "loss: 996.682783617969\n",
      "penalty: 7.853777476185505\n",
      "h_val:  tensor(4.1592, grad_fn=<SubBackward0>)\n",
      "squared loss: 843.2170938242269\n",
      "loss: 857.9782740681042\n",
      "penalty: 8.649360802372954\n",
      "h_val:  tensor(5.1446, grad_fn=<SubBackward0>)\n",
      "squared loss: 770.9654678652578\n",
      "loss: 791.2552643481397\n",
      "penalty: 13.233500281239486\n",
      "h_val:  tensor(4.7981, grad_fn=<SubBackward0>)\n",
      "squared loss: 770.0123211786192\n",
      "loss: 788.5350219300772\n",
      "penalty: 11.510841975337367\n",
      "h_val:  tensor(4.1201, grad_fn=<SubBackward0>)\n",
      "squared loss: 770.0905387214391\n",
      "loss: 785.4901383970746\n",
      "penalty: 8.48743928288397\n",
      "h_val:  tensor(3.8647, grad_fn=<SubBackward0>)\n",
      "squared loss: 770.4462982482213\n",
      "loss: 784.8082663684792\n",
      "penalty: 7.467775264794935\n",
      "h_val:  tensor(3.6567, grad_fn=<SubBackward0>)\n",
      "squared loss: 770.8286070304265\n",
      "loss: 784.4068923399217\n",
      "penalty: 6.685864874669745\n",
      "h_val:  tensor(3.4916, grad_fn=<SubBackward0>)\n",
      "squared loss: 771.1415863034947\n",
      "loss: 784.1338738545036\n",
      "penalty: 6.095603292546118\n",
      "h_val:  tensor(3.2825, grad_fn=<SubBackward0>)\n",
      "squared loss: 771.488386340841\n",
      "loss: 783.7804150926594\n",
      "penalty: 5.387385816727038\n",
      "h_val:  tensor(3.0068, grad_fn=<SubBackward0>)\n",
      "squared loss: 771.8499102438209\n",
      "loss: 783.2864958686265\n",
      "penalty: 4.520362512596126\n",
      "h_val:  tensor(2.6962, grad_fn=<SubBackward0>)\n",
      "squared loss: 772.1655701422762\n",
      "loss: 782.7294072951248\n",
      "penalty: 3.634849699085416\n",
      "h_val:  tensor(2.4899, grad_fn=<SubBackward0>)\n",
      "squared loss: 772.2357583978524\n",
      "loss: 782.2747256163926\n",
      "penalty: 3.099852663375591\n",
      "h_val:  tensor(2.4056, grad_fn=<SubBackward0>)\n",
      "squared loss: 771.7342108073047\n",
      "loss: 781.5774845435701\n",
      "penalty: 2.893360039101822\n",
      "h_val:  tensor(2.7442, grad_fn=<SubBackward0>)\n",
      "squared loss: 768.874802183449\n",
      "loss: 779.6209694745783\n",
      "penalty: 3.765342843487349\n",
      "h_val:  tensor(2.7219, grad_fn=<SubBackward0>)\n",
      "squared loss: 768.8712610462189\n",
      "loss: 779.5516047172794\n",
      "penalty: 3.704442269797653\n",
      "h_val:  tensor(2.7903, grad_fn=<SubBackward0>)\n",
      "squared loss: 768.5568299719021\n",
      "loss: 779.4186734719901\n",
      "penalty: 3.8928027419649442\n",
      "h_val:  tensor(2.8057, grad_fn=<SubBackward0>)\n",
      "squared loss: 768.2953963786827\n",
      "loss: 779.1948140693169\n",
      "penalty: 3.9358862632362595\n",
      "h_val:  tensor(2.7991, grad_fn=<SubBackward0>)\n",
      "squared loss: 767.2413343763263\n",
      "loss: 778.104203419074\n",
      "penalty: 3.917571494714008\n",
      "h_val:  tensor(2.6429, grad_fn=<SubBackward0>)\n",
      "squared loss: 766.2676806908435\n",
      "loss: 776.6945538380148\n",
      "penalty: 3.4924246107856423\n",
      "h_val:  tensor(2.1522, grad_fn=<SubBackward0>)\n",
      "squared loss: 764.7787053280565\n",
      "loss: 774.0326405799206\n",
      "penalty: 2.3160558762448304\n",
      "h_val:  tensor(1.5188, grad_fn=<SubBackward0>)\n",
      "squared loss: 761.8937923454301\n",
      "loss: 770.0208616973152\n",
      "penalty: 1.153449272853252\n",
      "h_val:  tensor(1.6288, grad_fn=<SubBackward0>)\n",
      "squared loss: 760.6356088257639\n",
      "loss: 768.981722852913\n",
      "penalty: 1.3264190768072484\n",
      "h_val:  tensor(1.5530, grad_fn=<SubBackward0>)\n",
      "squared loss: 760.3914592689295\n",
      "loss: 768.5989888299268\n",
      "penalty: 1.205861461774524\n",
      "h_val:  tensor(1.5586, grad_fn=<SubBackward0>)\n",
      "squared loss: 760.2199935209195\n",
      "loss: 768.4407084183404\n",
      "penalty: 1.2145905159921941\n",
      "h_val:  tensor(1.6116, grad_fn=<SubBackward0>)\n",
      "squared loss: 759.7383345196988\n",
      "loss: 768.0547516049174\n",
      "penalty: 1.2986927074062993\n",
      "h_val:  tensor(1.6611, grad_fn=<SubBackward0>)\n",
      "squared loss: 759.1450615368811\n",
      "loss: 767.5509343652466\n",
      "penalty: 1.3796239996238455\n",
      "h_val:  tensor(1.8448, grad_fn=<SubBackward0>)\n",
      "squared loss: 760.6489895602774\n",
      "loss: 769.3970359912755\n",
      "penalty: 1.7015977336763966\n",
      "h_val:  tensor(1.7044, grad_fn=<SubBackward0>)\n",
      "squared loss: 758.6246574327154\n",
      "loss: 767.1100215238199\n",
      "penalty: 1.4524656066352692\n",
      "h_val:  tensor(1.6903, grad_fn=<SubBackward0>)\n",
      "squared loss: 757.6767782560995\n",
      "loss: 766.1399569624192\n",
      "penalty: 1.428611500349625\n",
      "h_val:  tensor(1.5587, grad_fn=<SubBackward0>)\n",
      "squared loss: 756.5967943790532\n",
      "loss: 764.8382672053956\n",
      "penalty: 1.2147744816037747\n",
      "h_val:  tensor(1.2947, grad_fn=<SubBackward0>)\n",
      "squared loss: 754.3531303502847\n",
      "loss: 762.2005386686792\n",
      "penalty: 0.8381574110029337\n",
      "h_val:  tensor(1.1044, grad_fn=<SubBackward0>)\n",
      "squared loss: 753.9764300486096\n",
      "loss: 761.5681579685096\n",
      "penalty: 0.6098848671960264\n",
      "h_val:  tensor(1.1128, grad_fn=<SubBackward0>)\n",
      "squared loss: 753.6309627859654\n",
      "loss: 761.2337556441116\n",
      "penalty: 0.6191178537115671\n",
      "h_val:  tensor(1.0826, grad_fn=<SubBackward0>)\n",
      "squared loss: 753.5215229907469\n",
      "loss: 761.0841453753984\n",
      "penalty: 0.5860458026257557\n",
      "h_val:  tensor(1.0376, grad_fn=<SubBackward0>)\n",
      "squared loss: 753.4287706511151\n",
      "loss: 760.9277052352379\n",
      "penalty: 0.5383553098497299\n",
      "h_val:  tensor(1.0307, grad_fn=<SubBackward0>)\n",
      "squared loss: 753.3874530401462\n",
      "loss: 760.877573539988\n",
      "penalty: 0.531148414863121\n",
      "h_val:  tensor(1.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 753.2694922322494\n",
      "loss: 760.7287209230101\n",
      "penalty: 0.5066789370292426\n",
      "h_val:  tensor(0.9623, grad_fn=<SubBackward0>)\n",
      "squared loss: 752.9226167668297\n",
      "loss: 760.3337383724136\n",
      "penalty: 0.46302755239982707\n",
      "h_val:  tensor(0.8859, grad_fn=<SubBackward0>)\n",
      "squared loss: 752.1568508394397\n",
      "loss: 759.500650987909\n",
      "penalty: 0.3924305033852726\n",
      "h_val:  tensor(0.8623, grad_fn=<SubBackward0>)\n",
      "squared loss: 751.5009028712101\n",
      "loss: 758.8345391649343\n",
      "penalty: 0.37177959914292635\n",
      "h_val:  tensor(0.8321, grad_fn=<SubBackward0>)\n",
      "squared loss: 750.9218941309128\n",
      "loss: 758.2305358386096\n",
      "penalty: 0.3461682249537856\n",
      "h_val:  tensor(0.8321, grad_fn=<SubBackward0>)\n",
      "squared loss: 750.5542776538517\n",
      "loss: 757.8734358997842\n",
      "penalty: 0.3462329933952722\n",
      "h_val:  tensor(0.7937, grad_fn=<SubBackward0>)\n",
      "squared loss: 750.1011372581276\n",
      "loss: 757.3858311694938\n",
      "penalty: 0.3150067607742109\n",
      "h_val:  tensor(0.7786, grad_fn=<SubBackward0>)\n",
      "squared loss: 749.6450672896009\n",
      "loss: 756.9139826247091\n",
      "penalty: 0.3030954234352679\n",
      "h_val:  tensor(0.8410, grad_fn=<SubBackward0>)\n",
      "squared loss: 747.4128886058294\n",
      "loss: 754.7174989309092\n",
      "penalty: 0.3536328978843373\n",
      "h_val:  tensor(0.7736, grad_fn=<SubBackward0>)\n",
      "squared loss: 748.7414360717521\n",
      "loss: 756.0012310161896\n",
      "penalty: 0.299237645673829\n",
      "h_val:  tensor(0.8167, grad_fn=<SubBackward0>)\n",
      "squared loss: 746.84867310181\n",
      "loss: 754.1353678144934\n",
      "penalty: 0.3335289041338043\n",
      "h_val:  tensor(0.7888, grad_fn=<SubBackward0>)\n",
      "squared loss: 748.0806376155964\n",
      "loss: 755.3533150495267\n",
      "penalty: 0.3110780885406605\n",
      "h_val:  tensor(0.8115, grad_fn=<SubBackward0>)\n",
      "squared loss: 746.7671778906213\n",
      "loss: 754.050671766878\n",
      "penalty: 0.3292711428493828\n",
      "h_val:  tensor(0.7983, grad_fn=<SubBackward0>)\n",
      "squared loss: 746.4074375177535\n",
      "loss: 753.6832163832374\n",
      "penalty: 0.31862600415312453\n",
      "h_val:  tensor(0.7996, grad_fn=<SubBackward0>)\n",
      "squared loss: 746.3146554315686\n",
      "loss: 753.5934531958695\n",
      "penalty: 0.31968148345385794\n",
      "h_val:  tensor(0.8159, grad_fn=<SubBackward0>)\n",
      "squared loss: 746.0220945088355\n",
      "loss: 753.323449903655\n",
      "penalty: 0.3328688180902289\n",
      "h_val:  tensor(0.8204, grad_fn=<SubBackward0>)\n",
      "squared loss: 745.6991251691776\n",
      "loss: 753.003805375806\n",
      "penalty: 0.33651020233334145\n",
      "h_val:  tensor(0.8490, grad_fn=<SubBackward0>)\n",
      "squared loss: 744.4546380186486\n",
      "loss: 751.7837578019393\n",
      "penalty: 0.36040232626679164\n",
      "h_val:  tensor(0.8999, grad_fn=<SubBackward0>)\n",
      "squared loss: 742.6415252638695\n",
      "loss: 750.009388646868\n",
      "penalty: 0.4049165704625106\n",
      "h_val:  tensor(1.0123, grad_fn=<SubBackward0>)\n",
      "squared loss: 741.3493450445366\n",
      "loss: 748.8200592842567\n",
      "penalty: 0.5123795614693581\n",
      "h_val:  tensor(0.9855, grad_fn=<SubBackward0>)\n",
      "squared loss: 740.820222310268\n",
      "loss: 748.269997107114\n",
      "penalty: 0.48559739982943384\n",
      "h_val:  tensor(1.0064, grad_fn=<SubBackward0>)\n",
      "squared loss: 740.612400976813\n",
      "loss: 748.0854385174459\n",
      "penalty: 0.5064575610557089\n",
      "h_val:  tensor(1.0143, grad_fn=<SubBackward0>)\n",
      "squared loss: 740.5204627892142\n",
      "loss: 748.0024590144433\n",
      "penalty: 0.5144249016321891\n",
      "h_val:  tensor(1.0268, grad_fn=<SubBackward0>)\n",
      "squared loss: 740.2528181407048\n",
      "loss: 747.7492429525396\n",
      "penalty: 0.527121178426943\n",
      "h_val:  tensor(1.0370, grad_fn=<SubBackward0>)\n",
      "squared loss: 739.7745871803194\n",
      "loss: 747.2828996292665\n",
      "penalty: 0.5376707908589031\n",
      "h_val:  tensor(1.0397, grad_fn=<SubBackward0>)\n",
      "squared loss: 738.9159236855531\n",
      "loss: 746.4275373682088\n",
      "penalty: 0.5405286274876744\n",
      "h_val:  tensor(1.0227, grad_fn=<SubBackward0>)\n",
      "squared loss: 738.1915954517098\n",
      "loss: 745.6840300463277\n",
      "penalty: 0.5229733721023052\n",
      "h_val:  tensor(1.0065, grad_fn=<SubBackward0>)\n",
      "squared loss: 737.8558476388577\n",
      "loss: 745.3299531590758\n",
      "penalty: 0.5065419774261356\n",
      "h_val:  tensor(0.9962, grad_fn=<SubBackward0>)\n",
      "squared loss: 737.6097625282293\n",
      "loss: 745.0703312166299\n",
      "penalty: 0.49622693436025184\n",
      "h_val:  tensor(1.0012, grad_fn=<SubBackward0>)\n",
      "squared loss: 737.567503580986\n",
      "loss: 745.0328029967584\n",
      "penalty: 0.5011815568213065\n",
      "h_val:  tensor(1.0183, grad_fn=<SubBackward0>)\n",
      "squared loss: 737.4600893416273\n",
      "loss: 744.9429490903711\n",
      "penalty: 0.5184171561702304\n",
      "h_val:  tensor(1.0478, grad_fn=<SubBackward0>)\n",
      "squared loss: 737.3225154124012\n",
      "loss: 744.8370723518049\n",
      "penalty: 0.5489425814359835\n",
      "h_val:  tensor(1.0724, grad_fn=<SubBackward0>)\n",
      "squared loss: 737.2245640782951\n",
      "loss: 744.7666607266243\n",
      "penalty: 0.5749998285332393\n",
      "h_val:  tensor(1.0828, grad_fn=<SubBackward0>)\n",
      "squared loss: 737.1676146892206\n",
      "loss: 744.7220571508816\n",
      "penalty: 0.586220035913667\n",
      "h_val:  tensor(1.0886, grad_fn=<SubBackward0>)\n",
      "squared loss: 737.1031346271795\n",
      "loss: 744.6654039876893\n",
      "penalty: 0.5925756000307564\n",
      "h_val:  tensor(1.0906, grad_fn=<SubBackward0>)\n",
      "squared loss: 737.0293291458938\n",
      "loss: 744.5956366545824\n",
      "penalty: 0.5947121587668887\n",
      "h_val:  tensor(1.0887, grad_fn=<SubBackward0>)\n",
      "squared loss: 736.9664370519329\n",
      "loss: 744.5324730356472\n",
      "penalty: 0.5926659395356448\n",
      "h_val:  tensor(1.0862, grad_fn=<SubBackward0>)\n",
      "squared loss: 736.9308063572139\n",
      "loss: 744.4950940247597\n",
      "penalty: 0.5899669926744909\n",
      "h_val:  tensor(1.0860, grad_fn=<SubBackward0>)\n",
      "squared loss: 736.9116637463894\n",
      "loss: 744.4760300657472\n",
      "penalty: 0.5897373871712795\n",
      "h_val:  tensor(1.0881, grad_fn=<SubBackward0>)\n",
      "squared loss: 736.8945179295739\n",
      "loss: 744.4612210419269\n",
      "penalty: 0.5919897892985349\n",
      "h_val:  tensor(1.0924, grad_fn=<SubBackward0>)\n",
      "squared loss: 736.8642904780869\n",
      "loss: 744.4358119723121\n",
      "penalty: 0.5966715884459494\n",
      "h_val:  tensor(1.1023, grad_fn=<SubBackward0>)\n",
      "squared loss: 736.7952822355826\n",
      "loss: 744.3782194203918\n",
      "penalty: 0.6075215458712986\n",
      "h_val:  tensor(1.1240, grad_fn=<SubBackward0>)\n",
      "squared loss: 736.6435184364801\n",
      "loss: 744.2523924147349\n",
      "penalty: 0.6316374872721432\n",
      "h_val:  tensor(1.1680, grad_fn=<SubBackward0>)\n",
      "squared loss: 736.351166216722\n",
      "loss: 744.015190607552\n",
      "penalty: 0.6821282032069838\n",
      "h_val:  tensor(1.2287, grad_fn=<SubBackward0>)\n",
      "squared loss: 735.9913293504353\n",
      "loss: 743.7357039018742\n",
      "penalty: 0.7549121862996014\n",
      "h_val:  tensor(1.2576, grad_fn=<SubBackward0>)\n",
      "squared loss: 735.7885427510017\n",
      "loss: 743.5739863409984\n",
      "penalty: 0.7908414341316164\n",
      "h_val:  tensor(1.2543, grad_fn=<SubBackward0>)\n",
      "squared loss: 735.7009112798664\n",
      "loss: 743.4841193603817\n",
      "penalty: 0.7866819133459328\n",
      "h_val:  tensor(1.2437, grad_fn=<SubBackward0>)\n",
      "squared loss: 735.6600770809606\n",
      "loss: 743.4307955456426\n",
      "penalty: 0.7733600380012535\n",
      "h_val:  tensor(1.2370, grad_fn=<SubBackward0>)\n",
      "squared loss: 735.6079413026687\n",
      "loss: 743.3717576187687\n",
      "penalty: 0.7650546473658946\n",
      "h_val:  tensor(1.2343, grad_fn=<SubBackward0>)\n",
      "squared loss: 735.4930515993073\n",
      "loss: 743.2569052037737\n",
      "penalty: 0.7616922891896254\n",
      "h_val:  tensor(1.2438, grad_fn=<SubBackward0>)\n",
      "squared loss: 735.3222817012685\n",
      "loss: 743.1033834153758\n",
      "penalty: 0.7734896060282175\n",
      "h_val:  tensor(1.2684, grad_fn=<SubBackward0>)\n",
      "squared loss: 735.1415356348743\n",
      "loss: 742.9596557137326\n",
      "penalty: 0.8044716794875459\n",
      "h_val:  tensor(1.2997, grad_fn=<SubBackward0>)\n",
      "squared loss: 734.9936031581645\n",
      "loss: 742.8562703450182\n",
      "penalty: 0.8446504566392601\n",
      "h_val:  tensor(1.3327, grad_fn=<SubBackward0>)\n",
      "squared loss: 734.8510095603971\n",
      "loss: 742.7598659544024\n",
      "penalty: 0.8880528061958471\n",
      "h_val:  tensor(1.3680, grad_fn=<SubBackward0>)\n",
      "squared loss: 734.6722646373271\n",
      "loss: 742.6307602424096\n",
      "penalty: 0.9357301624398148\n",
      "h_val:  tensor(1.4110, grad_fn=<SubBackward0>)\n",
      "squared loss: 734.379656702359\n",
      "loss: 742.4004679745738\n",
      "penalty: 0.9954914668817709\n",
      "h_val:  tensor(1.4895, grad_fn=<SubBackward0>)\n",
      "squared loss: 733.7440459411021\n",
      "loss: 741.8860383854641\n",
      "penalty: 1.10933662041113\n",
      "h_val:  tensor(1.6225, grad_fn=<SubBackward0>)\n",
      "squared loss: 732.6333707865585\n",
      "loss: 740.9993833578793\n",
      "penalty: 1.3162625950431133\n",
      "h_val:  tensor(1.7312, grad_fn=<SubBackward0>)\n",
      "squared loss: 731.5771747522466\n",
      "loss: 740.144946437793\n",
      "penalty: 1.4985216369584062\n",
      "h_val:  tensor(1.7474, grad_fn=<SubBackward0>)\n",
      "squared loss: 730.9519194871432\n",
      "loss: 739.5597513290764\n",
      "penalty: 1.5267362893061192\n",
      "h_val:  tensor(1.7633, grad_fn=<SubBackward0>)\n",
      "squared loss: 730.555149345708\n",
      "loss: 739.2015974995446\n",
      "penalty: 1.5546712032970713\n",
      "h_val:  tensor(1.8165, grad_fn=<SubBackward0>)\n",
      "squared loss: 730.1393988946351\n",
      "loss: 738.8956843857808\n",
      "penalty: 1.649792439632772\n",
      "h_val:  tensor(1.8951, grad_fn=<SubBackward0>)\n",
      "squared loss: 729.6027233319728\n",
      "loss: 738.5225267294354\n",
      "penalty: 1.7956283533244148\n",
      "h_val:  tensor(2.0173, grad_fn=<SubBackward0>)\n",
      "squared loss: 728.6516261444577\n",
      "loss: 737.8351592229054\n",
      "penalty: 2.034707604992753\n",
      "h_val:  tensor(2.2500, grad_fn=<SubBackward0>)\n",
      "squared loss: 726.7230391395686\n",
      "loss: 736.4418650319402\n",
      "penalty: 2.5313319076041334\n",
      "h_val:  tensor(2.4397, grad_fn=<SubBackward0>)\n",
      "squared loss: 725.1319596031925\n",
      "loss: 735.3225911708327\n",
      "penalty: 2.9760650779834634\n",
      "h_val:  tensor(2.2589, grad_fn=<SubBackward0>)\n",
      "squared loss: 724.537171005946\n",
      "loss: 734.2864276018082\n",
      "penalty: 2.5513838775771536\n",
      "h_val:  tensor(2.1067, grad_fn=<SubBackward0>)\n",
      "squared loss: 723.3345364215295\n",
      "loss: 732.7263928484261\n",
      "penalty: 2.2191813118598698\n",
      "h_val:  tensor(2.0134, grad_fn=<SubBackward0>)\n",
      "squared loss: 721.3310758422828\n",
      "loss: 730.4825482258774\n",
      "penalty: 2.026874630805416\n",
      "h_val:  tensor(2.1905, grad_fn=<SubBackward0>)\n",
      "squared loss: 720.1912090877539\n",
      "loss: 729.7467779573653\n",
      "penalty: 2.3991844938348046\n",
      "h_val:  tensor(2.4443, grad_fn=<SubBackward0>)\n",
      "squared loss: 718.5796253903785\n",
      "loss: 728.7416296849009\n",
      "penalty: 2.987193247958841\n",
      "h_val:  tensor(3.3920, grad_fn=<SubBackward0>)\n",
      "squared loss: 713.6866106769015\n",
      "loss: 726.6687541320824\n",
      "penalty: 5.752685546704027\n",
      "h_val:  tensor(3.4976, grad_fn=<SubBackward0>)\n",
      "squared loss: 712.8282831221018\n",
      "loss: 726.1809782227891\n",
      "penalty: 6.116486401848263\n",
      "h_val:  tensor(3.4664, grad_fn=<SubBackward0>)\n",
      "squared loss: 712.7360584502488\n",
      "loss: 725.9804067269447\n",
      "penalty: 6.007946932561606\n",
      "h_val:  tensor(3.4694, grad_fn=<SubBackward0>)\n",
      "squared loss: 712.4971652968217\n",
      "loss: 725.7552033320434\n",
      "penalty: 6.018416875033939\n",
      "h_val:  tensor(3.4373, grad_fn=<SubBackward0>)\n",
      "squared loss: 712.3617765306931\n",
      "loss: 725.5115281035573\n",
      "penalty: 5.907625907622887\n",
      "h_val:  tensor(3.4487, grad_fn=<SubBackward0>)\n",
      "squared loss: 712.1356246081082\n",
      "loss: 725.3293267979758\n",
      "penalty: 5.946905831538261\n",
      "h_val:  tensor(3.4548, grad_fn=<SubBackward0>)\n",
      "squared loss: 711.9940738860168\n",
      "loss: 725.2121134056946\n",
      "penalty: 5.96787934435622\n",
      "h_val:  tensor(3.4734, grad_fn=<SubBackward0>)\n",
      "squared loss: 711.8363921585791\n",
      "loss: 725.1217576383339\n",
      "penalty: 6.032212273988695\n",
      "h_val:  tensor(3.4881, grad_fn=<SubBackward0>)\n",
      "squared loss: 711.6176462592119\n",
      "loss: 724.9575081910928\n",
      "penalty: 6.0835657422648834\n",
      "h_val:  tensor(3.5308, grad_fn=<SubBackward0>)\n",
      "squared loss: 711.0422927504302\n",
      "loss: 724.5385913143796\n",
      "penalty: 6.233180200555142\n",
      "h_val:  tensor(3.6138, grad_fn=<SubBackward0>)\n",
      "squared loss: 709.6625484394591\n",
      "loss: 723.4695986433397\n",
      "penalty: 6.529766631141439\n",
      "h_val:  tensor(3.8327, grad_fn=<SubBackward0>)\n",
      "squared loss: 706.0402326165997\n",
      "loss: 720.6955248845924\n",
      "penalty: 7.344698309441454\n",
      "h_val:  tensor(4.7383, grad_fn=<SubBackward0>)\n",
      "squared loss: 698.9920606108507\n",
      "loss: 717.6303365348646\n",
      "penalty: 11.225836228571582\n",
      "h_val:  tensor(4.5765, grad_fn=<SubBackward0>)\n",
      "squared loss: 695.1393924554369\n",
      "loss: 713.0177615995755\n",
      "penalty: 10.472062777663837\n",
      "h_val:  tensor(4.7876, grad_fn=<SubBackward0>)\n",
      "squared loss: 690.0827663879633\n",
      "loss: 708.981016317094\n",
      "penalty: 11.460633242033467\n",
      "h_val:  tensor(4.9347, grad_fn=<SubBackward0>)\n",
      "squared loss: 688.5325323947668\n",
      "loss: 708.163270969448\n",
      "penalty: 12.175705583053565\n",
      "h_val:  tensor(4.9559, grad_fn=<SubBackward0>)\n",
      "squared loss: 688.2081853761795\n",
      "loss: 707.9472608968551\n",
      "penalty: 12.280573278428022\n",
      "h_val:  tensor(4.9133, grad_fn=<SubBackward0>)\n",
      "squared loss: 688.0999200178153\n",
      "loss: 707.6269528696774\n",
      "penalty: 12.070129960825849\n",
      "h_val:  tensor(4.7447, grad_fn=<SubBackward0>)\n",
      "squared loss: 688.2511253704014\n",
      "loss: 706.951982286466\n",
      "penalty: 11.256059570397005\n",
      "h_val:  tensor(4.3686, grad_fn=<SubBackward0>)\n",
      "squared loss: 689.0143060364348\n",
      "loss: 705.9671619893732\n",
      "penalty: 9.542439811934587\n",
      "h_val:  tensor(4.2987, grad_fn=<SubBackward0>)\n",
      "squared loss: 688.9406944068322\n",
      "loss: 705.5818232464453\n",
      "penalty: 9.23948388619492\n",
      "h_val:  tensor(4.2691, grad_fn=<SubBackward0>)\n",
      "squared loss: 688.4579793933756\n",
      "loss: 704.9612655598796\n",
      "penalty: 9.112815902874662\n",
      "h_val:  tensor(4.2350, grad_fn=<SubBackward0>)\n",
      "squared loss: 688.3828236715942\n",
      "loss: 704.7401047861549\n",
      "penalty: 8.967803171443567\n",
      "h_val:  tensor(4.2460, grad_fn=<SubBackward0>)\n",
      "squared loss: 688.26572366931\n",
      "loss: 704.6713117255176\n",
      "penalty: 9.014275239032177\n",
      "h_val:  tensor(4.2911, grad_fn=<SubBackward0>)\n",
      "squared loss: 687.850180264458\n",
      "loss: 704.4556906167184\n",
      "penalty: 9.206853112473395\n",
      "h_val:  tensor(4.3534, grad_fn=<SubBackward0>)\n",
      "squared loss: 686.4755301753302\n",
      "loss: 703.3689658999816\n",
      "penalty: 9.475940733311324\n",
      "h_val:  tensor(4.6067, grad_fn=<SubBackward0>)\n",
      "squared loss: 681.6461900278975\n",
      "loss: 699.7527301181924\n",
      "penalty: 10.610679796424268\n",
      "h_val:  tensor(4.8131, grad_fn=<SubBackward0>)\n",
      "squared loss: 678.3360059060072\n",
      "loss: 697.4787060417295\n",
      "penalty: 11.583094131575177\n",
      "h_val:  tensor(4.6044, grad_fn=<SubBackward0>)\n",
      "squared loss: 676.5862391119813\n",
      "loss: 694.7617220563124\n",
      "penalty: 10.600312984218348\n",
      "h_val:  tensor(2.9630, grad_fn=<SubBackward0>)\n",
      "squared loss: 679.574475772554\n",
      "loss: 691.523689229041\n",
      "penalty: 4.389832647475878\n",
      "h_val:  tensor(3.9376, grad_fn=<SubBackward0>)\n",
      "squared loss: 673.765450221896\n",
      "loss: 689.0873620554071\n",
      "penalty: 7.7524531418289495\n",
      "h_val:  tensor(2.6104, grad_fn=<SubBackward0>)\n",
      "squared loss: 687.285992699449\n",
      "loss: 698.2396474928954\n",
      "penalty: 3.407067003558644\n",
      "h_val:  tensor(3.3719, grad_fn=<SubBackward0>)\n",
      "squared loss: 672.2212178493984\n",
      "loss: 685.4666474246555\n",
      "penalty: 5.684736076246864\n",
      "h_val:  tensor(3.0323, grad_fn=<SubBackward0>)\n",
      "squared loss: 669.1733829190056\n",
      "loss: 681.3542771775022\n",
      "penalty: 4.597322718241268\n",
      "h_val:  tensor(2.1809, grad_fn=<SubBackward0>)\n",
      "squared loss: 646.3100100335083\n",
      "loss: 656.4656426147124\n",
      "penalty: 2.378234837821441\n",
      "h_val:  tensor(2.4605, grad_fn=<SubBackward0>)\n",
      "squared loss: 634.7102306499553\n",
      "loss: 645.6931093711934\n",
      "penalty: 3.0270901859258634\n",
      "h_val:  tensor(3.3275, grad_fn=<SubBackward0>)\n",
      "squared loss: 628.4333287653451\n",
      "loss: 642.084161618343\n",
      "penalty: 5.536270501146715\n",
      "h_val:  tensor(4.5390, grad_fn=<SubBackward0>)\n",
      "squared loss: 622.4978301902869\n",
      "loss: 641.0258537768549\n",
      "penalty: 10.301322738664457\n",
      "h_val:  tensor(4.1726, grad_fn=<SubBackward0>)\n",
      "squared loss: 622.4413331097326\n",
      "loss: 639.3400068806349\n",
      "penalty: 8.705490302354297\n",
      "h_val:  tensor(4.5908, grad_fn=<SubBackward0>)\n",
      "squared loss: 618.685308203124\n",
      "loss: 637.4451121485722\n",
      "penalty: 10.53793526492898\n",
      "h_val:  tensor(5.0025, grad_fn=<SubBackward0>)\n",
      "squared loss: 615.4282152844274\n",
      "loss: 636.189456278154\n",
      "penalty: 12.512600662164703\n",
      "h_val:  tensor(5.3757, grad_fn=<SubBackward0>)\n",
      "squared loss: 611.6421460585901\n",
      "loss: 634.3654597014204\n",
      "penalty: 14.44907749844194\n",
      "h_val:  tensor(5.5851, grad_fn=<SubBackward0>)\n",
      "squared loss: 608.1322176890922\n",
      "loss: 632.0212762915882\n",
      "penalty: 15.596660335492794\n",
      "h_val:  tensor(5.7388, grad_fn=<SubBackward0>)\n",
      "squared loss: 603.9885987927597\n",
      "loss: 628.7650407789566\n",
      "penalty: 16.467158188062115\n",
      "h_val:  tensor(6.0081, grad_fn=<SubBackward0>)\n",
      "squared loss: 593.441100460919\n",
      "loss: 619.8350194314006\n",
      "penalty: 18.048490206500585\n",
      "h_val:  tensor(6.1203, grad_fn=<SubBackward0>)\n",
      "squared loss: 581.2309361540931\n",
      "loss: 608.337857362444\n",
      "penalty: 18.729112594303494\n",
      "h_val:  tensor(7.4580, grad_fn=<SubBackward0>)\n",
      "squared loss: 563.7763715409762\n",
      "loss: 600.0570369649541\n",
      "penalty: 27.810839015488494\n",
      "h_val:  tensor(6.1429, grad_fn=<SubBackward0>)\n",
      "squared loss: 570.3337212073553\n",
      "loss: 597.6232974144909\n",
      "penalty: 18.86781368806031\n",
      "h_val:  tensor(6.1768, grad_fn=<SubBackward0>)\n",
      "squared loss: 569.11281018798\n",
      "loss: 596.6241532260502\n",
      "penalty: 19.076329116658375\n",
      "h_val:  tensor(6.3067, grad_fn=<SubBackward0>)\n",
      "squared loss: 566.2511419531593\n",
      "loss: 594.6102233759301\n",
      "penalty: 19.88717758935123\n",
      "h_val:  tensor(6.2516, grad_fn=<SubBackward0>)\n",
      "squared loss: 565.227670751496\n",
      "loss: 593.2633131711289\n",
      "penalty: 19.541424918802143\n",
      "h_val:  tensor(6.0664, grad_fn=<SubBackward0>)\n",
      "squared loss: 564.9952047696139\n",
      "loss: 591.9074981566996\n",
      "penalty: 18.400697061501333\n",
      "h_val:  tensor(5.8986, grad_fn=<SubBackward0>)\n",
      "squared loss: 564.5384352694143\n",
      "loss: 590.4544692692095\n",
      "penalty: 17.396553905350636\n",
      "h_val:  tensor(5.6532, grad_fn=<SubBackward0>)\n",
      "squared loss: 561.7250547136489\n",
      "loss: 586.2363497568101\n",
      "penalty: 15.97937962052976\n",
      "h_val:  tensor(5.7972, grad_fn=<SubBackward0>)\n",
      "squared loss: 560.6536734384439\n",
      "loss: 586.0014546345584\n",
      "penalty: 16.80390707588887\n",
      "h_val:  tensor(5.7039, grad_fn=<SubBackward0>)\n",
      "squared loss: 559.5828302576242\n",
      "loss: 584.3864687321607\n",
      "penalty: 16.26697415967884\n",
      "h_val:  tensor(6.0641, grad_fn=<SubBackward0>)\n",
      "squared loss: 556.4308981193799\n",
      "loss: 583.3659806318726\n",
      "penalty: 18.3865519275004\n",
      "h_val:  tensor(6.3326, grad_fn=<SubBackward0>)\n",
      "squared loss: 553.7606193587441\n",
      "loss: 582.369903928415\n",
      "penalty: 20.050707921872036\n",
      "h_val:  tensor(6.8989, grad_fn=<SubBackward0>)\n",
      "squared loss: 547.3525825121625\n",
      "loss: 579.7364020538103\n",
      "penalty: 23.797493526560544\n",
      "h_val:  tensor(7.2898, grad_fn=<SubBackward0>)\n",
      "squared loss: 542.2419501123672\n",
      "loss: 577.4333128502207\n",
      "penalty: 26.57075700406722\n",
      "h_val:  tensor(7.4345, grad_fn=<SubBackward0>)\n",
      "squared loss: 538.0806577652783\n",
      "loss: 574.3792953555683\n",
      "penalty: 27.63574562911716\n",
      "h_val:  tensor(7.1436, grad_fn=<SubBackward0>)\n",
      "squared loss: 537.5994589018624\n",
      "loss: 571.8070805827081\n",
      "penalty: 25.515413571695007\n",
      "h_val:  tensor(6.6667, grad_fn=<SubBackward0>)\n",
      "squared loss: 539.5032461499083\n",
      "loss: 570.4226297826717\n",
      "penalty: 22.222716220806454\n",
      "h_val:  tensor(6.1038, grad_fn=<SubBackward0>)\n",
      "squared loss: 541.7603088511147\n",
      "loss: 569.0773660220729\n",
      "penalty: 18.627929883407234\n",
      "h_val:  tensor(5.3483, grad_fn=<SubBackward0>)\n",
      "squared loss: 543.4671318371757\n",
      "loss: 566.4444151442345\n",
      "penalty: 14.302046829082748\n",
      "h_val:  tensor(4.4160, grad_fn=<SubBackward0>)\n",
      "squared loss: 544.0586742902616\n",
      "loss: 562.4667949317007\n",
      "penalty: 9.750585167093002\n",
      "h_val:  tensor(3.7925, grad_fn=<SubBackward0>)\n",
      "squared loss: 543.4937527052182\n",
      "loss: 559.335964149891\n",
      "penalty: 7.191452686396046\n",
      "h_val:  tensor(3.3539, grad_fn=<SubBackward0>)\n",
      "squared loss: 541.6333525027758\n",
      "loss: 555.9151035305298\n",
      "penalty: 5.624407762143242\n",
      "h_val:  tensor(2.9982, grad_fn=<SubBackward0>)\n",
      "squared loss: 536.8069762908211\n",
      "loss: 549.9878505979366\n",
      "penalty: 4.494698540174605\n",
      "h_val:  tensor(3.0595, grad_fn=<SubBackward0>)\n",
      "squared loss: 525.8861318432611\n",
      "loss: 539.3191441219645\n",
      "penalty: 4.680190741396647\n",
      "h_val:  tensor(4.6634, grad_fn=<SubBackward0>)\n",
      "squared loss: 493.44949749197315\n",
      "loss: 513.2743168016574\n",
      "penalty: 10.873498939068742\n",
      "h_val:  tensor(8.4565, grad_fn=<SubBackward0>)\n",
      "squared loss: 464.38632510084244\n",
      "loss: 509.30881366091285\n",
      "penalty: 35.75596157336089\n",
      "h_val:  tensor(6.1522, grad_fn=<SubBackward0>)\n",
      "squared loss: 476.01185257842764\n",
      "loss: 503.98775820213046\n",
      "penalty: 18.924567896475626\n",
      "h_val:  tensor(6.8747, grad_fn=<SubBackward0>)\n",
      "squared loss: 465.9025465462821\n",
      "loss: 498.6273389461518\n",
      "penalty: 23.63080637049731\n",
      "h_val:  tensor(7.4204, grad_fn=<SubBackward0>)\n",
      "squared loss: 446.82544121282706\n",
      "loss: 483.48827379814765\n",
      "penalty: 27.530971711725744\n",
      "h_val:  tensor(6.8882, grad_fn=<SubBackward0>)\n",
      "squared loss: 444.4747976738779\n",
      "loss: 477.3321243102118\n",
      "penalty: 23.72354783400263\n",
      "h_val:  tensor(7.1300, grad_fn=<SubBackward0>)\n",
      "squared loss: 437.5017213835632\n",
      "loss: 472.0528301948355\n",
      "penalty: 25.418345466940394\n",
      "h_val:  tensor(6.6270, grad_fn=<SubBackward0>)\n",
      "squared loss: 434.6502866411496\n",
      "loss: 465.740720820719\n",
      "penalty: 21.958306001512074\n",
      "h_val:  tensor(6.5090, grad_fn=<SubBackward0>)\n",
      "squared loss: 431.63288457612236\n",
      "loss: 461.9600532321967\n",
      "penalty: 21.18357032009871\n",
      "h_val:  tensor(6.4257, grad_fn=<SubBackward0>)\n",
      "squared loss: 431.9236013574513\n",
      "loss: 461.70947000986797\n",
      "penalty: 20.644540292589053\n",
      "h_val:  tensor(6.2232, grad_fn=<SubBackward0>)\n",
      "squared loss: 432.6970668186532\n",
      "loss: 461.19749278951946\n",
      "penalty: 19.364395672312728\n",
      "h_val:  tensor(5.8656, grad_fn=<SubBackward0>)\n",
      "squared loss: 433.7904861558096\n",
      "loss: 460.1231360618673\n",
      "penalty: 17.20259606046468\n",
      "h_val:  tensor(5.1885, grad_fn=<SubBackward0>)\n",
      "squared loss: 435.24670895498565\n",
      "loss: 457.82851578122944\n",
      "penalty: 13.46036982753487\n",
      "h_val:  tensor(4.3550, grad_fn=<SubBackward0>)\n",
      "squared loss: 435.80351806534554\n",
      "loss: 454.4083218116926\n",
      "penalty: 9.482883300969688\n",
      "h_val:  tensor(3.5955, grad_fn=<SubBackward0>)\n",
      "squared loss: 436.4721353600291\n",
      "loss: 452.05737945138935\n",
      "penalty: 6.463675888054435\n",
      "h_val:  tensor(3.5170, grad_fn=<SubBackward0>)\n",
      "squared loss: 435.9174398886371\n",
      "loss: 451.23349839900965\n",
      "penalty: 6.184597057934099\n",
      "h_val:  tensor(3.6577, grad_fn=<SubBackward0>)\n",
      "squared loss: 435.01201001611946\n",
      "loss: 450.83724429481737\n",
      "penalty: 6.689526766041576\n",
      "h_val:  tensor(3.9247, grad_fn=<SubBackward0>)\n",
      "squared loss: 433.36929832837524\n",
      "loss: 450.2155582411559\n",
      "penalty: 7.701638869492253\n",
      "h_val:  tensor(4.1165, grad_fn=<SubBackward0>)\n",
      "squared loss: 431.69721154952305\n",
      "loss: 449.32463174512077\n",
      "penalty: 8.472870497433144\n",
      "h_val:  tensor(4.4952, grad_fn=<SubBackward0>)\n",
      "squared loss: 426.64052079785\n",
      "loss: 445.9326245421403\n",
      "penalty: 10.103623078262197\n",
      "h_val:  tensor(4.8210, grad_fn=<SubBackward0>)\n",
      "squared loss: 417.3468487805195\n",
      "loss: 438.2274233059427\n",
      "penalty: 11.621128666980269\n",
      "h_val:  tensor(4.9319, grad_fn=<SubBackward0>)\n",
      "squared loss: 400.54386761565337\n",
      "loss: 422.1239867334771\n",
      "penalty: 12.161879784841675\n",
      "h_val:  tensor(4.7825, grad_fn=<SubBackward0>)\n",
      "squared loss: 387.6508125460854\n",
      "loss: 408.65671493330865\n",
      "penalty: 11.43611663325648\n",
      "h_val:  tensor(4.4405, grad_fn=<SubBackward0>)\n",
      "squared loss: 382.82762066756885\n",
      "loss: 402.3418924665218\n",
      "penalty: 9.859163539481882\n",
      "h_val:  tensor(4.0783, grad_fn=<SubBackward0>)\n",
      "squared loss: 382.1504515269666\n",
      "loss: 400.17178025089515\n",
      "penalty: 8.316351803632715\n",
      "h_val:  tensor(3.7769, grad_fn=<SubBackward0>)\n",
      "squared loss: 382.3875454882182\n",
      "loss: 399.2522268632837\n",
      "penalty: 7.132595395346686\n",
      "h_val:  tensor(3.5370, grad_fn=<SubBackward0>)\n",
      "squared loss: 382.44873703129736\n",
      "loss: 398.46102639220885\n",
      "penalty: 6.255255688892781\n",
      "h_val:  tensor(3.2686, grad_fn=<SubBackward0>)\n",
      "squared loss: 382.10234769403763\n",
      "loss: 397.2437264948784\n",
      "penalty: 5.3417489486170115\n",
      "h_val:  tensor(3.0465, grad_fn=<SubBackward0>)\n",
      "squared loss: 380.46459705756314\n",
      "loss: 394.90713407272176\n",
      "penalty: 4.640434272326185\n",
      "h_val:  tensor(2.9035, grad_fn=<SubBackward0>)\n",
      "squared loss: 364.5503100626714\n",
      "loss: 378.5289146212008\n",
      "penalty: 4.215286306448994\n",
      "h_val:  tensor(5.1707, grad_fn=<SubBackward0>)\n",
      "squared loss: 374.79940826366686\n",
      "loss: 397.8682005377502\n",
      "penalty: 13.36808329631139\n",
      "h_val:  tensor(3.1823, grad_fn=<SubBackward0>)\n",
      "squared loss: 361.56963223737216\n",
      "loss: 376.38220856741657\n",
      "penalty: 5.063648275982626\n",
      "h_val:  tensor(3.5430, grad_fn=<SubBackward0>)\n",
      "squared loss: 356.69213978689805\n",
      "loss: 372.7663627910367\n",
      "penalty: 6.276554395802686\n",
      "h_val:  tensor(5.4241, grad_fn=<SubBackward0>)\n",
      "squared loss: 337.0193904857828\n",
      "loss: 361.7513731630599\n",
      "penalty: 14.710284843240567\n",
      "h_val:  tensor(5.6214, grad_fn=<SubBackward0>)\n",
      "squared loss: 323.2999116575674\n",
      "loss: 349.32135836846845\n",
      "penalty: 15.799937002759684\n",
      "h_val:  tensor(6.5257, grad_fn=<SubBackward0>)\n",
      "squared loss: 314.23743899438335\n",
      "loss: 345.88657091410295\n",
      "penalty: 21.29269445582913\n",
      "h_val:  tensor(5.8026, grad_fn=<SubBackward0>)\n",
      "squared loss: 314.74984645347706\n",
      "loss: 341.9523537620563\n",
      "penalty: 16.834808670190043\n",
      "h_val:  tensor(5.2518, grad_fn=<SubBackward0>)\n",
      "squared loss: 311.44100727718603\n",
      "loss: 335.64182133837414\n",
      "penalty: 13.790607636996516\n",
      "h_val:  tensor(4.3847, grad_fn=<SubBackward0>)\n",
      "squared loss: 305.1511875182239\n",
      "loss: 325.3179569134557\n",
      "penalty: 9.612658020470601\n",
      "h_val:  tensor(7.3769, grad_fn=<SubBackward0>)\n",
      "squared loss: 331.83843629643684\n",
      "loss: 370.28889147984967\n",
      "penalty: 27.20965765727071\n",
      "h_val:  tensor(3.7006, grad_fn=<SubBackward0>)\n",
      "squared loss: 292.8973436281945\n",
      "loss: 310.5284130444735\n",
      "penalty: 6.847356660675478\n",
      "h_val:  tensor(13.4579, grad_fn=<SubBackward0>)\n",
      "squared loss: 332.8103629205416\n",
      "loss: 434.7013664186432\n",
      "penalty: 90.55796701000254\n",
      "h_val:  tensor(3.9575, grad_fn=<SubBackward0>)\n",
      "squared loss: 290.66850906734356\n",
      "loss: 309.39108079612237\n",
      "penalty: 7.8310852220770775\n",
      "h_val:  tensor(4.0698, grad_fn=<SubBackward0>)\n",
      "squared loss: 284.76141356008753\n",
      "loss: 303.9240482752115\n",
      "penalty: 8.28183524609357\n",
      "h_val:  tensor(4.3933, grad_fn=<SubBackward0>)\n",
      "squared loss: 278.7037954707393\n",
      "loss: 299.25106864008586\n",
      "penalty: 9.650709670976422\n",
      "h_val:  tensor(4.5018, grad_fn=<SubBackward0>)\n",
      "squared loss: 276.9101550858783\n",
      "loss: 297.9592169595393\n",
      "penalty: 10.133017362909113\n",
      "h_val:  tensor(4.6111, grad_fn=<SubBackward0>)\n",
      "squared loss: 274.42274441124385\n",
      "loss: 296.0123603148554\n",
      "penalty: 10.630961314034735\n",
      "h_val:  tensor(4.5407, grad_fn=<SubBackward0>)\n",
      "squared loss: 272.94852993360644\n",
      "loss: 294.2477231224509\n",
      "penalty: 10.309056622752246\n",
      "h_val:  tensor(4.4348, grad_fn=<SubBackward0>)\n",
      "squared loss: 277.89213638386184\n",
      "loss: 298.88638812140107\n",
      "penalty: 9.833839879593341\n",
      "h_val:  tensor(4.3912, grad_fn=<SubBackward0>)\n",
      "squared loss: 271.79595046156123\n",
      "loss: 292.4791011539019\n",
      "penalty: 9.641429724495433\n",
      "h_val:  tensor(4.3529, grad_fn=<SubBackward0>)\n",
      "squared loss: 270.48191834811206\n",
      "loss: 291.0455848177412\n",
      "penalty: 9.473999715687748\n",
      "h_val:  tensor(4.1761, grad_fn=<SubBackward0>)\n",
      "squared loss: 270.81578387574825\n",
      "loss: 290.62693951072055\n",
      "penalty: 8.72003214939317\n",
      "h_val:  tensor(4.0291, grad_fn=<SubBackward0>)\n",
      "squared loss: 271.146925551444\n",
      "loss: 290.3482420932173\n",
      "penalty: 8.116911876631402\n",
      "h_val:  tensor(3.7979, grad_fn=<SubBackward0>)\n",
      "squared loss: 271.43285155995005\n",
      "loss: 289.7191445412774\n",
      "penalty: 7.21186460792593\n",
      "h_val:  tensor(3.3447, grad_fn=<SubBackward0>)\n",
      "squared loss: 271.36602280011203\n",
      "loss: 288.02026706717305\n",
      "penalty: 5.593604332204951\n",
      "h_val:  tensor(2.6886, grad_fn=<SubBackward0>)\n",
      "squared loss: 270.18434191175925\n",
      "loss: 284.8544772949156\n",
      "penalty: 3.6143109560726954\n",
      "h_val:  tensor(2.0416, grad_fn=<SubBackward0>)\n",
      "squared loss: 267.87474101133654\n",
      "loss: 281.03981724922943\n",
      "penalty: 2.0839883494381892\n",
      "h_val:  tensor(1.6949, grad_fn=<SubBackward0>)\n",
      "squared loss: 265.3481525243272\n",
      "loss: 277.93149576592964\n",
      "penalty: 1.4363166624511314\n",
      "h_val:  tensor(1.7694, grad_fn=<SubBackward0>)\n",
      "squared loss: 262.86653835437994\n",
      "loss: 275.6726291908447\n",
      "penalty: 1.56543065342401\n",
      "h_val:  tensor(2.4174, grad_fn=<SubBackward0>)\n",
      "squared loss: 260.53779688574514\n",
      "loss: 274.8306058645812\n",
      "penalty: 2.9218611210203758\n",
      "h_val:  tensor(2.1753, grad_fn=<SubBackward0>)\n",
      "squared loss: 260.262638989334\n",
      "loss: 273.96064726924766\n",
      "penalty: 2.365958321158453\n",
      "h_val:  tensor(1.9161, grad_fn=<SubBackward0>)\n",
      "squared loss: 259.1809792462237\n",
      "loss: 272.29270853394576\n",
      "penalty: 1.8357563755978525\n",
      "h_val:  tensor(1.7950, grad_fn=<SubBackward0>)\n",
      "squared loss: 257.2600656262476\n",
      "loss: 270.14019511435765\n",
      "penalty: 1.6109411308122443\n",
      "h_val:  tensor(1.5474, grad_fn=<SubBackward0>)\n",
      "squared loss: 251.8791697276468\n",
      "loss: 264.4042317863346\n",
      "penalty: 1.1971878158171791\n",
      "h_val:  tensor(1.8378, grad_fn=<SubBackward0>)\n",
      "squared loss: 247.2345329579269\n",
      "loss: 260.3471502829885\n",
      "penalty: 1.6887790062505252\n",
      "h_val:  tensor(5.7543, grad_fn=<SubBackward0>)\n",
      "squared loss: 235.00940764780563\n",
      "loss: 263.2505523127119\n",
      "penalty: 16.5557690388482\n",
      "h_val:  tensor(2.9351, grad_fn=<SubBackward0>)\n",
      "squared loss: 241.28687525983352\n",
      "loss: 257.1385506053029\n",
      "penalty: 4.3074532424157095\n",
      "h_val:  tensor(3.1534, grad_fn=<SubBackward0>)\n",
      "squared loss: 239.04585762573635\n",
      "loss: 255.5784563217571\n",
      "penalty: 4.972109598750512\n",
      "h_val:  tensor(2.8885, grad_fn=<SubBackward0>)\n",
      "squared loss: 241.14259320796398\n",
      "loss: 256.8467451112236\n",
      "penalty: 4.171632949933441\n",
      "h_val:  tensor(3.0198, grad_fn=<SubBackward0>)\n",
      "squared loss: 238.45225699204443\n",
      "loss: 254.561495873638\n",
      "penalty: 4.5596468160804875\n",
      "h_val:  tensor(2.7472, grad_fn=<SubBackward0>)\n",
      "squared loss: 239.0999270845468\n",
      "loss: 254.40233851733112\n",
      "penalty: 3.7735828920038186\n",
      "h_val:  tensor(2.1099, grad_fn=<SubBackward0>)\n",
      "squared loss: 240.91649918032326\n",
      "loss: 254.62499113927737\n",
      "penalty: 2.2257781536333323\n",
      "h_val:  tensor(2.4925, grad_fn=<SubBackward0>)\n",
      "squared loss: 239.56116163783594\n",
      "loss: 254.17942993174685\n",
      "penalty: 3.1063994067598815\n",
      "h_val:  tensor(2.6645, grad_fn=<SubBackward0>)\n",
      "squared loss: 238.74657452795898\n",
      "loss: 253.82401402635656\n",
      "penalty: 3.5496704674748556\n",
      "h_val:  tensor(2.8543, grad_fn=<SubBackward0>)\n",
      "squared loss: 237.34241746179953\n",
      "loss: 252.9676676378088\n",
      "penalty: 4.07361777020583\n",
      "h_val:  tensor(2.9246, grad_fn=<SubBackward0>)\n",
      "squared loss: 235.54490816235716\n",
      "loss: 251.40257385343585\n",
      "penalty: 4.276573695505916\n",
      "h_val:  tensor(2.7575, grad_fn=<SubBackward0>)\n",
      "squared loss: 234.55588041351655\n",
      "loss: 249.95753582927586\n",
      "penalty: 3.8019720892181303\n",
      "h_val:  tensor(2.5551, grad_fn=<SubBackward0>)\n",
      "squared loss: 234.16212570175693\n",
      "loss: 249.03249266094898\n",
      "penalty: 3.264183190360871\n",
      "h_val:  tensor(2.4335, grad_fn=<SubBackward0>)\n",
      "squared loss: 233.67304310903958\n",
      "loss: 248.24701116041857\n",
      "penalty: 2.960966397086758\n",
      "h_val:  tensor(2.4833, grad_fn=<SubBackward0>)\n",
      "squared loss: 233.46810191216832\n",
      "loss: 248.1678847202426\n",
      "penalty: 3.0833525614331183\n",
      "h_val:  tensor(2.4937, grad_fn=<SubBackward0>)\n",
      "squared loss: 233.20234122198178\n",
      "loss: 247.92754108659298\n",
      "penalty: 3.1093787628164624\n",
      "h_val:  tensor(2.5548, grad_fn=<SubBackward0>)\n",
      "squared loss: 232.51113900212388\n",
      "loss: 247.3969218380292\n",
      "penalty: 3.2635726137503998\n",
      "h_val:  tensor(2.6525, grad_fn=<SubBackward0>)\n",
      "squared loss: 230.8213430991244\n",
      "loss: 245.98908106590957\n",
      "penalty: 3.5178157922311235\n",
      "h_val:  tensor(2.7607, grad_fn=<SubBackward0>)\n",
      "squared loss: 227.45083978208157\n",
      "loss: 242.9869814661351\n",
      "penalty: 3.810866279844172\n",
      "h_val:  tensor(2.9675, grad_fn=<SubBackward0>)\n",
      "squared loss: 220.2805821391803\n",
      "loss: 236.6229691309627\n",
      "penalty: 4.403171165453528\n",
      "h_val:  tensor(3.1655, grad_fn=<SubBackward0>)\n",
      "squared loss: 215.69858277027015\n",
      "loss: 232.83232579998423\n",
      "penalty: 5.0103528276700064\n",
      "h_val:  tensor(2.8414, grad_fn=<SubBackward0>)\n",
      "squared loss: 212.2039591397154\n",
      "loss: 228.3228352636243\n",
      "penalty: 4.036751818123764\n",
      "h_val:  tensor(2.4234, grad_fn=<SubBackward0>)\n",
      "squared loss: 203.78561229364044\n",
      "loss: 218.87747534854972\n",
      "penalty: 2.936458716954866\n",
      "h_val:  tensor(2.8777, grad_fn=<SubBackward0>)\n",
      "squared loss: 199.30458860864172\n",
      "loss: 215.690112463242\n",
      "penalty: 4.1406666296068515\n",
      "h_val:  tensor(6.1282, grad_fn=<SubBackward0>)\n",
      "squared loss: 191.85213214794553\n",
      "loss: 223.18493137112029\n",
      "penalty: 18.777323728815894\n",
      "h_val:  tensor(3.6657, grad_fn=<SubBackward0>)\n",
      "squared loss: 194.53676699183788\n",
      "loss: 213.60670631619942\n",
      "penalty: 6.718814818815475\n",
      "h_val:  tensor(4.1225, grad_fn=<SubBackward0>)\n",
      "squared loss: 191.058969842751\n",
      "loss: 211.96710157930175\n",
      "penalty: 8.497388772939416\n",
      "h_val:  tensor(4.8712, grad_fn=<SubBackward0>)\n",
      "squared loss: 183.64399128027262\n",
      "loss: 208.0391998010733\n",
      "penalty: 11.864222604661418\n",
      "h_val:  tensor(5.0529, grad_fn=<SubBackward0>)\n",
      "squared loss: 178.68989891539758\n",
      "loss: 204.0613473776229\n",
      "penalty: 12.765961852558085\n",
      "h_val:  tensor(5.2589, grad_fn=<SubBackward0>)\n",
      "squared loss: 161.0547605832248\n",
      "loss: 187.7673119975688\n",
      "penalty: 13.828010494480319\n",
      "h_val:  tensor(3.9651, grad_fn=<SubBackward0>)\n",
      "squared loss: 156.87003463381436\n",
      "loss: 177.6313391936514\n",
      "penalty: 7.861105781186523\n",
      "h_val:  tensor(3.0682, grad_fn=<SubBackward0>)\n",
      "squared loss: 154.97504161089918\n",
      "loss: 172.4816393160418\n",
      "penalty: 4.706987896271085\n",
      "h_val:  tensor(2.9593, grad_fn=<SubBackward0>)\n",
      "squared loss: 152.71329051566866\n",
      "loss: 169.86953760528283\n",
      "penalty: 4.378821828031055\n",
      "h_val:  tensor(2.5930, grad_fn=<SubBackward0>)\n",
      "squared loss: 153.06048330513119\n",
      "loss: 169.1360193815651\n",
      "penalty: 3.361886283051848\n",
      "h_val:  tensor(2.6268, grad_fn=<SubBackward0>)\n",
      "squared loss: 152.8794701609155\n",
      "loss: 169.04782408486963\n",
      "penalty: 3.449934030481351\n",
      "h_val:  tensor(2.7062, grad_fn=<SubBackward0>)\n",
      "squared loss: 152.36548144179977\n",
      "loss: 168.76058315022493\n",
      "penalty: 3.6618243783609583\n",
      "h_val:  tensor(2.8367, grad_fn=<SubBackward0>)\n",
      "squared loss: 151.3089510564491\n",
      "loss: 168.094825886216\n",
      "penalty: 4.023439155279789\n",
      "h_val:  tensor(3.0378, grad_fn=<SubBackward0>)\n",
      "squared loss: 149.3011847284262\n",
      "loss: 166.73223734857996\n",
      "penalty: 4.614122569413246\n",
      "h_val:  tensor(3.2414, grad_fn=<SubBackward0>)\n",
      "squared loss: 146.77025376198281\n",
      "loss: 164.92076599512788\n",
      "penalty: 5.253266130033672\n",
      "h_val:  tensor(3.1643, grad_fn=<SubBackward0>)\n",
      "squared loss: 145.4354742673141\n",
      "loss: 163.39215500435424\n",
      "penalty: 5.006503759346342\n",
      "h_val:  tensor(3.0267, grad_fn=<SubBackward0>)\n",
      "squared loss: 144.85889654211798\n",
      "loss: 162.43710722294824\n",
      "penalty: 4.5803280812210625\n",
      "h_val:  tensor(2.9915, grad_fn=<SubBackward0>)\n",
      "squared loss: 144.7557851248104\n",
      "loss: 162.25109077212713\n",
      "penalty: 4.474522666649148\n",
      "h_val:  tensor(2.9445, grad_fn=<SubBackward0>)\n",
      "squared loss: 144.64135310445022\n",
      "loss: 162.0136898345339\n",
      "penalty: 4.334960756108228\n",
      "h_val:  tensor(2.8580, grad_fn=<SubBackward0>)\n",
      "squared loss: 144.12381061356805\n",
      "loss: 161.29124663549294\n",
      "penalty: 4.083983943356539\n",
      "h_val:  tensor(2.8308, grad_fn=<SubBackward0>)\n",
      "squared loss: 143.27935850100704\n",
      "loss: 160.42824157302013\n",
      "penalty: 4.006758144532177\n",
      "h_val:  tensor(2.8283, grad_fn=<SubBackward0>)\n",
      "squared loss: 142.41211711126635\n",
      "loss: 159.61301859397074\n",
      "penalty: 3.999660019280117\n",
      "h_val:  tensor(2.7843, grad_fn=<SubBackward0>)\n",
      "squared loss: 141.92037825890446\n",
      "loss: 159.03560614569594\n",
      "penalty: 3.876103147366252\n",
      "h_val:  tensor(2.7113, grad_fn=<SubBackward0>)\n",
      "squared loss: 141.54875350209528\n",
      "loss: 158.48842598286498\n",
      "penalty: 3.6754605860863507\n",
      "h_val:  tensor(2.6247, grad_fn=<SubBackward0>)\n",
      "squared loss: 140.91226469364824\n",
      "loss: 157.6606497453698\n",
      "penalty: 3.4444582061674334\n",
      "h_val:  tensor(2.5577, grad_fn=<SubBackward0>)\n",
      "squared loss: 139.75321953772684\n",
      "loss: 156.41555843888275\n",
      "penalty: 3.2709616716363863\n",
      "h_val:  tensor(2.5567, grad_fn=<SubBackward0>)\n",
      "squared loss: 138.45714406657157\n",
      "loss: 155.2377389120019\n",
      "penalty: 3.268300949669478\n",
      "h_val:  tensor(2.5975, grad_fn=<SubBackward0>)\n",
      "squared loss: 137.30938062693178\n",
      "loss: 154.30752164205518\n",
      "penalty: 3.3734204630974367\n",
      "h_val:  tensor(2.6589, grad_fn=<SubBackward0>)\n",
      "squared loss: 136.33084146600504\n",
      "loss: 153.5761987997541\n",
      "penalty: 3.5349687987930962\n",
      "h_val:  tensor(2.7102, grad_fn=<SubBackward0>)\n",
      "squared loss: 135.50332886824106\n",
      "loss: 152.93799864399531\n",
      "penalty: 3.6725787130747687\n",
      "h_val:  tensor(2.7303, grad_fn=<SubBackward0>)\n",
      "squared loss: 134.54991224549465\n",
      "loss: 152.07907181701358\n",
      "penalty: 3.727349502127175\n",
      "h_val:  tensor(2.6335, grad_fn=<SubBackward0>)\n",
      "squared loss: 133.1718232836437\n",
      "loss: 150.48009878607039\n",
      "penalty: 3.467759524827538\n",
      "h_val:  tensor(2.1976, grad_fn=<SubBackward0>)\n",
      "squared loss: 130.820860532493\n",
      "loss: 147.11831217803922\n",
      "penalty: 2.4146372778187235\n",
      "h_val:  tensor(1.5887, grad_fn=<SubBackward0>)\n",
      "squared loss: 126.2268671601642\n",
      "loss: 141.47304549255784\n",
      "penalty: 1.2619220299321403\n",
      "h_val:  tensor(3.8658, grad_fn=<SubBackward0>)\n",
      "squared loss: 121.0796740692997\n",
      "loss: 143.1156361137143\n",
      "penalty: 7.47216830459441\n",
      "h_val:  tensor(1.7956, grad_fn=<SubBackward0>)\n",
      "squared loss: 121.65945981206562\n",
      "loss: 137.47666758152394\n",
      "penalty: 1.612078977416896\n",
      "h_val:  tensor(17.2829, grad_fn=<SubBackward0>)\n",
      "squared loss: 108.82055693595849\n",
      "loss: 273.52382809393254\n",
      "penalty: 149.34873464514084\n",
      "h_val:  tensor(2.9322, grad_fn=<SubBackward0>)\n",
      "squared loss: 119.74744151495165\n",
      "loss: 138.54505638734258\n",
      "penalty: 4.298830256348109\n",
      "h_val:  tensor(2.1599, grad_fn=<SubBackward0>)\n",
      "squared loss: 119.51196881193754\n",
      "loss: 136.17446416841432\n",
      "penalty: 2.332591661063329\n",
      "h_val:  tensor(2.1523, grad_fn=<SubBackward0>)\n",
      "squared loss: 117.01962526939658\n",
      "loss: 133.72386855158464\n",
      "penalty: 2.3162756973807577\n",
      "h_val:  tensor(2.5586, grad_fn=<SubBackward0>)\n",
      "squared loss: 109.42022605378803\n",
      "loss: 127.40385262076114\n",
      "penalty: 3.2731851315931144\n",
      "h_val:  tensor(2.1653, grad_fn=<SubBackward0>)\n",
      "squared loss: 108.95928801275281\n",
      "loss: 126.0230288832443\n",
      "penalty: 2.3442183984631906\n",
      "h_val:  tensor(2.2148, grad_fn=<SubBackward0>)\n",
      "squared loss: 108.03012336496802\n",
      "loss: 125.23472152029588\n",
      "penalty: 2.4525681106256965\n",
      "h_val:  tensor(2.7220, grad_fn=<SubBackward0>)\n",
      "squared loss: 105.62404315702489\n",
      "loss: 124.19072379106807\n",
      "penalty: 3.7046527513899323\n",
      "h_val:  tensor(3.1773, grad_fn=<SubBackward0>)\n",
      "squared loss: 103.58818286718852\n",
      "loss: 123.53671065762437\n",
      "penalty: 5.047651432490843\n",
      "h_val:  tensor(2.5899, grad_fn=<SubBackward0>)\n",
      "squared loss: 104.64977689749003\n",
      "loss: 122.82210137812474\n",
      "penalty: 3.353834753479377\n",
      "h_val:  tensor(2.3906, grad_fn=<SubBackward0>)\n",
      "squared loss: 104.85172338553085\n",
      "loss: 122.53410677424735\n",
      "penalty: 2.8574373468613934\n",
      "h_val:  tensor(2.4968, grad_fn=<SubBackward0>)\n",
      "squared loss: 103.93670358098056\n",
      "loss: 121.91740009333249\n",
      "penalty: 3.1169564612769998\n",
      "h_val:  tensor(2.9256, grad_fn=<SubBackward0>)\n",
      "squared loss: 100.21270148487645\n",
      "loss: 119.59238257866623\n",
      "penalty: 4.279559457797535\n",
      "h_val:  tensor(2.7467, grad_fn=<SubBackward0>)\n",
      "squared loss: 99.20064617887711\n",
      "loss: 118.16727497559629\n",
      "penalty: 3.772291453529802\n",
      "h_val:  tensor(2.2433, grad_fn=<SubBackward0>)\n",
      "squared loss: 98.48221089105844\n",
      "loss: 116.3211673840967\n",
      "penalty: 2.516114822276138\n",
      "h_val:  tensor(1.5424, grad_fn=<SubBackward0>)\n",
      "squared loss: 99.20817161768605\n",
      "loss: 115.73891471611812\n",
      "penalty: 1.1895485232479017\n",
      "h_val:  tensor(1.6043, grad_fn=<SubBackward0>)\n",
      "squared loss: 98.31402209044602\n",
      "loss: 114.93537803735538\n",
      "penalty: 1.2868355707924009\n",
      "h_val:  tensor(1.5366, grad_fn=<SubBackward0>)\n",
      "squared loss: 97.4294461854426\n",
      "loss: 114.0122678091165\n",
      "penalty: 1.1806399347131384\n",
      "h_val:  tensor(1.2950, grad_fn=<SubBackward0>)\n",
      "squared loss: 97.14636598775415\n",
      "loss: 113.49964863243382\n",
      "penalty: 0.8384669256683662\n",
      "h_val:  tensor(1.4321, grad_fn=<SubBackward0>)\n",
      "squared loss: 96.3437703792633\n",
      "loss: 112.94379325926113\n",
      "penalty: 1.0254653579246138\n",
      "h_val:  tensor(1.6247, grad_fn=<SubBackward0>)\n",
      "squared loss: 95.29584362543606\n",
      "loss: 112.30062502348883\n",
      "penalty: 1.3198085443899066\n",
      "h_val:  tensor(6.1385, grad_fn=<SubBackward0>)\n",
      "squared loss: 86.02014292452648\n",
      "loss: 121.79828655455721\n",
      "penalty: 18.84074588468121\n",
      "h_val:  tensor(2.4014, grad_fn=<SubBackward0>)\n",
      "squared loss: 91.32456451211783\n",
      "loss: 110.28157513975907\n",
      "penalty: 2.8834597339539623\n",
      "h_val:  tensor(3.0011, grad_fn=<SubBackward0>)\n",
      "squared loss: 88.88654152189181\n",
      "loss: 109.6659544922168\n",
      "penalty: 4.503306476979839\n",
      "h_val:  tensor(2.5930, grad_fn=<SubBackward0>)\n",
      "squared loss: 88.15318375445953\n",
      "loss: 107.78317801202448\n",
      "penalty: 3.3618357483755754\n",
      "h_val:  tensor(2.0522, grad_fn=<SubBackward0>)\n",
      "squared loss: 85.18583156014972\n",
      "loss: 103.77945036678811\n",
      "penalty: 2.105798837656462\n",
      "h_val:  tensor(1.8369, grad_fn=<SubBackward0>)\n",
      "squared loss: 82.61243279169126\n",
      "loss: 101.07246283938584\n",
      "penalty: 1.6870976197294414\n",
      "h_val:  tensor(1.8990, grad_fn=<SubBackward0>)\n",
      "squared loss: 81.66377488431635\n",
      "loss: 100.55431236073215\n",
      "penalty: 1.8030962131097152\n",
      "h_val:  tensor(2.0163, grad_fn=<SubBackward0>)\n",
      "squared loss: 78.76821705522751\n",
      "loss: 98.25050596888003\n",
      "penalty: 2.0327175636458543\n",
      "h_val:  tensor(1.6893, grad_fn=<SubBackward0>)\n",
      "squared loss: 78.91259506935685\n",
      "loss: 97.55351968587634\n",
      "penalty: 1.4269324643895664\n",
      "h_val:  tensor(1.6625, grad_fn=<SubBackward0>)\n",
      "squared loss: 78.73719926337807\n",
      "loss: 97.35847284291667\n",
      "penalty: 1.3819223025115894\n",
      "h_val:  tensor(1.5937, grad_fn=<SubBackward0>)\n",
      "squared loss: 78.42481771748656\n",
      "loss: 96.96348600500289\n",
      "penalty: 1.2698925654521187\n",
      "h_val:  tensor(1.5567, grad_fn=<SubBackward0>)\n",
      "squared loss: 77.87130489834874\n",
      "loss: 96.43345041242954\n",
      "penalty: 1.2116554907418653\n",
      "h_val:  tensor(1.5883, grad_fn=<SubBackward0>)\n",
      "squared loss: 77.49436281245218\n",
      "loss: 96.17255922636981\n",
      "penalty: 1.2612842653646363\n",
      "h_val:  tensor(1.6451, grad_fn=<SubBackward0>)\n",
      "squared loss: 77.22368719730143\n",
      "loss: 96.03852154314943\n",
      "penalty: 1.3532060930707452\n",
      "h_val:  tensor(1.6573, grad_fn=<SubBackward0>)\n",
      "squared loss: 76.96415537546116\n",
      "loss: 95.81880616281838\n",
      "penalty: 1.3733080630609664\n",
      "h_val:  tensor(1.6452, grad_fn=<SubBackward0>)\n",
      "squared loss: 76.49983866462345\n",
      "loss: 95.36327521254519\n",
      "penalty: 1.3533536733389786\n",
      "h_val:  tensor(1.6735, grad_fn=<SubBackward0>)\n",
      "squared loss: 76.15434576127242\n",
      "loss: 95.13974320932267\n",
      "penalty: 1.400365828674293\n",
      "h_val:  tensor(1.6489, grad_fn=<SubBackward0>)\n",
      "squared loss: 75.94653573664226\n",
      "loss: 94.95207248296622\n",
      "penalty: 1.3594540596411684\n",
      "h_val:  tensor(1.4193, grad_fn=<SubBackward0>)\n",
      "squared loss: 75.40607236284339\n",
      "loss: 94.26940959333469\n",
      "penalty: 1.0072109351068594\n",
      "h_val:  tensor(1.1111, grad_fn=<SubBackward0>)\n",
      "squared loss: 75.39044879402628\n",
      "loss: 94.04627684349151\n",
      "penalty: 0.6172787952127836\n",
      "h_val:  tensor(1.0832, grad_fn=<SubBackward0>)\n",
      "squared loss: 75.16688714797374\n",
      "loss: 93.70601937433027\n",
      "penalty: 0.586647800568609\n",
      "h_val:  tensor(1.0008, grad_fn=<SubBackward0>)\n",
      "squared loss: 75.06146924232311\n",
      "loss: 93.50793113733766\n",
      "penalty: 0.5008155362380808\n",
      "h_val:  tensor(0.8413, grad_fn=<SubBackward0>)\n",
      "squared loss: 74.94005964553111\n",
      "loss: 93.28776820164401\n",
      "penalty: 0.353901429172184\n",
      "h_val:  tensor(0.8347, grad_fn=<SubBackward0>)\n",
      "squared loss: 74.80574229495319\n",
      "loss: 93.18965293175538\n",
      "penalty: 0.34838060876503246\n",
      "h_val:  tensor(0.7924, grad_fn=<SubBackward0>)\n",
      "squared loss: 74.62158181958931\n",
      "loss: 93.06241579839487\n",
      "penalty: 0.3139149312884697\n",
      "h_val:  tensor(0.7517, grad_fn=<SubBackward0>)\n",
      "squared loss: 74.49945971682253\n",
      "loss: 92.97801663077345\n",
      "penalty: 0.28255339234038557\n",
      "h_val:  tensor(0.7095, grad_fn=<SubBackward0>)\n",
      "squared loss: 74.38522693026059\n",
      "loss: 92.886055672925\n",
      "penalty: 0.2517101732891647\n",
      "h_val:  tensor(0.6731, grad_fn=<SubBackward0>)\n",
      "squared loss: 74.32338102264687\n",
      "loss: 92.81306410681452\n",
      "penalty: 0.22653510230099297\n",
      "h_val:  tensor(0.6316, grad_fn=<SubBackward0>)\n",
      "squared loss: 74.25716400783955\n",
      "loss: 92.72518416198828\n",
      "penalty: 0.19946708394754187\n",
      "h_val:  tensor(0.5596, grad_fn=<SubBackward0>)\n",
      "squared loss: 74.1596010101133\n",
      "loss: 92.59638918573171\n",
      "penalty: 0.15660178701780217\n",
      "h_val:  tensor(0.5444, grad_fn=<SubBackward0>)\n",
      "squared loss: 74.13661675382897\n",
      "loss: 92.57597023652073\n",
      "penalty: 0.14816437304522972\n",
      "h_val:  tensor(0.5404, grad_fn=<SubBackward0>)\n",
      "squared loss: 74.1140609598417\n",
      "loss: 92.56542330896565\n",
      "penalty: 0.1460160803725014\n",
      "h_val:  tensor(0.5422, grad_fn=<SubBackward0>)\n",
      "squared loss: 74.06436404012172\n",
      "loss: 92.54360452853646\n",
      "penalty: 0.14698983070570254\n",
      "h_val:  tensor(0.5609, grad_fn=<SubBackward0>)\n",
      "squared loss: 73.90447084898233\n",
      "loss: 92.46534852437283\n",
      "penalty: 0.15732870235687058\n",
      "h_val:  tensor(0.6320, grad_fn=<SubBackward0>)\n",
      "squared loss: 73.53313894899418\n",
      "loss: 92.29475984218725\n",
      "penalty: 0.1997385816986094\n",
      "h_val:  tensor(0.7291, grad_fn=<SubBackward0>)\n",
      "squared loss: 73.21736008666323\n",
      "loss: 92.17361775672205\n",
      "penalty: 0.2657853855242668\n",
      "h_val:  tensor(0.7691, grad_fn=<SubBackward0>)\n",
      "squared loss: 73.11857039815496\n",
      "loss: 92.13039660320398\n",
      "penalty: 0.2957654988635406\n",
      "h_val:  tensor(0.7963, grad_fn=<SubBackward0>)\n",
      "squared loss: 73.05934479775843\n",
      "loss: 92.09063173535401\n",
      "penalty: 0.31703213806523195\n",
      "h_val:  tensor(0.8382, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.96584570052245\n",
      "loss: 92.03837929651024\n",
      "penalty: 0.3512785745333414\n",
      "h_val:  tensor(0.9113, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.79584614521582\n",
      "loss: 91.96890914547677\n",
      "penalty: 0.4152287410133729\n",
      "h_val:  tensor(0.9582, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.66737223115817\n",
      "loss: 91.93028144548175\n",
      "penalty: 0.45907637940258855\n",
      "h_val:  tensor(0.9684, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.61252861510175\n",
      "loss: 91.91307078938793\n",
      "penalty: 0.4689199490965663\n",
      "h_val:  tensor(0.9628, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.59766685391756\n",
      "loss: 91.90393904656295\n",
      "penalty: 0.46350700941362555\n",
      "h_val:  tensor(0.9529, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.5880489932707\n",
      "loss: 91.8924162755643\n",
      "penalty: 0.4539783092780892\n",
      "h_val:  tensor(0.9388, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.56980330649678\n",
      "loss: 91.87046708946232\n",
      "penalty: 0.4406940412643601\n",
      "h_val:  tensor(0.9300, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.53772292580275\n",
      "loss: 91.83984663809004\n",
      "penalty: 0.43248390359359157\n",
      "h_val:  tensor(0.9322, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.50933576641746\n",
      "loss: 91.81468531306004\n",
      "penalty: 0.4344915990911611\n",
      "h_val:  tensor(0.9379, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.49066341951412\n",
      "loss: 91.79949843863001\n",
      "penalty: 0.4397852820078714\n",
      "h_val:  tensor(0.9514, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.45385337752036\n",
      "loss: 91.77607296037115\n",
      "penalty: 0.45258484520828934\n",
      "h_val:  tensor(0.9606, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.42150987928609\n",
      "loss: 91.75939495274402\n",
      "penalty: 0.4613703732466677\n",
      "h_val:  tensor(0.9670, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.3762941550269\n",
      "loss: 91.73735101643922\n",
      "penalty: 0.4675607212221605\n",
      "h_val:  tensor(0.9639, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.35110016654504\n",
      "loss: 91.72492117990018\n",
      "penalty: 0.4645278369692178\n",
      "h_val:  tensor(0.9565, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.34336144396012\n",
      "loss: 91.71923315821289\n",
      "penalty: 0.4574392783535296\n",
      "h_val:  tensor(0.9440, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.3364140416303\n",
      "loss: 91.7102168322115\n",
      "penalty: 0.44557484492955124\n",
      "h_val:  tensor(0.8954, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.31494924970461\n",
      "loss: 91.6799542503812\n",
      "penalty: 0.40089509993451566\n",
      "h_val:  tensor(0.8477, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.29280063964445\n",
      "loss: 91.65209632465779\n",
      "penalty: 0.3593374782213732\n",
      "h_val:  tensor(0.8085, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.26977242425987\n",
      "loss: 91.62758224215729\n",
      "penalty: 0.32680355017047213\n",
      "h_val:  tensor(0.7944, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.25064332926189\n",
      "loss: 91.60653229615619\n",
      "penalty: 0.3155717883151231\n",
      "h_val:  tensor(0.7856, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.21923537161817\n",
      "loss: 91.57385252893003\n",
      "penalty: 0.30859058057723626\n",
      "h_val:  tensor(0.7888, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.19637349924177\n",
      "loss: 91.55609295874055\n",
      "penalty: 0.3110932955380727\n",
      "h_val:  tensor(0.8016, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.16081953714274\n",
      "loss: 91.53461738792836\n",
      "penalty: 0.32125794798777896\n",
      "h_val:  tensor(0.8162, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.1371772200254\n",
      "loss: 91.52286138835842\n",
      "penalty: 0.333102771596009\n",
      "h_val:  tensor(0.8274, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.11929433507338\n",
      "loss: 91.51446777559022\n",
      "penalty: 0.34229448599719\n",
      "h_val:  tensor(0.8436, grad_fn=<SubBackward0>)\n",
      "squared loss: 72.0830019086824\n",
      "loss: 91.49646439057817\n",
      "penalty: 0.35579267536965503\n",
      "h_val:  tensor(0.8836, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.97532291598584\n",
      "loss: 91.44386685583676\n",
      "penalty: 0.3903402663556935\n",
      "h_val:  tensor(0.9467, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.7795154382074\n",
      "loss: 91.35191437455963\n",
      "penalty: 0.448162127554921\n",
      "h_val:  tensor(1.0117, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.54622149852236\n",
      "loss: 91.24794611712412\n",
      "penalty: 0.5117906630612274\n",
      "h_val:  tensor(1.0193, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.45170733963691\n",
      "loss: 91.19546490000529\n",
      "penalty: 0.519488555101496\n",
      "h_val:  tensor(0.9991, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.4530278751079\n",
      "loss: 91.18097688224479\n",
      "penalty: 0.49907744314787594\n",
      "h_val:  tensor(0.9903, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.44864628718155\n",
      "loss: 91.16990397944765\n",
      "penalty: 0.49034352986765317\n",
      "h_val:  tensor(0.9531, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.4137198899293\n",
      "loss: 91.11357489970143\n",
      "penalty: 0.45424500718244687\n",
      "h_val:  tensor(0.9441, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.368667818449\n",
      "loss: 91.07800582204797\n",
      "penalty: 0.4456398037291156\n",
      "h_val:  tensor(0.9587, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.31516064818035\n",
      "loss: 91.05687356905813\n",
      "penalty: 0.45954124445047284\n",
      "h_val:  tensor(0.9685, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.28545086500266\n",
      "loss: 91.04347690596371\n",
      "penalty: 0.4690438822426705\n",
      "h_val:  tensor(0.9593, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.25422965266694\n",
      "loss: 91.01141415579517\n",
      "penalty: 0.4601445968234684\n",
      "h_val:  tensor(0.9073, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.22636354607796\n",
      "loss: 90.9490536096453\n",
      "penalty: 0.41158039685443737\n",
      "h_val:  tensor(0.8555, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.23333827414554\n",
      "loss: 90.91745042995284\n",
      "penalty: 0.36594474787028597\n",
      "h_val:  tensor(0.8217, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.24519937283719\n",
      "loss: 90.9031981125001\n",
      "penalty: 0.3376350007267443\n",
      "h_val:  tensor(0.8068, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.24763220177502\n",
      "loss: 90.89365694241091\n",
      "penalty: 0.325424985813677\n",
      "h_val:  tensor(0.7991, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.2190075805235\n",
      "loss: 90.86653487376093\n",
      "penalty: 0.31928202230078345\n",
      "h_val:  tensor(0.8134, grad_fn=<SubBackward0>)\n",
      "squared loss: 71.11931215977756\n",
      "loss: 90.80311505841406\n",
      "penalty: 0.33078548591574536\n",
      "h_val:  tensor(0.8592, grad_fn=<SubBackward0>)\n",
      "squared loss: 70.99703736490419\n",
      "loss: 90.74445002738867\n",
      "penalty: 0.3690746708935273\n",
      "h_val:  tensor(0.9070, grad_fn=<SubBackward0>)\n",
      "squared loss: 70.89612312605102\n",
      "loss: 90.69700606670719\n",
      "penalty: 0.4113178263192967\n",
      "h_val:  tensor(0.9383, grad_fn=<SubBackward0>)\n",
      "squared loss: 70.80965068440983\n",
      "loss: 90.63862993369253\n",
      "penalty: 0.4402188167408483\n",
      "h_val:  tensor(0.9657, grad_fn=<SubBackward0>)\n",
      "squared loss: 70.72513866344772\n",
      "loss: 90.57303987948745\n",
      "penalty: 0.4663017486574059\n",
      "h_val:  tensor(0.9560, grad_fn=<SubBackward0>)\n",
      "squared loss: 70.69682159610566\n",
      "loss: 90.53620787380007\n",
      "penalty: 0.45693268988891583\n",
      "h_val:  tensor(0.9353, grad_fn=<SubBackward0>)\n",
      "squared loss: 70.62788810134325\n",
      "loss: 90.45321796478048\n",
      "penalty: 0.43741644625199894\n",
      "h_val:  tensor(0.9392, grad_fn=<SubBackward0>)\n",
      "squared loss: 70.5567660467984\n",
      "loss: 90.39971413739809\n",
      "penalty: 0.4410135391989686\n",
      "h_val:  tensor(1.0099, grad_fn=<SubBackward0>)\n",
      "squared loss: 70.2159704911774\n",
      "loss: 90.19538563877884\n",
      "penalty: 0.5099091167865338\n",
      "h_val:  tensor(1.1757, grad_fn=<SubBackward0>)\n",
      "squared loss: 69.78782020971661\n",
      "loss: 90.04074535607265\n",
      "penalty: 0.691088210876987\n",
      "h_val:  tensor(1.2329, grad_fn=<SubBackward0>)\n",
      "squared loss: 69.67012378629174\n",
      "loss: 90.01409696183528\n",
      "penalty: 0.7600580900946284\n",
      "h_val:  tensor(1.2641, grad_fn=<SubBackward0>)\n",
      "squared loss: 69.55082793831902\n",
      "loss: 89.95240068454731\n",
      "penalty: 0.7989878015240062\n",
      "h_val:  tensor(1.2807, grad_fn=<SubBackward0>)\n",
      "squared loss: 69.29990681718658\n",
      "loss: 89.76835623840994\n",
      "penalty: 0.8200696904615387\n",
      "h_val:  tensor(1.2207, grad_fn=<SubBackward0>)\n",
      "squared loss: 69.1868618954299\n",
      "loss: 89.61062807411659\n",
      "penalty: 0.7450915189471007\n",
      "h_val:  tensor(1.2307, grad_fn=<SubBackward0>)\n",
      "squared loss: 69.03129430513093\n",
      "loss: 89.52047111628262\n",
      "penalty: 0.7572925406033141\n",
      "h_val:  tensor(1.2582, grad_fn=<SubBackward0>)\n",
      "squared loss: 68.92026039089976\n",
      "loss: 89.47501378020293\n",
      "penalty: 0.7915597703911519\n",
      "h_val:  tensor(1.3268, grad_fn=<SubBackward0>)\n",
      "squared loss: 68.6519368092866\n",
      "loss: 89.35092991527661\n",
      "penalty: 0.8802558302163749\n",
      "h_val:  tensor(1.4334, grad_fn=<SubBackward0>)\n",
      "squared loss: 68.11060981131413\n",
      "loss: 89.0746177140302\n",
      "penalty: 1.0273128251008743\n",
      "h_val:  tensor(1.4903, grad_fn=<SubBackward0>)\n",
      "squared loss: 67.8443765481937\n",
      "loss: 88.95855746230929\n",
      "penalty: 1.1105405309623049\n",
      "h_val:  tensor(1.4825, grad_fn=<SubBackward0>)\n",
      "squared loss: 67.76581398823444\n",
      "loss: 88.8892264144602\n",
      "penalty: 1.0988744085102278\n",
      "h_val:  tensor(1.4318, grad_fn=<SubBackward0>)\n",
      "squared loss: 67.70396599253517\n",
      "loss: 88.7693564317898\n",
      "penalty: 1.02507532594974\n",
      "h_val:  tensor(1.3557, grad_fn=<SubBackward0>)\n",
      "squared loss: 67.47734590030774\n",
      "loss: 88.53219791325724\n",
      "penalty: 0.9189268420068366\n",
      "h_val:  tensor(1.2925, grad_fn=<SubBackward0>)\n",
      "squared loss: 67.12048451542235\n",
      "loss: 88.25771032286208\n",
      "penalty: 0.8353367230097245\n",
      "h_val:  tensor(1.1684, grad_fn=<SubBackward0>)\n",
      "squared loss: 66.99117164455244\n",
      "loss: 88.0822228917557\n",
      "penalty: 0.6826218926466612\n",
      "h_val:  tensor(1.0158, grad_fn=<SubBackward0>)\n",
      "squared loss: 66.96428684504701\n",
      "loss: 87.92528302579925\n",
      "penalty: 0.5159245922711976\n",
      "h_val:  tensor(0.7913, grad_fn=<SubBackward0>)\n",
      "squared loss: 66.88490802262947\n",
      "loss: 87.6589513734548\n",
      "penalty: 0.3130626985071351\n",
      "h_val:  tensor(0.7110, grad_fn=<SubBackward0>)\n",
      "squared loss: 66.72203962746336\n",
      "loss: 87.4740932789493\n",
      "penalty: 0.25279260855492386\n",
      "h_val:  tensor(0.6578, grad_fn=<SubBackward0>)\n",
      "squared loss: 65.72665385967223\n",
      "loss: 86.7207855906721\n",
      "penalty: 0.21635825450187712\n",
      "h_val:  tensor(1.3686, grad_fn=<SubBackward0>)\n",
      "squared loss: 63.4592505901161\n",
      "loss: 86.23530275896209\n",
      "penalty: 0.9364993891262514\n",
      "h_val:  tensor(0.9253, grad_fn=<SubBackward0>)\n",
      "squared loss: 63.92622739433114\n",
      "loss: 85.72439234631653\n",
      "penalty: 0.4280961358830762\n",
      "h_val:  tensor(0.9638, grad_fn=<SubBackward0>)\n",
      "squared loss: 63.751599147461675\n",
      "loss: 85.58496828854749\n",
      "penalty: 0.4644096358269979\n",
      "h_val:  tensor(1.1326, grad_fn=<SubBackward0>)\n",
      "squared loss: 63.228891744096565\n",
      "loss: 85.38694863531303\n",
      "penalty: 0.6414098534226546\n",
      "h_val:  tensor(1.2291, grad_fn=<SubBackward0>)\n",
      "squared loss: 62.79866124345702\n",
      "loss: 85.25420166378852\n",
      "penalty: 0.7553463761050035\n",
      "h_val:  tensor(1.2460, grad_fn=<SubBackward0>)\n",
      "squared loss: 62.50088912587673\n",
      "loss: 85.07559421782267\n",
      "penalty: 0.7762924370846082\n",
      "h_val:  tensor(1.2168, grad_fn=<SubBackward0>)\n",
      "squared loss: 62.10536172351379\n",
      "loss: 84.80554266863135\n",
      "penalty: 0.7403307008509712\n",
      "h_val:  tensor(1.2249, grad_fn=<SubBackward0>)\n",
      "squared loss: 61.638364409171075\n",
      "loss: 84.57346448366444\n",
      "penalty: 0.750191075126751\n",
      "h_val:  tensor(1.2208, grad_fn=<SubBackward0>)\n",
      "squared loss: 61.24125900885725\n",
      "loss: 84.37920044838302\n",
      "penalty: 0.7451638025060746\n",
      "h_val:  tensor(1.2017, grad_fn=<SubBackward0>)\n",
      "squared loss: 60.89363827390729\n",
      "loss: 84.2028971046042\n",
      "penalty: 0.7220889007127806\n",
      "h_val:  tensor(1.1892, grad_fn=<SubBackward0>)\n",
      "squared loss: 60.66641543995107\n",
      "loss: 84.06983576293213\n",
      "penalty: 0.7071435286978951\n",
      "h_val:  tensor(1.1514, grad_fn=<SubBackward0>)\n",
      "squared loss: 60.255413902769554\n",
      "loss: 83.78536675836845\n",
      "penalty: 0.6628704230094804\n",
      "h_val:  tensor(1.1689, grad_fn=<SubBackward0>)\n",
      "squared loss: 59.78690179910689\n",
      "loss: 83.55794873437789\n",
      "penalty: 0.6832065427947814\n",
      "h_val:  tensor(1.2126, grad_fn=<SubBackward0>)\n",
      "squared loss: 59.55669234561245\n",
      "loss: 83.51727931589667\n",
      "penalty: 0.7351891763079581\n",
      "h_val:  tensor(1.2212, grad_fn=<SubBackward0>)\n",
      "squared loss: 59.46277079600037\n",
      "loss: 83.48974739264396\n",
      "penalty: 0.7456884089488861\n",
      "h_val:  tensor(1.2801, grad_fn=<SubBackward0>)\n",
      "squared loss: 58.70622990919968\n",
      "loss: 83.29700665404123\n",
      "penalty: 0.8193802507543091\n",
      "h_val:  tensor(1.2572, grad_fn=<SubBackward0>)\n",
      "squared loss: 58.30111424772898\n",
      "loss: 83.14426567524148\n",
      "penalty: 0.7903119976517946\n",
      "h_val:  tensor(1.0835, grad_fn=<SubBackward0>)\n",
      "squared loss: 57.422299838592025\n",
      "loss: 82.74967323215316\n",
      "penalty: 0.5870212967597521\n",
      "h_val:  tensor(0.9434, grad_fn=<SubBackward0>)\n",
      "squared loss: 57.24934772162734\n",
      "loss: 82.61329586069058\n",
      "penalty: 0.44502674672021525\n",
      "h_val:  tensor(0.8447, grad_fn=<SubBackward0>)\n",
      "squared loss: 57.08322598800896\n",
      "loss: 82.42752609209852\n",
      "penalty: 0.3567957281672923\n",
      "h_val:  tensor(0.6976, grad_fn=<SubBackward0>)\n",
      "squared loss: 57.23948526729109\n",
      "loss: 82.47885089782133\n",
      "penalty: 0.243291022298395\n",
      "h_val:  tensor(0.7333, grad_fn=<SubBackward0>)\n",
      "squared loss: 56.94882454536587\n",
      "loss: 82.2094574876039\n",
      "penalty: 0.2688404218510159\n",
      "h_val:  tensor(0.7197, grad_fn=<SubBackward0>)\n",
      "squared loss: 56.90181839422222\n",
      "loss: 82.1523092278135\n",
      "penalty: 0.2590000050328934\n",
      "h_val:  tensor(0.7694, grad_fn=<SubBackward0>)\n",
      "squared loss: 56.71220236787203\n",
      "loss: 82.02847129773565\n",
      "penalty: 0.2959827273635379\n",
      "h_val:  tensor(0.8307, grad_fn=<SubBackward0>)\n",
      "squared loss: 56.617906257968514\n",
      "loss: 81.92212657086152\n",
      "penalty: 0.34499030583105045\n",
      "h_val:  tensor(0.8306, grad_fn=<SubBackward0>)\n",
      "squared loss: 56.56862443518421\n",
      "loss: 81.87861652715848\n",
      "penalty: 0.34497241622806185\n",
      "h_val:  tensor(0.8340, grad_fn=<SubBackward0>)\n",
      "squared loss: 56.438221517962745\n",
      "loss: 81.81711876912645\n",
      "penalty: 0.3477987486577897\n",
      "h_val:  tensor(0.8378, grad_fn=<SubBackward0>)\n",
      "squared loss: 56.29635656870525\n",
      "loss: 81.76859536580805\n",
      "penalty: 0.35097999041472494\n",
      "h_val:  tensor(0.8416, grad_fn=<SubBackward0>)\n",
      "squared loss: 56.12745225566658\n",
      "loss: 81.72601376355843\n",
      "penalty: 0.35415843150500975\n",
      "h_val:  tensor(0.8420, grad_fn=<SubBackward0>)\n",
      "squared loss: 56.08159334455766\n",
      "loss: 81.71523677657342\n",
      "penalty: 0.3544978979137558\n",
      "h_val:  tensor(0.8413, grad_fn=<SubBackward0>)\n",
      "squared loss: 56.06451402232665\n",
      "loss: 81.7069445112355\n",
      "penalty: 0.35387130373059633\n",
      "h_val:  tensor(0.8410, grad_fn=<SubBackward0>)\n",
      "squared loss: 56.03771299910983\n",
      "loss: 81.6895471478813\n",
      "penalty: 0.3536043281007658\n",
      "h_val:  tensor(0.8431, grad_fn=<SubBackward0>)\n",
      "squared loss: 55.99708290302868\n",
      "loss: 81.66239349901184\n",
      "penalty: 0.3553960826105789\n",
      "h_val:  tensor(0.8490, grad_fn=<SubBackward0>)\n",
      "squared loss: 55.92882706696116\n",
      "loss: 81.61868585123386\n",
      "penalty: 0.36042474738709174\n",
      "h_val:  tensor(0.8466, grad_fn=<SubBackward0>)\n",
      "squared loss: 55.87329875747097\n",
      "loss: 81.57358251821701\n",
      "penalty: 0.3583270854346418\n",
      "h_val:  tensor(0.8306, grad_fn=<SubBackward0>)\n",
      "squared loss: 55.82755664728909\n",
      "loss: 81.51433866780131\n",
      "penalty: 0.3449349784196519\n",
      "h_val:  tensor(0.8218, grad_fn=<SubBackward0>)\n",
      "squared loss: 55.806285555904346\n",
      "loss: 81.4820226819348\n",
      "penalty: 0.3376717821006803\n",
      "h_val:  tensor(0.8208, grad_fn=<SubBackward0>)\n",
      "squared loss: 55.775411539724445\n",
      "loss: 81.46244510762236\n",
      "penalty: 0.3368673837495754\n",
      "h_val:  tensor(0.8181, grad_fn=<SubBackward0>)\n",
      "squared loss: 55.61545885672065\n",
      "loss: 81.38012548341906\n",
      "penalty: 0.33464947886918534\n",
      "h_val:  tensor(0.8254, grad_fn=<SubBackward0>)\n",
      "squared loss: 55.558801157473276\n",
      "loss: 81.35720002699053\n",
      "penalty: 0.3406635900990559\n",
      "h_val:  tensor(0.9409, grad_fn=<SubBackward0>)\n",
      "squared loss: 55.1613227802221\n",
      "loss: 81.2427036784686\n",
      "penalty: 0.4426507144381699\n",
      "h_val:  tensor(0.9566, grad_fn=<SubBackward0>)\n",
      "squared loss: 55.05574764571173\n",
      "loss: 81.19825621664303\n",
      "penalty: 0.4575396116758126\n",
      "h_val:  tensor(0.9710, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.95550101064888\n",
      "loss: 81.15795975762802\n",
      "penalty: 0.4714458444901706\n",
      "h_val:  tensor(0.9646, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.963318783316645\n",
      "loss: 81.15303711571435\n",
      "penalty: 0.4651940250474393\n",
      "h_val:  tensor(0.9606, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.95654290718994\n",
      "loss: 81.14112063356987\n",
      "penalty: 0.4614003538623779\n",
      "h_val:  tensor(0.9208, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.9790399607275\n",
      "loss: 81.10611561895706\n",
      "penalty: 0.4239642220568122\n",
      "h_val:  tensor(0.8924, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.94688372461794\n",
      "loss: 81.06207813340644\n",
      "penalty: 0.3982078495862524\n",
      "h_val:  tensor(0.8365, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.961995205037795\n",
      "loss: 81.02462055468715\n",
      "penalty: 0.34983354901268054\n",
      "h_val:  tensor(0.8285, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.922497621966414\n",
      "loss: 81.00781146501578\n",
      "penalty: 0.34320985525412717\n",
      "h_val:  tensor(0.8212, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.91085378913196\n",
      "loss: 80.99601978393248\n",
      "penalty: 0.33714719678110844\n",
      "h_val:  tensor(0.8172, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.849412566264064\n",
      "loss: 80.96490880431372\n",
      "penalty: 0.3338926239557973\n",
      "h_val:  tensor(0.8094, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.77268498275689\n",
      "loss: 80.92189257675837\n",
      "penalty: 0.3275653288374619\n",
      "h_val:  tensor(0.8118, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.646911639802674\n",
      "loss: 80.8583345040614\n",
      "penalty: 0.3295483000330307\n",
      "h_val:  tensor(0.8283, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.57709531156674\n",
      "loss: 80.83400486904812\n",
      "penalty: 0.34302606771415145\n",
      "h_val:  tensor(0.8253, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.56629863729523\n",
      "loss: 80.8223083453915\n",
      "penalty: 0.3405771260570879\n",
      "h_val:  tensor(0.8171, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.52144045931988\n",
      "loss: 80.77644246485676\n",
      "penalty: 0.33383701066484917\n",
      "h_val:  tensor(0.8257, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.47925454480117\n",
      "loss: 80.75417995698542\n",
      "penalty: 0.3408508782429067\n",
      "h_val:  tensor(0.8598, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.3715602044715\n",
      "loss: 80.71429979964914\n",
      "penalty: 0.36965309874623553\n",
      "h_val:  tensor(0.8647, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.333307908976785\n",
      "loss: 80.69639616863874\n",
      "penalty: 0.3738174286611644\n",
      "h_val:  tensor(0.8759, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.264574220232056\n",
      "loss: 80.66911456954884\n",
      "penalty: 0.38363918039424544\n",
      "h_val:  tensor(0.8667, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.22023083152398\n",
      "loss: 80.64122875590988\n",
      "penalty: 0.3756260154016754\n",
      "h_val:  tensor(0.8682, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.165360640001616\n",
      "loss: 80.61538908992031\n",
      "penalty: 0.3768907334237375\n",
      "h_val:  tensor(0.8575, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.09580567469243\n",
      "loss: 80.57356385645882\n",
      "penalty: 0.36768793087137125\n",
      "h_val:  tensor(0.8611, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.05208578518179\n",
      "loss: 80.55472995703475\n",
      "penalty: 0.3707375123800167\n",
      "h_val:  tensor(0.8656, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.03656614611865\n",
      "loss: 80.54883087099867\n",
      "penalty: 0.37460345759287994\n",
      "h_val:  tensor(0.8686, grad_fn=<SubBackward0>)\n",
      "squared loss: 54.022130991515795\n",
      "loss: 80.54207214421899\n",
      "penalty: 0.3772741787144165\n",
      "h_val:  tensor(0.8711, grad_fn=<SubBackward0>)\n",
      "squared loss: 53.994205949757706\n",
      "loss: 80.52797845540826\n",
      "penalty: 0.37937684170359626\n",
      "h_val:  tensor(0.8723, grad_fn=<SubBackward0>)\n",
      "squared loss: 53.94904969381943\n",
      "loss: 80.50628975691407\n",
      "penalty: 0.3804818791641128\n",
      "h_val:  tensor(0.8760, grad_fn=<SubBackward0>)\n",
      "squared loss: 53.8696544452028\n",
      "loss: 80.47323442283253\n",
      "penalty: 0.3836674954335212\n",
      "h_val:  tensor(0.8827, grad_fn=<SubBackward0>)\n",
      "squared loss: 53.775834347117666\n",
      "loss: 80.44137284656364\n",
      "penalty: 0.38962219822164557\n",
      "h_val:  tensor(0.8843, grad_fn=<SubBackward0>)\n",
      "squared loss: 53.714066114398776\n",
      "loss: 80.42070430187347\n",
      "penalty: 0.39099533221675487\n",
      "h_val:  tensor(0.8821, grad_fn=<SubBackward0>)\n",
      "squared loss: 53.65552375148017\n",
      "loss: 80.39906392534306\n",
      "penalty: 0.38900618700263667\n",
      "h_val:  tensor(0.8783, grad_fn=<SubBackward0>)\n",
      "squared loss: 53.559806184536185\n",
      "loss: 80.36190408959344\n",
      "penalty: 0.3856647477520557\n",
      "h_val:  tensor(0.8827, grad_fn=<SubBackward0>)\n",
      "squared loss: 53.34235572233929\n",
      "loss: 80.28329773392903\n",
      "penalty: 0.38962122206654154\n",
      "h_val:  tensor(0.9346, grad_fn=<SubBackward0>)\n",
      "squared loss: 52.922488680342106\n",
      "loss: 80.16487101791394\n",
      "penalty: 0.43669650636216134\n",
      "h_val:  tensor(0.9623, grad_fn=<SubBackward0>)\n",
      "squared loss: 52.71494902815349\n",
      "loss: 80.08879466684735\n",
      "penalty: 0.4630332483386186\n",
      "h_val:  tensor(0.9399, grad_fn=<SubBackward0>)\n",
      "squared loss: 52.64819349270584\n",
      "loss: 79.99884578711253\n",
      "penalty: 0.4417323781043215\n",
      "h_val:  tensor(0.9253, grad_fn=<SubBackward0>)\n",
      "squared loss: 52.63138532533411\n",
      "loss: 79.9681034348722\n",
      "penalty: 0.42813475207199453\n",
      "h_val:  tensor(0.9037, grad_fn=<SubBackward0>)\n",
      "squared loss: 52.585990719069315\n",
      "loss: 79.9235624989976\n",
      "penalty: 0.4083324123217935\n",
      "h_val:  tensor(0.8686, grad_fn=<SubBackward0>)\n",
      "squared loss: 52.49636125935352\n",
      "loss: 79.853798508655\n",
      "penalty: 0.3772455250469525\n",
      "h_val:  tensor(0.8141, grad_fn=<SubBackward0>)\n",
      "squared loss: 52.324097645184764\n",
      "loss: 79.74407018030506\n",
      "penalty: 0.3313832071944588\n",
      "h_val:  tensor(0.7599, grad_fn=<SubBackward0>)\n",
      "squared loss: 52.12192945260752\n",
      "loss: 79.63066594511253\n",
      "penalty: 0.28876131465243327\n",
      "h_val:  tensor(0.7276, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.950846741356564\n",
      "loss: 79.54231030944153\n",
      "penalty: 0.26471865858024074\n",
      "h_val:  tensor(0.7142, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.8280179024282\n",
      "loss: 79.47422614884819\n",
      "penalty: 0.2550737651649717\n",
      "h_val:  tensor(0.7086, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.72354783578794\n",
      "loss: 79.41466756230334\n",
      "penalty: 0.2510866467927976\n",
      "h_val:  tensor(0.7087, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.632406639023905\n",
      "loss: 79.35240782186396\n",
      "penalty: 0.25111566921927875\n",
      "h_val:  tensor(0.7184, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.54099107918015\n",
      "loss: 79.26936782194828\n",
      "penalty: 0.25808220376138324\n",
      "h_val:  tensor(0.7297, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.517427496299\n",
      "loss: 79.21707181552479\n",
      "penalty: 0.2662503758165253\n",
      "h_val:  tensor(0.7278, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.50468324826323\n",
      "loss: 79.19692936192841\n",
      "penalty: 0.2648225325978518\n",
      "h_val:  tensor(0.7234, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.47575239212993\n",
      "loss: 79.16105610183384\n",
      "penalty: 0.2616313980143825\n",
      "h_val:  tensor(0.7265, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.41883916038627\n",
      "loss: 79.1156561241881\n",
      "penalty: 0.26386605433733584\n",
      "h_val:  tensor(0.7364, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.371532534708024\n",
      "loss: 79.08740403687068\n",
      "penalty: 0.2711748495882847\n",
      "h_val:  tensor(0.7409, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.33745001091415\n",
      "loss: 79.06908925869067\n",
      "penalty: 0.2744614502386358\n",
      "h_val:  tensor(0.7394, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.30754958276427\n",
      "loss: 79.05276387650011\n",
      "penalty: 0.27332400012256447\n",
      "h_val:  tensor(0.7350, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.22228142162374\n",
      "loss: 79.00982862985404\n",
      "penalty: 0.27010160412667633\n",
      "h_val:  tensor(0.7404, grad_fn=<SubBackward0>)\n",
      "squared loss: 51.086026936040014\n",
      "loss: 78.95355448388264\n",
      "penalty: 0.2740598890784114\n",
      "h_val:  tensor(0.7640, grad_fn=<SubBackward0>)\n",
      "squared loss: 50.95983731784627\n",
      "loss: 78.90675766200901\n",
      "penalty: 0.2918629453043055\n",
      "h_val:  tensor(0.7941, grad_fn=<SubBackward0>)\n",
      "squared loss: 50.85743608359581\n",
      "loss: 78.8691181795896\n",
      "penalty: 0.3152803293847627\n",
      "h_val:  tensor(0.8029, grad_fn=<SubBackward0>)\n",
      "squared loss: 50.83404496247711\n",
      "loss: 78.86035487331601\n",
      "penalty: 0.3223514397400623\n",
      "h_val:  tensor(0.8047, grad_fn=<SubBackward0>)\n",
      "squared loss: 50.81722625985607\n",
      "loss: 78.85267644166335\n",
      "penalty: 0.3237629504328047\n",
      "h_val:  tensor(0.8040, grad_fn=<SubBackward0>)\n",
      "squared loss: 50.739258623648816\n",
      "loss: 78.81792847498184\n",
      "penalty: 0.3232272162588108\n",
      "h_val:  tensor(0.7943, grad_fn=<SubBackward0>)\n",
      "squared loss: 50.5918623350793\n",
      "loss: 78.75507476634588\n",
      "penalty: 0.31546638554699397\n",
      "h_val:  tensor(0.7653, grad_fn=<SubBackward0>)\n",
      "squared loss: 50.322905415030036\n",
      "loss: 78.6427611296727\n",
      "penalty: 0.2928799177286556\n",
      "h_val:  tensor(0.7214, grad_fn=<SubBackward0>)\n",
      "squared loss: 50.06499691129572\n",
      "loss: 78.54147357375174\n",
      "penalty: 0.26021032833842583\n",
      "h_val:  tensor(0.6975, grad_fn=<SubBackward0>)\n",
      "squared loss: 49.91873676196795\n",
      "loss: 78.48325785061206\n",
      "penalty: 0.24328309850227542\n",
      "h_val:  tensor(0.6831, grad_fn=<SubBackward0>)\n",
      "squared loss: 49.77434285381081\n",
      "loss: 78.43456351324218\n",
      "penalty: 0.23331315527464735\n",
      "h_val:  tensor(0.6809, grad_fn=<SubBackward0>)\n",
      "squared loss: 49.67092752158169\n",
      "loss: 78.39727488902241\n",
      "penalty: 0.2318200040599208\n",
      "h_val:  tensor(0.6934, grad_fn=<SubBackward0>)\n",
      "squared loss: 48.70525165308666\n",
      "loss: 78.08196315906314\n",
      "penalty: 0.24042462347291982\n",
      "h_val:  tensor(0.7394, grad_fn=<SubBackward0>)\n",
      "squared loss: 47.892004290543284\n",
      "loss: 77.89091689986087\n",
      "penalty: 0.2733752635840643\n",
      "h_val:  tensor(0.7547, grad_fn=<SubBackward0>)\n",
      "squared loss: 47.56717252087621\n",
      "loss: 77.80166104554877\n",
      "penalty: 0.2847490723671632\n",
      "h_val:  tensor(0.7675, grad_fn=<SubBackward0>)\n",
      "squared loss: 47.421926903568426\n",
      "loss: 77.71915022274283\n",
      "penalty: 0.29454037551540446\n",
      "h_val:  tensor(0.7740, grad_fn=<SubBackward0>)\n",
      "squared loss: 47.43614006365951\n",
      "loss: 77.7042503917187\n",
      "penalty: 0.2995736974551287\n",
      "h_val:  tensor(0.7762, grad_fn=<SubBackward0>)\n",
      "squared loss: 47.41882452214342\n",
      "loss: 77.67938172888445\n",
      "penalty: 0.3012392988784955\n",
      "h_val:  tensor(0.7854, grad_fn=<SubBackward0>)\n",
      "squared loss: 47.26144699960204\n",
      "loss: 77.55201209239948\n",
      "penalty: 0.3084585852648461\n",
      "h_val:  tensor(0.7981, grad_fn=<SubBackward0>)\n",
      "squared loss: 47.018962455324534\n",
      "loss: 77.47952266207382\n",
      "penalty: 0.3185010006184816\n",
      "h_val:  tensor(0.8194, grad_fn=<SubBackward0>)\n",
      "squared loss: 46.68865590918111\n",
      "loss: 77.41394184018138\n",
      "penalty: 0.3356698543634904\n",
      "h_val:  tensor(0.8311, grad_fn=<SubBackward0>)\n",
      "squared loss: 46.526236822669716\n",
      "loss: 77.35974136546929\n",
      "penalty: 0.3453722483428757\n",
      "h_val:  tensor(0.8231, grad_fn=<SubBackward0>)\n",
      "squared loss: 46.41242575366253\n",
      "loss: 77.28606180788381\n",
      "penalty: 0.33876896123724354\n",
      "h_val:  tensor(0.7946, grad_fn=<SubBackward0>)\n",
      "squared loss: 46.29544864046933\n",
      "loss: 77.21911622795442\n",
      "penalty: 0.31571443030913476\n",
      "h_val:  tensor(0.7663, grad_fn=<SubBackward0>)\n",
      "squared loss: 46.212877700453056\n",
      "loss: 77.16371675410285\n",
      "penalty: 0.29358127721720045\n",
      "h_val:  tensor(0.7384, grad_fn=<SubBackward0>)\n",
      "squared loss: 46.13324526090901\n",
      "loss: 77.11540893761862\n",
      "penalty: 0.2725857295247178\n",
      "h_val:  tensor(0.7212, grad_fn=<SubBackward0>)\n",
      "squared loss: 46.07779821232627\n",
      "loss: 77.09596896595286\n",
      "penalty: 0.26007537711924383\n",
      "h_val:  tensor(0.7012, grad_fn=<SubBackward0>)\n",
      "squared loss: 46.00448316364352\n",
      "loss: 77.07889225867038\n",
      "penalty: 0.24582934764575173\n",
      "h_val:  tensor(0.6885, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.94764756364165\n",
      "loss: 77.06847505712469\n",
      "penalty: 0.2369936444683888\n",
      "h_val:  tensor(0.6784, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.877380310326934\n",
      "loss: 77.05614360151714\n",
      "penalty: 0.2301254432424685\n",
      "h_val:  tensor(0.6681, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.75234345316787\n",
      "loss: 77.03571651056713\n",
      "penalty: 0.2231789725693542\n",
      "h_val:  tensor(0.6659, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.608985887749284\n",
      "loss: 77.0151021482212\n",
      "penalty: 0.22172523678925157\n",
      "h_val:  tensor(0.6755, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.52757995008041\n",
      "loss: 77.00376231868144\n",
      "penalty: 0.22812121879658545\n",
      "h_val:  tensor(0.6843, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.51598851130404\n",
      "loss: 76.99976757144033\n",
      "penalty: 0.23412367944565418\n",
      "h_val:  tensor(0.6893, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.51763694123959\n",
      "loss: 76.9965016025662\n",
      "penalty: 0.23755997286719405\n",
      "h_val:  tensor(0.6940, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.5155890969915\n",
      "loss: 76.98987399290002\n",
      "penalty: 0.24081635357844056\n",
      "h_val:  tensor(0.6965, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.488669131172614\n",
      "loss: 76.97625238051377\n",
      "penalty: 0.24254561695119992\n",
      "h_val:  tensor(0.6971, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.37828176897615\n",
      "loss: 76.94491930754124\n",
      "penalty: 0.2429865803506937\n",
      "h_val:  tensor(0.7573, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.000093243620675\n",
      "loss: 76.94551384038492\n",
      "penalty: 0.28676210634849775\n",
      "h_val:  tensor(0.7161, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.133181697906075\n",
      "loss: 76.89814539275612\n",
      "penalty: 0.2564342642706399\n",
      "h_val:  tensor(0.7115, grad_fn=<SubBackward0>)\n",
      "squared loss: 44.90271139441356\n",
      "loss: 76.8926326114978\n",
      "penalty: 0.2531437236632213\n",
      "h_val:  tensor(0.7102, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.01530112362836\n",
      "loss: 76.87478950005013\n",
      "penalty: 0.25216679326261177\n",
      "h_val:  tensor(0.5975, grad_fn=<SubBackward0>)\n",
      "squared loss: 44.833185272653935\n",
      "loss: 76.81118115276891\n",
      "penalty: 0.17851402759596718\n",
      "h_val:  tensor(0.6008, grad_fn=<SubBackward0>)\n",
      "squared loss: 44.67820028901314\n",
      "loss: 76.78834885571844\n",
      "penalty: 0.18048643597005015\n",
      "h_val:  tensor(0.5963, grad_fn=<SubBackward0>)\n",
      "squared loss: 44.464654552826396\n",
      "loss: 76.7585162967751\n",
      "penalty: 0.17777419212915235\n",
      "h_val:  tensor(0.5913, grad_fn=<SubBackward0>)\n",
      "squared loss: 44.36036756379494\n",
      "loss: 76.74638122986516\n",
      "penalty: 0.17480247766031556\n",
      "h_val:  tensor(0.5826, grad_fn=<SubBackward0>)\n",
      "squared loss: 44.059801371337734\n",
      "loss: 76.69523846413833\n",
      "penalty: 0.16970869969164978\n",
      "h_val:  tensor(0.5878, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.77327428367708\n",
      "loss: 76.62356138921365\n",
      "penalty: 0.1727695230860439\n",
      "h_val:  tensor(0.6013, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.6841395414763\n",
      "loss: 76.57085840525792\n",
      "penalty: 0.18075841081310026\n",
      "h_val:  tensor(0.5882, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.795678853259794\n",
      "loss: 76.5440065089294\n",
      "penalty: 0.1729742299017183\n",
      "h_val:  tensor(0.5825, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.943998051404854\n",
      "loss: 76.51227402229395\n",
      "penalty: 0.16965926434663714\n",
      "h_val:  tensor(0.5755, grad_fn=<SubBackward0>)\n",
      "squared loss: 44.09229578876679\n",
      "loss: 76.47910102439421\n",
      "penalty: 0.1656078469153812\n",
      "h_val:  tensor(0.5778, grad_fn=<SubBackward0>)\n",
      "squared loss: 44.18535422695726\n",
      "loss: 76.41786118981622\n",
      "penalty: 0.16690630947719448\n",
      "h_val:  tensor(0.5797, grad_fn=<SubBackward0>)\n",
      "squared loss: 44.18002356152631\n",
      "loss: 76.36116564935656\n",
      "penalty: 0.16801144026800974\n",
      "h_val:  tensor(0.5815, grad_fn=<SubBackward0>)\n",
      "squared loss: 44.09678891833956\n",
      "loss: 76.3448097615391\n",
      "penalty: 0.16909085178945016\n",
      "h_val:  tensor(0.5792, grad_fn=<SubBackward0>)\n",
      "squared loss: 44.02970345702095\n",
      "loss: 76.33989547184036\n",
      "penalty: 0.16776491444728822\n",
      "h_val:  tensor(0.5733, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.91917323982056\n",
      "loss: 76.33250475174417\n",
      "penalty: 0.16431831690809942\n",
      "h_val:  tensor(0.5647, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.81154451060378\n",
      "loss: 76.32142464639067\n",
      "penalty: 0.1594395275228231\n",
      "h_val:  tensor(0.5491, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.66848630657163\n",
      "loss: 76.29780364478196\n",
      "penalty: 0.15077348967108603\n",
      "h_val:  tensor(0.5359, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.61527201859248\n",
      "loss: 76.27450372037063\n",
      "penalty: 0.14361447749847925\n",
      "h_val:  tensor(0.5330, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.66150555507\n",
      "loss: 76.2651762087764\n",
      "penalty: 0.14203814797101028\n",
      "h_val:  tensor(0.5357, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.69876585581577\n",
      "loss: 76.26109727176731\n",
      "penalty: 0.14350251975305733\n",
      "h_val:  tensor(0.5455, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.76028496653566\n",
      "loss: 76.25213639392128\n",
      "penalty: 0.14876361915277062\n",
      "h_val:  tensor(0.5613, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.8020294072538\n",
      "loss: 76.23960627201585\n",
      "penalty: 0.157533556730246\n",
      "h_val:  tensor(0.5857, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.80208518768535\n",
      "loss: 76.21924786680682\n",
      "penalty: 0.17155009597672383\n",
      "h_val:  tensor(0.6208, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.72379173228321\n",
      "loss: 76.18685058443127\n",
      "penalty: 0.19266803321384815\n",
      "h_val:  tensor(0.6649, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.54605822846266\n",
      "loss: 76.14214532228654\n",
      "penalty: 0.22105199260187589\n",
      "h_val:  tensor(0.6937, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.31538438078939\n",
      "loss: 76.10414795968377\n",
      "penalty: 0.2406372204911717\n",
      "h_val:  tensor(0.6889, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.16301849245268\n",
      "loss: 76.08819771829275\n",
      "penalty: 0.23728871353883904\n",
      "h_val:  tensor(0.6748, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.10930174524293\n",
      "loss: 76.08219404723143\n",
      "penalty: 0.22767851438597833\n",
      "h_val:  tensor(0.6490, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.041498891988034\n",
      "loss: 76.07165537396621\n",
      "penalty: 0.21060616456348544\n",
      "h_val:  tensor(0.6046, grad_fn=<SubBackward0>)\n",
      "squared loss: 42.93272187014193\n",
      "loss: 76.04939569913765\n",
      "penalty: 0.18278373640484355\n",
      "h_val:  tensor(0.5430, grad_fn=<SubBackward0>)\n",
      "squared loss: 42.774385358178996\n",
      "loss: 76.009715282733\n",
      "penalty: 0.14741522053304942\n",
      "h_val:  tensor(0.5034, grad_fn=<SubBackward0>)\n",
      "squared loss: 42.64589138033667\n",
      "loss: 75.97596756751125\n",
      "penalty: 0.126714194123982\n",
      "h_val:  tensor(0.5047, grad_fn=<SubBackward0>)\n",
      "squared loss: 42.64182676379371\n",
      "loss: 75.964230359795\n",
      "penalty: 0.12737496943749\n",
      "h_val:  tensor(0.5199, grad_fn=<SubBackward0>)\n",
      "squared loss: 42.70586311416497\n",
      "loss: 75.95456958934672\n",
      "penalty: 0.1351570171598032\n",
      "h_val:  tensor(0.5382, grad_fn=<SubBackward0>)\n",
      "squared loss: 42.79186107327765\n",
      "loss: 75.94582024610663\n",
      "penalty: 0.14484836258620098\n",
      "h_val:  tensor(0.5573, grad_fn=<SubBackward0>)\n",
      "squared loss: 42.88228710952441\n",
      "loss: 75.93152616836342\n",
      "penalty: 0.15531055111438316\n",
      "h_val:  tensor(0.6041, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.05638580445049\n",
      "loss: 75.88897864262682\n",
      "penalty: 0.18245241130109405\n",
      "h_val:  tensor(0.8252, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.52442725323606\n",
      "loss: 75.90692387096956\n",
      "penalty: 0.3405064084358452\n",
      "h_val:  tensor(0.6945, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.251451071901705\n",
      "loss: 75.83326620311529\n",
      "penalty: 0.24118972975400202\n",
      "h_val:  tensor(0.7595, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.28912608748574\n",
      "loss: 75.77613517924729\n",
      "penalty: 0.28840294022883434\n",
      "h_val:  tensor(0.7813, grad_fn=<SubBackward0>)\n",
      "squared loss: 42.91951871024846\n",
      "loss: 75.53579903597904\n",
      "penalty: 0.30525178276849785\n",
      "h_val:  tensor(0.8144, grad_fn=<SubBackward0>)\n",
      "squared loss: 41.957635804767634\n",
      "loss: 75.17876919042456\n",
      "penalty: 0.3316485749894206\n",
      "h_val:  tensor(1.7613, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.91593381705424\n",
      "loss: 79.13376564312804\n",
      "penalty: 1.55106967964991\n",
      "h_val:  tensor(0.8523, grad_fn=<SubBackward0>)\n",
      "squared loss: 41.83271976754928\n",
      "loss: 75.14524953552777\n",
      "penalty: 0.36319320446137426\n",
      "h_val:  tensor(1.0489, grad_fn=<SubBackward0>)\n",
      "squared loss: 41.46527217106901\n",
      "loss: 75.57147733461342\n",
      "penalty: 0.5501451285154667\n",
      "h_val:  tensor(0.8852, grad_fn=<SubBackward0>)\n",
      "squared loss: 41.604209495335546\n",
      "loss: 75.10177902685082\n",
      "penalty: 0.39176798885698955\n",
      "h_val:  tensor(0.9099, grad_fn=<SubBackward0>)\n",
      "squared loss: 41.3836997377266\n",
      "loss: 75.06991488810282\n",
      "penalty: 0.4139441422892756\n",
      "h_val:  tensor(0.8838, grad_fn=<SubBackward0>)\n",
      "squared loss: 41.29685857653608\n",
      "loss: 74.98583114848638\n",
      "penalty: 0.39057426967025616\n",
      "h_val:  tensor(0.8657, grad_fn=<SubBackward0>)\n",
      "squared loss: 40.70101419232574\n",
      "loss: 74.57517819607948\n",
      "penalty: 0.37475819927333653\n",
      "h_val:  tensor(0.8216, grad_fn=<SubBackward0>)\n",
      "squared loss: 40.638529081512004\n",
      "loss: 74.48544316144482\n",
      "penalty: 0.3375216850311011\n",
      "h_val:  tensor(0.7737, grad_fn=<SubBackward0>)\n",
      "squared loss: 40.19141823015217\n",
      "loss: 74.22732909230028\n",
      "penalty: 0.2993157002284128\n",
      "h_val:  tensor(0.6111, grad_fn=<SubBackward0>)\n",
      "squared loss: 39.633404163149144\n",
      "loss: 74.06064793077434\n",
      "penalty: 0.18669722196869387\n",
      "h_val:  tensor(0.6440, grad_fn=<SubBackward0>)\n",
      "squared loss: 39.72115654394147\n",
      "loss: 73.91206768014304\n",
      "penalty: 0.20738413512891574\n",
      "h_val:  tensor(0.4451, grad_fn=<SubBackward0>)\n",
      "squared loss: 39.59922826901447\n",
      "loss: 73.64755029517917\n",
      "penalty: 0.0990575653668787\n",
      "h_val:  tensor(0.4072, grad_fn=<SubBackward0>)\n",
      "squared loss: 39.65974190895564\n",
      "loss: 73.59529446105999\n",
      "penalty: 0.0828975551113476\n",
      "h_val:  tensor(0.4414, grad_fn=<SubBackward0>)\n",
      "squared loss: 39.48123585561497\n",
      "loss: 73.5089163975738\n",
      "penalty: 0.09743334313421143\n",
      "h_val:  tensor(0.6691, grad_fn=<SubBackward0>)\n",
      "squared loss: 38.99607356337154\n",
      "loss: 73.37515396889879\n",
      "penalty: 0.2238733180111657\n",
      "h_val:  tensor(0.6168, grad_fn=<SubBackward0>)\n",
      "squared loss: 39.00710843218866\n",
      "loss: 73.32196903918248\n",
      "penalty: 0.19020358759702746\n",
      "h_val:  tensor(0.6019, grad_fn=<SubBackward0>)\n",
      "squared loss: 38.883078208005344\n",
      "loss: 73.22752495727005\n",
      "penalty: 0.18113605983016867\n",
      "h_val:  tensor(0.6144, grad_fn=<SubBackward0>)\n",
      "squared loss: 38.584750525727145\n",
      "loss: 73.09312858725187\n",
      "penalty: 0.1887175317500761\n",
      "h_val:  tensor(0.6731, grad_fn=<SubBackward0>)\n",
      "squared loss: 38.0611068818922\n",
      "loss: 72.90825812586125\n",
      "penalty: 0.2265075336979274\n",
      "h_val:  tensor(0.7404, grad_fn=<SubBackward0>)\n",
      "squared loss: 37.609745819355595\n",
      "loss: 72.78524307473654\n",
      "penalty: 0.27408234938598075\n",
      "h_val:  tensor(0.7685, grad_fn=<SubBackward0>)\n",
      "squared loss: 37.43320288856096\n",
      "loss: 72.70962794349425\n",
      "penalty: 0.29533170036019707\n",
      "h_val:  tensor(0.8540, grad_fn=<SubBackward0>)\n",
      "squared loss: 37.179896771761605\n",
      "loss: 72.61571029093497\n",
      "penalty: 0.3646798259400173\n",
      "h_val:  tensor(0.7711, grad_fn=<SubBackward0>)\n",
      "squared loss: 37.23494824003596\n",
      "loss: 72.49837263567102\n",
      "penalty: 0.2973318386062115\n",
      "h_val:  tensor(0.7239, grad_fn=<SubBackward0>)\n",
      "squared loss: 37.2037585348388\n",
      "loss: 72.36690748020132\n",
      "penalty: 0.2619839608266133\n",
      "h_val:  tensor(0.7024, grad_fn=<SubBackward0>)\n",
      "squared loss: 37.11874444388384\n",
      "loss: 72.27897645338427\n",
      "penalty: 0.24671521440517766\n",
      "h_val:  tensor(0.7302, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.83798313518313\n",
      "loss: 72.17022498667706\n",
      "penalty: 0.26656682173965834\n",
      "h_val:  tensor(0.9380, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.99770974671332\n",
      "loss: 72.03324718365018\n",
      "penalty: 0.43990712479943267\n",
      "h_val:  tensor(0.8025, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.08339636482113\n",
      "loss: 71.93026931210234\n",
      "penalty: 0.3220240682211906\n",
      "h_val:  tensor(0.6504, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.86767571921162\n",
      "loss: 71.75491625615665\n",
      "penalty: 0.21152800472700845\n",
      "h_val:  tensor(0.5469, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.34827162209903\n",
      "loss: 71.49944905014766\n",
      "penalty: 0.1495719405028821\n",
      "h_val:  tensor(0.6131, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.2994221761333\n",
      "loss: 71.93402828037564\n",
      "penalty: 0.1879215104538945\n",
      "h_val:  tensor(0.5337, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.22633880830331\n",
      "loss: 71.46105474143346\n",
      "penalty: 0.14244408834730624\n",
      "h_val:  tensor(0.4401, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.17126133257645\n",
      "loss: 71.40519760998697\n",
      "penalty: 0.09682225077072172\n",
      "h_val:  tensor(0.3982, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.13536386135777\n",
      "loss: 71.38156757652334\n",
      "penalty: 0.07928662812925505\n",
      "h_val:  tensor(0.3918, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.023577848973126\n",
      "loss: 71.35345668061936\n",
      "penalty: 0.07673783718469103\n",
      "h_val:  tensor(0.4083, grad_fn=<SubBackward0>)\n",
      "squared loss: 34.74970211454478\n",
      "loss: 71.27947792017663\n",
      "penalty: 0.08333947405479844\n",
      "h_val:  tensor(0.4589, grad_fn=<SubBackward0>)\n",
      "squared loss: 34.44050467196843\n",
      "loss: 71.22082483195436\n",
      "penalty: 0.10529126295291091\n",
      "h_val:  tensor(0.4921, grad_fn=<SubBackward0>)\n",
      "squared loss: 34.16662608100595\n",
      "loss: 71.16150145053832\n",
      "penalty: 0.12110483175022589\n",
      "h_val:  tensor(0.6375, grad_fn=<SubBackward0>)\n",
      "squared loss: 33.70417717633565\n",
      "loss: 71.12186334647595\n",
      "penalty: 0.20320149172730154\n",
      "h_val:  tensor(0.5684, grad_fn=<SubBackward0>)\n",
      "squared loss: 33.58282462571582\n",
      "loss: 71.01897769449423\n",
      "penalty: 0.16151501120135364\n",
      "h_val:  tensor(0.6151, grad_fn=<SubBackward0>)\n",
      "squared loss: 33.288943181052055\n",
      "loss: 70.93520913231006\n",
      "penalty: 0.18917172791699693\n",
      "h_val:  tensor(0.8758, grad_fn=<SubBackward0>)\n",
      "squared loss: 32.62763974276327\n",
      "loss: 70.92715032268666\n",
      "penalty: 0.3835358424863977\n",
      "h_val:  tensor(0.6742, grad_fn=<SubBackward0>)\n",
      "squared loss: 33.03854392747619\n",
      "loss: 70.8746990680263\n",
      "penalty: 0.2272403603248615\n",
      "h_val:  tensor(0.8136, grad_fn=<SubBackward0>)\n",
      "squared loss: 32.45512301355513\n",
      "loss: 70.78010102772005\n",
      "penalty: 0.3309492808595692\n",
      "h_val:  tensor(0.5828, grad_fn=<SubBackward0>)\n",
      "squared loss: 32.63610657441811\n",
      "loss: 70.67368121771169\n",
      "penalty: 0.1698374130340481\n",
      "h_val:  tensor(0.6138, grad_fn=<SubBackward0>)\n",
      "squared loss: 32.349625091867765\n",
      "loss: 70.5308572940921\n",
      "penalty: 0.1883474351609654\n",
      "h_val:  tensor(0.6140, grad_fn=<SubBackward0>)\n",
      "squared loss: 32.15956847115528\n",
      "loss: 70.41226802880449\n",
      "penalty: 0.188483551635861\n",
      "h_val:  tensor(0.6753, grad_fn=<SubBackward0>)\n",
      "squared loss: 31.641814577810987\n",
      "loss: 70.21286292336895\n",
      "penalty: 0.2279981626212066\n",
      "h_val:  tensor(0.7748, grad_fn=<SubBackward0>)\n",
      "squared loss: 31.114183954989713\n",
      "loss: 70.0946714153632\n",
      "penalty: 0.30014452745922976\n",
      "h_val:  tensor(1.1303, grad_fn=<SubBackward0>)\n",
      "squared loss: 29.29260157486073\n",
      "loss: 69.84928501816945\n",
      "penalty: 0.6387417298072533\n",
      "h_val:  tensor(0.9441, grad_fn=<SubBackward0>)\n",
      "squared loss: 29.523905253787834\n",
      "loss: 69.69097891513263\n",
      "penalty: 0.44562746777007956\n",
      "h_val:  tensor(0.7087, grad_fn=<SubBackward0>)\n",
      "squared loss: 29.17285758535023\n",
      "loss: 69.41885385277148\n",
      "penalty: 0.2511395590310176\n",
      "h_val:  tensor(0.5344, grad_fn=<SubBackward0>)\n",
      "squared loss: 28.83076354728024\n",
      "loss: 69.22968711734141\n",
      "penalty: 0.14278443159969212\n",
      "h_val:  tensor(0.4653, grad_fn=<SubBackward0>)\n",
      "squared loss: 28.377364220926783\n",
      "loss: 69.06188843538631\n",
      "penalty: 0.10825029213087499\n",
      "h_val:  tensor(0.6147, grad_fn=<SubBackward0>)\n",
      "squared loss: 28.318878059496896\n",
      "loss: 69.25175057523802\n",
      "penalty: 0.18890572445216366\n",
      "h_val:  tensor(0.4761, grad_fn=<SubBackward0>)\n",
      "squared loss: 28.272279245244704\n",
      "loss: 69.01870109573682\n",
      "penalty: 0.1133256847323741\n",
      "h_val:  tensor(0.4681, grad_fn=<SubBackward0>)\n",
      "squared loss: 28.17034617816502\n",
      "loss: 68.98426965460065\n",
      "penalty: 0.10953923480428625\n",
      "h_val:  tensor(0.4216, grad_fn=<SubBackward0>)\n",
      "squared loss: 28.216597812030905\n",
      "loss: 68.96403744862292\n",
      "penalty: 0.08888265443457777\n",
      "h_val:  tensor(0.4309, grad_fn=<SubBackward0>)\n",
      "squared loss: 28.20425822522498\n",
      "loss: 68.9134272721999\n",
      "penalty: 0.09285567931337085\n",
      "h_val:  tensor(0.5727, grad_fn=<SubBackward0>)\n",
      "squared loss: 28.10456509027665\n",
      "loss: 68.97956901959499\n",
      "penalty: 0.1640183127068367\n",
      "h_val:  tensor(0.4628, grad_fn=<SubBackward0>)\n",
      "squared loss: 28.09054916845235\n",
      "loss: 68.85273092387261\n",
      "penalty: 0.10709397611017855\n",
      "h_val:  tensor(0.4288, grad_fn=<SubBackward0>)\n",
      "squared loss: 27.93246095247431\n",
      "loss: 68.6875777735802\n",
      "penalty: 0.09194901166859665\n",
      "h_val:  tensor(0.5487, grad_fn=<SubBackward0>)\n",
      "squared loss: 27.3866109460096\n",
      "loss: 68.53818628754799\n",
      "penalty: 0.15051238756739665\n",
      "h_val:  tensor(0.6236, grad_fn=<SubBackward0>)\n",
      "squared loss: 26.949215680832296\n",
      "loss: 68.47535558516678\n",
      "penalty: 0.1944646882690725\n",
      "h_val:  tensor(0.6018, grad_fn=<SubBackward0>)\n",
      "squared loss: 26.55875169337089\n",
      "loss: 68.42886982562803\n",
      "penalty: 0.1810938043119925\n",
      "h_val:  tensor(0.5967, grad_fn=<SubBackward0>)\n",
      "squared loss: 26.365914000726143\n",
      "loss: 68.39550456169972\n",
      "penalty: 0.17802629534859604\n",
      "h_val:  tensor(0.6492, grad_fn=<SubBackward0>)\n",
      "squared loss: 25.330158001654503\n",
      "loss: 68.24397693362904\n",
      "penalty: 0.21070227408882727\n",
      "h_val:  tensor(0.5714, grad_fn=<SubBackward0>)\n",
      "squared loss: 25.173763992372848\n",
      "loss: 68.16765828937139\n",
      "penalty: 0.16325986093905964\n",
      "h_val:  tensor(0.5496, grad_fn=<SubBackward0>)\n",
      "squared loss: 25.066064153717623\n",
      "loss: 68.1425904222696\n",
      "penalty: 0.15100295161022134\n",
      "h_val:  tensor(0.5102, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.957811227285852\n",
      "loss: 68.10743536279745\n",
      "penalty: 0.1301661838360002\n",
      "h_val:  tensor(0.5652, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.493033765442835\n",
      "loss: 68.08641804377372\n",
      "penalty: 0.15971465277656696\n",
      "h_val:  tensor(0.4954, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.48975800429248\n",
      "loss: 68.02915647343667\n",
      "penalty: 0.1227032908628357\n",
      "h_val:  tensor(0.4873, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.396942011251678\n",
      "loss: 68.00372926509985\n",
      "penalty: 0.11871183953829137\n",
      "h_val:  tensor(0.4704, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.384297662426825\n",
      "loss: 67.9748181249528\n",
      "penalty: 0.11063113099664815\n",
      "h_val:  tensor(0.4568, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.469809030999205\n",
      "loss: 67.96293605079711\n",
      "penalty: 0.10433291733122617\n",
      "h_val:  tensor(0.4109, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.639971052311775\n",
      "loss: 67.92040269042512\n",
      "penalty: 0.08441590384602495\n",
      "h_val:  tensor(0.3943, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.667153191182432\n",
      "loss: 67.89196180622962\n",
      "penalty: 0.07772648850322511\n",
      "h_val:  tensor(0.3962, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.544436072223117\n",
      "loss: 67.86755572660014\n",
      "penalty: 0.07848411757490112\n",
      "h_val:  tensor(0.3994, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.27148434592017\n",
      "loss: 67.84175208152602\n",
      "penalty: 0.07974193377274535\n",
      "h_val:  tensor(0.4366, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.784251025076298\n",
      "loss: 67.80696758090505\n",
      "penalty: 0.09531379437927892\n",
      "h_val:  tensor(0.4594, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.14358605069142\n",
      "loss: 67.77784869610032\n",
      "penalty: 0.10550827376186404\n",
      "h_val:  tensor(0.4775, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.13849485407123\n",
      "loss: 67.76651960490476\n",
      "penalty: 0.11398231585287977\n",
      "h_val:  tensor(0.5074, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.239912571385904\n",
      "loss: 67.75678413170411\n",
      "penalty: 0.12873895184511655\n",
      "h_val:  tensor(0.5063, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.23741201097698\n",
      "loss: 67.74895073076989\n",
      "penalty: 0.12817424104955794\n",
      "h_val:  tensor(0.5234, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.14116277864504\n",
      "loss: 67.73517297100308\n",
      "penalty: 0.13697415071774208\n",
      "h_val:  tensor(0.5278, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.080140963865535\n",
      "loss: 67.72630599189502\n",
      "penalty: 0.13930196974678033\n",
      "h_val:  tensor(0.5213, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.001720373877006\n",
      "loss: 67.71719935785526\n",
      "penalty: 0.13586377449543371\n",
      "h_val:  tensor(0.5023, grad_fn=<SubBackward0>)\n",
      "squared loss: 22.91359582443336\n",
      "loss: 67.70738574395939\n",
      "penalty: 0.12614163517487606\n",
      "h_val:  tensor(0.4608, grad_fn=<SubBackward0>)\n",
      "squared loss: 22.805383133153274\n",
      "loss: 67.69356015518879\n",
      "penalty: 0.10618888135146595\n",
      "h_val:  tensor(0.4081, grad_fn=<SubBackward0>)\n",
      "squared loss: 22.74117031008299\n",
      "loss: 67.68241606078709\n",
      "penalty: 0.08328798463062163\n",
      "h_val:  tensor(0.4019, grad_fn=<SubBackward0>)\n",
      "squared loss: 22.801153861339408\n",
      "loss: 67.67944390672857\n",
      "penalty: 0.0807764479753046\n",
      "h_val:  tensor(0.3984, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.042472823289273\n",
      "loss: 67.66979609081076\n",
      "penalty: 0.0793683034468157\n",
      "h_val:  tensor(0.3879, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.190738020838698\n",
      "loss: 67.6602098212382\n",
      "penalty: 0.07524880976983937\n",
      "h_val:  tensor(0.3739, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.431104278749334\n",
      "loss: 67.63637219611675\n",
      "penalty: 0.06989628625838563\n",
      "h_val:  tensor(0.3873, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.57065671769127\n",
      "loss: 67.60813144311356\n",
      "penalty: 0.07501789055547917\n",
      "h_val:  tensor(0.4441, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.5529936154313\n",
      "loss: 67.58117060394397\n",
      "penalty: 0.09860839584675778\n",
      "h_val:  tensor(0.4996, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.349316219729445\n",
      "loss: 67.56418570502434\n",
      "penalty: 0.12479252692397831\n",
      "h_val:  tensor(0.5208, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.007996026112234\n",
      "loss: 67.5362073689735\n",
      "penalty: 0.13559047908321684\n",
      "h_val:  tensor(0.5017, grad_fn=<SubBackward0>)\n",
      "squared loss: 22.779184877887584\n",
      "loss: 67.51702702139912\n",
      "penalty: 0.12584821764468637\n",
      "h_val:  tensor(0.5020, grad_fn=<SubBackward0>)\n",
      "squared loss: 22.76542341987636\n",
      "loss: 67.50427511075436\n",
      "penalty: 0.12600351608987226\n",
      "h_val:  tensor(0.5111, grad_fn=<SubBackward0>)\n",
      "squared loss: 22.914400903869677\n",
      "loss: 67.49569216928084\n",
      "penalty: 0.13063329655917585\n",
      "h_val:  tensor(0.5219, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.031459593119347\n",
      "loss: 67.49218405037918\n",
      "penalty: 0.13618475187929666\n",
      "h_val:  tensor(0.5311, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.13876631125858\n",
      "loss: 67.48408923972443\n",
      "penalty: 0.14103874894175625\n",
      "h_val:  tensor(0.5623, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.408032715406815\n",
      "loss: 67.45239302706976\n",
      "penalty: 0.15808486259718646\n",
      "h_val:  tensor(0.5909, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.579812892218452\n",
      "loss: 67.40750068403409\n",
      "penalty: 0.17459192912825278\n",
      "h_val:  tensor(0.6470, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.569575364184566\n",
      "loss: 67.32218805274017\n",
      "penalty: 0.2093030976099089\n",
      "h_val:  tensor(0.6418, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.321776007728133\n",
      "loss: 67.21115545316081\n",
      "penalty: 0.20596868451637274\n",
      "h_val:  tensor(0.7086, grad_fn=<SubBackward0>)\n",
      "squared loss: 22.68232150600855\n",
      "loss: 67.10176347516688\n",
      "penalty: 0.2510626957947202\n",
      "h_val:  tensor(0.6530, grad_fn=<SubBackward0>)\n",
      "squared loss: 21.848039432629676\n",
      "loss: 66.96912824689822\n",
      "penalty: 0.21320614395465295\n",
      "h_val:  tensor(0.6819, grad_fn=<SubBackward0>)\n",
      "squared loss: 21.61323578796552\n",
      "loss: 66.86477449185578\n",
      "penalty: 0.23252186227816554\n",
      "h_val:  tensor(0.8453, grad_fn=<SubBackward0>)\n",
      "squared loss: 21.403233335628812\n",
      "loss: 66.4443344874199\n",
      "penalty: 0.35730735680271497\n",
      "h_val:  tensor(1.1335, grad_fn=<SubBackward0>)\n",
      "squared loss: 21.61446961438375\n",
      "loss: 66.33337441532429\n",
      "penalty: 0.6424136028394991\n",
      "h_val:  tensor(1.0251, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.43304960416752\n",
      "loss: 66.17497477085075\n",
      "penalty: 0.5254171663495639\n",
      "h_val:  tensor(1.0156, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.215723926091133\n",
      "loss: 66.03383786806077\n",
      "penalty: 0.5156989925473796\n",
      "h_val:  tensor(1.0112, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.29282390881594\n",
      "loss: 65.8194820810963\n",
      "penalty: 0.511259846036176\n",
      "h_val:  tensor(1.0241, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.768731514108712\n",
      "loss: 65.66066764078597\n",
      "penalty: 0.5244404214655733\n",
      "h_val:  tensor(0.9848, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.62508471095818\n",
      "loss: 65.49291786959402\n",
      "penalty: 0.48491710120220116\n",
      "h_val:  tensor(0.8122, grad_fn=<SubBackward0>)\n",
      "squared loss: 25.474411621132067\n",
      "loss: 65.31508893847631\n",
      "penalty: 0.3298340562445322\n",
      "h_val:  tensor(0.8733, grad_fn=<SubBackward0>)\n",
      "squared loss: 25.779485999837313\n",
      "loss: 65.21610261328824\n",
      "penalty: 0.3813343142903336\n",
      "h_val:  tensor(0.8160, grad_fn=<SubBackward0>)\n",
      "squared loss: 25.48487065354392\n",
      "loss: 65.12327535950399\n",
      "penalty: 0.33290261466296023\n",
      "h_val:  tensor(0.8177, grad_fn=<SubBackward0>)\n",
      "squared loss: 25.41997040113285\n",
      "loss: 65.04421152813515\n",
      "penalty: 0.33431407735678453\n",
      "h_val:  tensor(0.9086, grad_fn=<SubBackward0>)\n",
      "squared loss: 25.43864261605704\n",
      "loss: 64.58276282685875\n",
      "penalty: 0.4127563484610185\n",
      "h_val:  tensor(1.2412, grad_fn=<SubBackward0>)\n",
      "squared loss: 25.440732942030763\n",
      "loss: 64.0683067590492\n",
      "penalty: 0.7702692430614262\n",
      "h_val:  tensor(1.1820, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.918544693510555\n",
      "loss: 63.719960006791\n",
      "penalty: 0.6985391052356055\n",
      "h_val:  tensor(1.1786, grad_fn=<SubBackward0>)\n",
      "squared loss: 23.188003596752452\n",
      "loss: 61.983162381107306\n",
      "penalty: 0.6945532837739354\n",
      "h_val:  tensor(5.0284, grad_fn=<SubBackward0>)\n",
      "squared loss: 24.785344525636532\n",
      "loss: 71.98788140262728\n",
      "penalty: 12.642333744914007\n",
      "h_val:  tensor(1.7548, grad_fn=<SubBackward0>)\n",
      "squared loss: 21.57054168699983\n",
      "loss: 60.05709173258825\n",
      "penalty: 1.5396924863082573\n",
      "h_val:  tensor(4.7502, grad_fn=<SubBackward0>)\n",
      "squared loss: 26.730453063522763\n",
      "loss: 69.50621513558576\n",
      "penalty: 11.282227309662364\n",
      "h_val:  tensor(2.0701, grad_fn=<SubBackward0>)\n",
      "squared loss: 20.65276944640235\n",
      "loss: 58.38975527586046\n",
      "penalty: 2.142645198491013\n",
      "h_val:  tensor(2.3083, grad_fn=<SubBackward0>)\n",
      "squared loss: 21.010529329188035\n",
      "loss: 56.747016001694895\n",
      "penalty: 2.6641404951505407\n",
      "h_val:  tensor(1.4779, grad_fn=<SubBackward0>)\n",
      "squared loss: 21.359093223679434\n",
      "loss: 56.475373657870676\n",
      "penalty: 1.0921354580914986\n",
      "h_val:  tensor(1.7113, grad_fn=<SubBackward0>)\n",
      "squared loss: 20.171575845527723\n",
      "loss: 55.18931562231474\n",
      "penalty: 1.4642757562732767\n",
      "h_val:  tensor(1.7314, grad_fn=<SubBackward0>)\n",
      "squared loss: 19.676913423631937\n",
      "loss: 54.54507488636853\n",
      "penalty: 1.4988094925561517\n",
      "h_val:  tensor(1.6270, grad_fn=<SubBackward0>)\n",
      "squared loss: 18.74645704041199\n",
      "loss: 52.64907301217306\n",
      "penalty: 1.323527051842482\n",
      "h_val:  tensor(1.4359, grad_fn=<SubBackward0>)\n",
      "squared loss: 18.7372364294716\n",
      "loss: 51.412971504705666\n",
      "penalty: 1.0309148879360275\n",
      "h_val:  tensor(1.2799, grad_fn=<SubBackward0>)\n",
      "squared loss: 19.46114047408838\n",
      "loss: 50.76177871185265\n",
      "penalty: 0.8191299312914653\n",
      "h_val:  tensor(1.2462, grad_fn=<SubBackward0>)\n",
      "squared loss: 19.021232053083\n",
      "loss: 50.50706138582196\n",
      "penalty: 0.7765665894268401\n",
      "h_val:  tensor(1.1008, grad_fn=<SubBackward0>)\n",
      "squared loss: 17.71044383715471\n",
      "loss: 49.79328924106639\n",
      "penalty: 0.6058593635212752\n",
      "h_val:  tensor(1.2389, grad_fn=<SubBackward0>)\n",
      "squared loss: 17.411927952098587\n",
      "loss: 49.43058828491326\n",
      "penalty: 0.7674583734713525\n",
      "h_val:  tensor(1.5479, grad_fn=<SubBackward0>)\n",
      "squared loss: 16.262900874548436\n",
      "loss: 48.5198678226412\n",
      "penalty: 1.1980169967531553\n",
      "h_val:  tensor(1.9527, grad_fn=<SubBackward0>)\n",
      "squared loss: 14.47840325394915\n",
      "loss: 47.42562068000018\n",
      "penalty: 1.9064525914423396\n",
      "h_val:  tensor(2.0500, grad_fn=<SubBackward0>)\n",
      "squared loss: 12.532301578265237\n",
      "loss: 46.01651613280753\n",
      "penalty: 2.101250494959074\n",
      "h_val:  tensor(1.7205, grad_fn=<SubBackward0>)\n",
      "squared loss: 10.390109700119043\n",
      "loss: 43.86846572858846\n",
      "penalty: 1.4800148231120902\n",
      "h_val:  tensor(1.2401, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.70954956171491\n",
      "loss: 42.87710637857832\n",
      "penalty: 0.7689594895186568\n",
      "h_val:  tensor(0.8523, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.414439845011414\n",
      "loss: 42.38409947004815\n",
      "penalty: 0.36316546641862146\n",
      "h_val:  tensor(0.6177, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.970188413165253\n",
      "loss: 42.12043806458132\n",
      "penalty: 0.19079954653381934\n",
      "h_val:  tensor(0.5054, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.78269495292803\n",
      "loss: 41.94824121741223\n",
      "penalty: 0.12770130096800636\n",
      "h_val:  tensor(0.3938, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.469624431967937\n",
      "loss: 41.69459699286956\n",
      "penalty: 0.0775506528114961\n",
      "h_val:  tensor(0.3608, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.411090254627094\n",
      "loss: 41.56923675352838\n",
      "penalty: 0.06509534137458098\n",
      "h_val:  tensor(0.3311, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.50368494717959\n",
      "loss: 41.464904732615594\n",
      "penalty: 0.05480186629155271\n",
      "h_val:  tensor(0.3161, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.674142644438746\n",
      "loss: 41.397716016082775\n",
      "penalty: 0.04996907400529525\n",
      "h_val:  tensor(0.2959, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.793127210766938\n",
      "loss: 41.37878449912718\n",
      "penalty: 0.043774009427577615\n",
      "h_val:  tensor(0.2941, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.835682851281984\n",
      "loss: 41.36500759607046\n",
      "penalty: 0.04324636360591916\n",
      "h_val:  tensor(0.2941, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.855069143641963\n",
      "loss: 41.35570301390851\n",
      "penalty: 0.043243452741162536\n",
      "h_val:  tensor(0.2965, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.8693020784604\n",
      "loss: 41.35153933350234\n",
      "penalty: 0.043954016833336586\n",
      "h_val:  tensor(0.3016, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.919662621030387\n",
      "loss: 41.34444941854342\n",
      "penalty: 0.04547939600292582\n",
      "h_val:  tensor(0.3015, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.960129135071078\n",
      "loss: 41.34095340455889\n",
      "penalty: 0.045462615150820236\n",
      "h_val:  tensor(0.2979, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.00687817957407\n",
      "loss: 41.33756328901639\n",
      "penalty: 0.04437063064106009\n",
      "h_val:  tensor(0.2923, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.03906489637931\n",
      "loss: 41.3339257109023\n",
      "penalty: 0.04271716499209756\n",
      "h_val:  tensor(0.2813, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.080708414900004\n",
      "loss: 41.3268584597197\n",
      "penalty: 0.039553043063386556\n",
      "h_val:  tensor(0.2729, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.08947636356976\n",
      "loss: 41.32065418508982\n",
      "penalty: 0.037228697473621196\n",
      "h_val:  tensor(0.2693, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.063823837967954\n",
      "loss: 41.31667171564039\n",
      "penalty: 0.03626854377372999\n",
      "h_val:  tensor(0.2696, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.03666204182394\n",
      "loss: 41.31546410637525\n",
      "penalty: 0.03633138945417295\n",
      "h_val:  tensor(0.2702, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.028902607091092\n",
      "loss: 41.31508198276761\n",
      "penalty: 0.03649575658547518\n",
      "h_val:  tensor(0.2705, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.025877977611962\n",
      "loss: 41.31453942443185\n",
      "penalty: 0.03658415976162666\n",
      "h_val:  tensor(0.2697, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.028995131183883\n",
      "loss: 41.31344295349686\n",
      "penalty: 0.03636899312407983\n",
      "h_val:  tensor(0.2658, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.046937441932112\n",
      "loss: 41.31137886251504\n",
      "penalty: 0.035322154868718335\n",
      "h_val:  tensor(0.2572, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.086495013798237\n",
      "loss: 41.3084300763488\n",
      "penalty: 0.033086671437853855\n",
      "h_val:  tensor(0.2467, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.135958241805977\n",
      "loss: 41.305580698335326\n",
      "penalty: 0.030433688264896997\n",
      "h_val:  tensor(0.2394, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.170775234395556\n",
      "loss: 41.303904286644546\n",
      "penalty: 0.02864751585544342\n",
      "h_val:  tensor(0.2357, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.186702877589\n",
      "loss: 41.303145082818716\n",
      "penalty: 0.02777128847792817\n",
      "h_val:  tensor(0.2327, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.196972988182784\n",
      "loss: 41.302420223358325\n",
      "penalty: 0.027069055652731138\n",
      "h_val:  tensor(0.2287, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.20662983438528\n",
      "loss: 41.30123531921015\n",
      "penalty: 0.026149511273181464\n",
      "h_val:  tensor(0.2250, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.208358499365099\n",
      "loss: 41.299847103858795\n",
      "penalty: 0.02531261121866127\n",
      "h_val:  tensor(0.2229, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.194545001270127\n",
      "loss: 41.29855524585585\n",
      "penalty: 0.024843773280454565\n",
      "h_val:  tensor(0.2214, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.164929958884265\n",
      "loss: 41.297129840232515\n",
      "penalty: 0.024507716791976216\n",
      "h_val:  tensor(0.2193, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.14362464496057\n",
      "loss: 41.29602636757211\n",
      "penalty: 0.024045907695002925\n",
      "h_val:  tensor(0.2155, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.137668868154346\n",
      "loss: 41.29506634204905\n",
      "penalty: 0.02322688512521369\n",
      "h_val:  tensor(0.2093, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.14768693282877\n",
      "loss: 41.29403786262066\n",
      "penalty: 0.021897958476049504\n",
      "h_val:  tensor(0.2024, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.17242115911239\n",
      "loss: 41.29301241804654\n",
      "penalty: 0.020477838815101037\n",
      "h_val:  tensor(0.1937, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.219664807734958\n",
      "loss: 41.29133054501779\n",
      "penalty: 0.018768910982140133\n",
      "h_val:  tensor(0.1867, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.29256187588808\n",
      "loss: 41.28955942366643\n",
      "penalty: 0.017419993815337327\n",
      "h_val:  tensor(0.1865, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.303555399925372\n",
      "loss: 41.287365627851194\n",
      "penalty: 0.01738400640786366\n",
      "h_val:  tensor(0.1843, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.334551788740889\n",
      "loss: 41.28174877257904\n",
      "penalty: 0.016981395147566858\n",
      "h_val:  tensor(0.1836, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.317302177738247\n",
      "loss: 41.28066399955192\n",
      "penalty: 0.016849866828394053\n",
      "h_val:  tensor(0.1818, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.306937607243269\n",
      "loss: 41.27992639022164\n",
      "penalty: 0.016524654476149113\n",
      "h_val:  tensor(0.1812, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.292360720045826\n",
      "loss: 41.27941070852935\n",
      "penalty: 0.016410274112851068\n",
      "h_val:  tensor(0.1795, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.29771330785182\n",
      "loss: 41.278834889992545\n",
      "penalty: 0.01610477149229949\n",
      "h_val:  tensor(0.1783, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.303008312686782\n",
      "loss: 41.27848150981586\n",
      "penalty: 0.01589920715956115\n",
      "h_val:  tensor(0.1769, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.322572435676552\n",
      "loss: 41.278226783318566\n",
      "penalty: 0.01565432142891202\n",
      "h_val:  tensor(0.1756, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.332455023546158\n",
      "loss: 41.277950678814946\n",
      "penalty: 0.015410719298856347\n",
      "h_val:  tensor(0.1730, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.351959991769\n",
      "loss: 41.27739588408966\n",
      "penalty: 0.014959707089027165\n",
      "h_val:  tensor(0.1692, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.36604965692726\n",
      "loss: 41.27636927090371\n",
      "penalty: 0.014308897252103474\n",
      "h_val:  tensor(0.1644, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.365887567667189\n",
      "loss: 41.27472242219887\n",
      "penalty: 0.013509865283236952\n",
      "h_val:  tensor(0.1595, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.333462504521993\n",
      "loss: 41.27342476707606\n",
      "penalty: 0.012713473809646866\n",
      "h_val:  tensor(0.1597, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.313976197607499\n",
      "loss: 41.272927793526364\n",
      "penalty: 0.012757154193118172\n",
      "h_val:  tensor(0.1575, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.285885797790066\n",
      "loss: 41.27215464000829\n",
      "penalty: 0.012395299066663904\n",
      "h_val:  tensor(0.1581, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.279265768504558\n",
      "loss: 41.27184711477341\n",
      "penalty: 0.012491802671350949\n",
      "h_val:  tensor(0.1588, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.274651986463274\n",
      "loss: 41.27161912364677\n",
      "penalty: 0.012600906897737019\n",
      "h_val:  tensor(0.1587, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.27424555674411\n",
      "loss: 41.27140363775041\n",
      "penalty: 0.01259118283701223\n",
      "h_val:  tensor(0.1573, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.278749334939624\n",
      "loss: 41.27087261265763\n",
      "penalty: 0.012371285400214944\n",
      "h_val:  tensor(0.1558, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.285992654538587\n",
      "loss: 41.2705592490481\n",
      "penalty: 0.012134091676527865\n",
      "h_val:  tensor(0.1542, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.29498933954608\n",
      "loss: 41.27018763048089\n",
      "penalty: 0.011886164455765303\n",
      "h_val:  tensor(0.1525, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.305125772091758\n",
      "loss: 41.26962166332372\n",
      "penalty: 0.011623186126218932\n",
      "h_val:  tensor(0.1508, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.31612918926386\n",
      "loss: 41.268840672743565\n",
      "penalty: 0.011375399032218882\n",
      "h_val:  tensor(0.1498, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.319935527581519\n",
      "loss: 41.268217003929095\n",
      "penalty: 0.011226858235635507\n",
      "h_val:  tensor(0.1496, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.319148890116056\n",
      "loss: 41.2678589171239\n",
      "penalty: 0.011194249890283886\n",
      "h_val:  tensor(0.1499, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.314913579235442\n",
      "loss: 41.26762853807713\n",
      "penalty: 0.0112298190650092\n",
      "h_val:  tensor(0.1504, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.310594641910965\n",
      "loss: 41.26745225808321\n",
      "penalty: 0.011312246233336189\n",
      "h_val:  tensor(0.1510, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.30877479800266\n",
      "loss: 41.267231770775524\n",
      "penalty: 0.01140399742753437\n",
      "h_val:  tensor(0.1518, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.309464358695228\n",
      "loss: 41.2667505252018\n",
      "penalty: 0.011526085780993043\n",
      "h_val:  tensor(0.1528, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.316025577019218\n",
      "loss: 41.265835447393606\n",
      "penalty: 0.011678943344330566\n",
      "h_val:  tensor(0.1545, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.329180054272445\n",
      "loss: 41.26451923555904\n",
      "penalty: 0.011936487752807775\n",
      "h_val:  tensor(0.1570, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.344371644615096\n",
      "loss: 41.26305071714813\n",
      "penalty: 0.012330897461239427\n",
      "h_val:  tensor(0.1601, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.359263850153848\n",
      "loss: 41.26177397318846\n",
      "penalty: 0.0128124781655011\n",
      "h_val:  tensor(0.1628, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.369383581801094\n",
      "loss: 41.2613009633905\n",
      "penalty: 0.013251084748946469\n",
      "h_val:  tensor(0.1652, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.376019403085518\n",
      "loss: 41.26103129022298\n",
      "penalty: 0.0136449210883098\n",
      "h_val:  tensor(0.1690, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.384039709900136\n",
      "loss: 41.260568988586485\n",
      "penalty: 0.01428520826579195\n",
      "h_val:  tensor(0.1727, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.389084565142385\n",
      "loss: 41.25997194447215\n",
      "penalty: 0.01491601516717882\n",
      "h_val:  tensor(0.1730, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.386271017311987\n",
      "loss: 41.2593887531777\n",
      "penalty: 0.014972258658573188\n",
      "h_val:  tensor(0.1706, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.37815437757696\n",
      "loss: 41.25899583995085\n",
      "penalty: 0.014544908596932676\n",
      "h_val:  tensor(0.1686, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.372270590203476\n",
      "loss: 41.2587978562185\n",
      "penalty: 0.014205243215644044\n",
      "h_val:  tensor(0.1667, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.367097658438661\n",
      "loss: 41.25858451818865\n",
      "penalty: 0.013891828279155445\n",
      "h_val:  tensor(0.1650, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.361840090550034\n",
      "loss: 41.25823838626611\n",
      "penalty: 0.013608941780497636\n",
      "h_val:  tensor(0.1644, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.35984744938114\n",
      "loss: 41.257882220353956\n",
      "penalty: 0.013521789653967189\n",
      "h_val:  tensor(0.1658, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.362562429327049\n",
      "loss: 41.257610700948746\n",
      "penalty: 0.013743588498115137\n",
      "h_val:  tensor(0.1683, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.367392451427818\n",
      "loss: 41.257406152649956\n",
      "penalty: 0.014163018042880473\n",
      "h_val:  tensor(0.1721, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.373922788089134\n",
      "loss: 41.25712468274885\n",
      "penalty: 0.014807887119357353\n",
      "h_val:  tensor(0.1745, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.3777454312507\n",
      "loss: 41.25689387176303\n",
      "penalty: 0.015229406729121257\n",
      "h_val:  tensor(0.1752, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.378128114137953\n",
      "loss: 41.25666215881518\n",
      "penalty: 0.015354472324250428\n",
      "h_val:  tensor(0.1743, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.37514182111293\n",
      "loss: 41.256415867609675\n",
      "penalty: 0.015186235614284133\n",
      "h_val:  tensor(0.1718, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.368941488987483\n",
      "loss: 41.25602709689235\n",
      "penalty: 0.01476533844624201\n",
      "h_val:  tensor(0.1683, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.360009049844356\n",
      "loss: 41.2555090381052\n",
      "penalty: 0.01417081264563114\n",
      "h_val:  tensor(0.1655, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.352895049961058\n",
      "loss: 41.25513711757256\n",
      "penalty: 0.013698972234275438\n",
      "h_val:  tensor(0.1641, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.350001821309442\n",
      "loss: 41.25500202944227\n",
      "penalty: 0.013469467972284346\n",
      "h_val:  tensor(0.1636, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.34915685569286\n",
      "loss: 41.25494038381889\n",
      "penalty: 0.013378720852880527\n",
      "h_val:  tensor(0.1626, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.347771264810573\n",
      "loss: 41.254807988652146\n",
      "penalty: 0.013227106062874496\n",
      "h_val:  tensor(0.1614, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.345594766239484\n",
      "loss: 41.25458073712157\n",
      "penalty: 0.013028646395627164\n",
      "h_val:  tensor(0.1599, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.341897469473395\n",
      "loss: 41.2542312634667\n",
      "penalty: 0.012789544292113377\n",
      "h_val:  tensor(0.1592, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.338205208882014\n",
      "loss: 41.253945796559464\n",
      "penalty: 0.012667795809528275\n",
      "h_val:  tensor(0.1594, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.337099722956857\n",
      "loss: 41.253831865550254\n",
      "penalty: 0.012703404429187538\n",
      "h_val:  tensor(0.1598, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.33753725348685\n",
      "loss: 41.25377355800055\n",
      "penalty: 0.012771790580311838\n",
      "h_val:  tensor(0.1604, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.338224554781055\n",
      "loss: 41.253664962363686\n",
      "penalty: 0.012865442640099502\n",
      "h_val:  tensor(0.1611, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.338594473565218\n",
      "loss: 41.25343970251665\n",
      "penalty: 0.01298358864396397\n",
      "h_val:  tensor(0.1617, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.337747976488776\n",
      "loss: 41.253068739861\n",
      "penalty: 0.013074018996487706\n",
      "h_val:  tensor(0.1618, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.334922677279595\n",
      "loss: 41.252613851324604\n",
      "penalty: 0.013087372874227185\n",
      "h_val:  tensor(0.1613, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.33154796315797\n",
      "loss: 41.252326926445825\n",
      "penalty: 0.01300961834739456\n",
      "h_val:  tensor(0.1607, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.329478714194932\n",
      "loss: 41.25221428678634\n",
      "penalty: 0.0129068929808406\n",
      "h_val:  tensor(0.1603, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.328606362094426\n",
      "loss: 41.2521559628841\n",
      "penalty: 0.012851467095670834\n",
      "h_val:  tensor(0.1600, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.32818733197689\n",
      "loss: 41.25207371821877\n",
      "penalty: 0.012792138273518659\n",
      "h_val:  tensor(0.1597, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.328581378983477\n",
      "loss: 41.251946994609405\n",
      "penalty: 0.012753889854093101\n",
      "h_val:  tensor(0.1598, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.330480144969085\n",
      "loss: 41.251755875516736\n",
      "penalty: 0.012774731488379928\n",
      "h_val:  tensor(0.1605, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.333342365446754\n",
      "loss: 41.251609936953756\n",
      "penalty: 0.012872137585688842\n",
      "h_val:  tensor(0.1610, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.335464460292439\n",
      "loss: 41.25154044535809\n",
      "penalty: 0.012963430283814982\n",
      "h_val:  tensor(0.1613, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.336495974043308\n",
      "loss: 41.25150400500749\n",
      "penalty: 0.013007825564734957\n",
      "h_new:  0.16129367975674036\n",
      "layer: 0 shape: torch.Size([20, 2])\n",
      "layer: 1 shape: torch.Size([20])\n",
      "layer: 2 shape: torch.Size([20, 2])\n",
      "layer: 3 shape: torch.Size([20])\n",
      "layer: 4 shape: torch.Size([2, 10, 1])\n",
      "layer: 5 shape: torch.Size([2, 1])\n",
      "rho:  1.0\n",
      "h_val:  tensor(0.1613, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.336495974043308\n",
      "loss: 41.27751965613696\n",
      "penalty: 0.039023476694204876\n",
      "h_val:  tensor(3160312.7762, grad_fn=<SubBackward0>)\n",
      "squared loss: 80.5082593245695\n",
      "loss: 4993788931579.053\n",
      "penalty: 4993788931466.63\n",
      "h_val:  tensor(93.5350, grad_fn=<SubBackward0>)\n",
      "squared loss: 19.376371560714432\n",
      "loss: 4440.761929131244\n",
      "penalty: 4389.480761156295\n",
      "h_val:  tensor(1.2216, grad_fn=<SubBackward0>)\n",
      "squared loss: 21.099073911233642\n",
      "loss: 53.94489206506025\n",
      "penalty: 0.9431517086043277\n",
      "h_val:  tensor(0.1566, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.33904007748282\n",
      "loss: 41.278560479612004\n",
      "penalty: 0.037517753656035595\n",
      "h_val:  tensor(0.1600, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.336743126934168\n",
      "loss: 41.27736223953969\n",
      "penalty: 0.03861825719286671\n",
      "h_val:  tensor(0.1598, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.336717430939538\n",
      "loss: 41.27726059183404\n",
      "penalty: 0.038542155965608615\n",
      "h_val:  tensor(0.1589, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.33664090878134\n",
      "loss: 41.27688501053082\n",
      "penalty: 0.03824249831654808\n",
      "h_val:  tensor(0.1529, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.33714900166811\n",
      "loss: 41.2754951900811\n",
      "penalty: 0.036340442837177314\n",
      "h_val:  tensor(0.1519, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.337385084679195\n",
      "loss: 41.2754422774742\n",
      "penalty: 0.03605085689510275\n",
      "h_val:  tensor(0.1514, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.33753461564399\n",
      "loss: 41.27540965593897\n",
      "penalty: 0.03586850241041329\n",
      "h_new:  0.15136053171384978\n",
      "rho:  10.0\n",
      "h_val:  tensor(0.1514, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.33753461564399\n",
      "loss: 41.37850470346212\n",
      "penalty: 0.13896354993356025\n",
      "h_val:  tensor(2600428.0189, grad_fn=<SubBackward0>)\n",
      "squared loss: 20.12823855028176\n",
      "loss: 33811129828123.895\n",
      "penalty: 33811129828071.844\n",
      "h_val:  tensor(87.5486, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.690439218915188\n",
      "loss: 38379.49194162468\n",
      "penalty: 38337.89445348933\n",
      "h_val:  tensor(1.1874, grad_fn=<SubBackward0>)\n",
      "squared loss: 17.37031658696786\n",
      "loss: 56.514343934701344\n",
      "penalty: 7.240670283939785\n",
      "h_val:  tensor(0.1023, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.701169120334464\n",
      "loss: 41.67204730574392\n",
      "penalty: 0.06880816681840046\n",
      "h_val:  tensor(0.1459, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.342669269951827\n",
      "loss: 41.37458355236795\n",
      "penalty: 0.12990124722438767\n",
      "h_val:  tensor(0.1452, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.342872920540321\n",
      "loss: 41.37375272490844\n",
      "penalty: 0.12886591928651625\n",
      "h_val:  tensor(0.1428, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.343698031134348\n",
      "loss: 41.37066628608948\n",
      "penalty: 0.12495096752010632\n",
      "h_val:  tensor(0.1323, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.345573308217332\n",
      "loss: 41.35645795793623\n",
      "penalty: 0.10884533106822666\n",
      "h_val:  tensor(0.1306, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.347193250846102\n",
      "loss: 41.35560949972872\n",
      "penalty: 0.10637458259833066\n",
      "h_val:  tensor(0.1299, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.348058590643959\n",
      "loss: 41.355383561255\n",
      "penalty: 0.10528563195939451\n",
      "h_val:  tensor(0.1295, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.34842480965663\n",
      "loss: 41.35526917530855\n",
      "penalty: 0.10480883791379494\n",
      "h_val:  tensor(0.1294, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.348542346554112\n",
      "loss: 41.35512012312109\n",
      "penalty: 0.10454981944359179\n",
      "h_val:  tensor(0.1295, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.348211038741402\n",
      "loss: 41.354928791779734\n",
      "penalty: 0.10470286022797166\n",
      "h_val:  tensor(0.1299, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.34753063052842\n",
      "loss: 41.35480320567324\n",
      "penalty: 0.10526898296465857\n",
      "h_val:  tensor(0.1302, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.346998061788879\n",
      "loss: 41.35475684481961\n",
      "penalty: 0.10575852259302199\n",
      "h_val:  tensor(0.1304, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.346674093853588\n",
      "loss: 41.35471630752349\n",
      "penalty: 0.10604173483514365\n",
      "h_new:  0.13039197339930597\n",
      "rho:  100.0\n",
      "h_val:  tensor(0.1304, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.346674093853588\n",
      "loss: 42.11980931023693\n",
      "penalty: 0.871134737548583\n",
      "h_val:  tensor(1594536.6616, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.227139548898364\n",
      "loss: 127127358520258.0\n",
      "penalty: 127127358520195.83\n",
      "h_val:  tensor(75.0338, grad_fn=<SubBackward0>)\n",
      "squared loss: 29.258974772445363\n",
      "loss: 281577.1624638635\n",
      "penalty: 281515.99534277536\n",
      "h_val:  tensor(1.0984, grad_fn=<SubBackward0>)\n",
      "squared loss: 26.872280454175254\n",
      "loss: 119.27527121454888\n",
      "penalty: 60.49931910625713\n",
      "h_val:  tensor(0.0022, grad_fn=<SubBackward0>)\n",
      "squared loss: 16.940648970804126\n",
      "loss: 48.84361871748232\n",
      "penalty: 0.0005819289390319848\n",
      "h_val:  tensor(0.1095, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.460136217499803\n",
      "loss: 41.97990087706179\n",
      "penalty: 0.6177286074626245\n",
      "h_val:  tensor(0.1073, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.482204150911473\n",
      "loss: 41.97760652659006\n",
      "penalty: 0.5933624041435951\n",
      "h_val:  tensor(0.1066, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.489331011270384\n",
      "loss: 41.976389984998036\n",
      "penalty: 0.5850176930149787\n",
      "h_val:  tensor(0.1054, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.498477741096805\n",
      "loss: 41.97272533232436\n",
      "penalty: 0.5722041760061638\n",
      "h_val:  tensor(0.1061, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.489022457157894\n",
      "loss: 41.97058055961651\n",
      "penalty: 0.5795158136897841\n",
      "h_val:  tensor(0.1067, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.48183261557225\n",
      "loss: 41.97020295459404\n",
      "penalty: 0.5863298401138184\n",
      "h_val:  tensor(0.1070, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.47820311836672\n",
      "loss: 41.97007067992331\n",
      "penalty: 0.5898284955680777\n",
      "h_val:  tensor(0.1072, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.475687124456659\n",
      "loss: 41.96992145201104\n",
      "penalty: 0.5921972055477045\n",
      "h_val:  tensor(0.1073, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.475073200400518\n",
      "loss: 41.96970840144466\n",
      "penalty: 0.5926010806721397\n",
      "h_val:  tensor(0.1071, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.476411608567012\n",
      "loss: 41.96933444587205\n",
      "penalty: 0.5908948724720036\n",
      "h_val:  tensor(0.1066, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.481040087455918\n",
      "loss: 41.96866764848604\n",
      "penalty: 0.5856133855388246\n",
      "h_val:  tensor(0.1059, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.487507411197297\n",
      "loss: 41.967847170245165\n",
      "penalty: 0.5783454204848626\n",
      "h_val:  tensor(0.1051, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.495682418188599\n",
      "loss: 41.96651253561646\n",
      "penalty: 0.5688708179884796\n",
      "h_val:  tensor(0.1042, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.502596022533528\n",
      "loss: 41.96434244589758\n",
      "penalty: 0.559847461876185\n",
      "h_val:  tensor(0.1039, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.502823166719375\n",
      "loss: 41.96128388852126\n",
      "penalty: 0.556653115010093\n",
      "h_val:  tensor(0.1046, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.493014460715473\n",
      "loss: 41.95833257988317\n",
      "penalty: 0.5636004795294681\n",
      "h_val:  tensor(0.1056, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.4788316789317\n",
      "loss: 41.95559702627723\n",
      "penalty: 0.5751190337644841\n",
      "h_val:  tensor(0.1068, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.463213189577651\n",
      "loss: 41.951856399746944\n",
      "penalty: 0.5870835589286467\n",
      "h_val:  tensor(0.1075, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.44824209894186\n",
      "loss: 41.9452313748475\n",
      "penalty: 0.5955936088625424\n",
      "h_val:  tensor(0.1071, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.441316997883746\n",
      "loss: 41.93368437297799\n",
      "penalty: 0.5912980291603024\n",
      "h_val:  tensor(0.1044, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.456246687246928\n",
      "loss: 41.91884013098768\n",
      "penalty: 0.5619979081063364\n",
      "h_val:  tensor(0.1003, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.48827980282715\n",
      "loss: 41.90744976295959\n",
      "penalty: 0.5189821724108384\n",
      "h_val:  tensor(0.0974, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.511056195921052\n",
      "loss: 41.900715639518594\n",
      "penalty: 0.4896959069039999\n",
      "h_val:  tensor(0.0942, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.53123619082511\n",
      "loss: 41.890145019251385\n",
      "penalty: 0.45924374448368255\n",
      "h_val:  tensor(0.0897, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.550594023716917\n",
      "loss: 41.866035160623355\n",
      "penalty: 0.4164479885036016\n",
      "h_val:  tensor(0.0851, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.550933118203295\n",
      "loss: 41.82479664016726\n",
      "penalty: 0.3761177750172205\n",
      "h_val:  tensor(0.0831, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.530713030193306\n",
      "loss: 41.7858538685427\n",
      "penalty: 0.3588042372908928\n",
      "h_val:  tensor(0.0822, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.515266262828295\n",
      "loss: 41.76208131731735\n",
      "penalty: 0.3512042275090174\n",
      "h_val:  tensor(0.0810, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.503579834134925\n",
      "loss: 41.739757535352936\n",
      "penalty: 0.34099390010980524\n",
      "h_val:  tensor(0.0796, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.49974250081212\n",
      "loss: 41.72405992508942\n",
      "penalty: 0.32932146554288416\n",
      "h_val:  tensor(0.0763, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.50291574306659\n",
      "loss: 41.70139741133573\n",
      "penalty: 0.3037369135652345\n",
      "h_val:  tensor(0.0729, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.514602573938484\n",
      "loss: 41.68609582726845\n",
      "penalty: 0.27723713691359847\n",
      "h_val:  tensor(0.0706, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.526382105961074\n",
      "loss: 41.68094735607432\n",
      "penalty: 0.2605929093052654\n",
      "h_val:  tensor(0.0699, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.528474668613612\n",
      "loss: 41.67758828148772\n",
      "penalty: 0.2552863611425028\n",
      "h_val:  tensor(0.0696, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.526886268475433\n",
      "loss: 41.67369327670731\n",
      "penalty: 0.2530949966127041\n",
      "h_val:  tensor(0.0699, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.520589592238846\n",
      "loss: 41.66994270328941\n",
      "penalty: 0.25566706330411065\n",
      "h_val:  tensor(0.0704, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.513184164568157\n",
      "loss: 41.66605811216297\n",
      "penalty: 0.2591413938126452\n",
      "h_val:  tensor(0.0706, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.507887750532849\n",
      "loss: 41.6622567564695\n",
      "penalty: 0.2605335403415455\n",
      "h_val:  tensor(0.0702, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.507547746580755\n",
      "loss: 41.65906237726612\n",
      "penalty: 0.2575882436942266\n",
      "h_val:  tensor(0.0692, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.511078486909714\n",
      "loss: 41.65563166891787\n",
      "penalty: 0.2505982507923851\n",
      "h_val:  tensor(0.0678, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.515605818744808\n",
      "loss: 41.65032536981463\n",
      "penalty: 0.2407851640979082\n",
      "h_val:  tensor(0.0663, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.51845051805669\n",
      "loss: 41.64271878318503\n",
      "penalty: 0.23044580260306818\n",
      "h_val:  tensor(0.0653, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.517094306206982\n",
      "loss: 41.634311424618105\n",
      "penalty: 0.22359483578868342\n",
      "h_val:  tensor(0.0646, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.51383926949682\n",
      "loss: 41.62642249994711\n",
      "penalty: 0.21919578856383373\n",
      "h_val:  tensor(0.0642, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.507963839920903\n",
      "loss: 41.6177980856246\n",
      "penalty: 0.2166931779588827\n",
      "h_val:  tensor(0.0641, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.499131513652026\n",
      "loss: 41.60781187608903\n",
      "penalty: 0.21576279140602692\n",
      "h_val:  tensor(0.0636, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.490104485646107\n",
      "loss: 41.595418156670256\n",
      "penalty: 0.2126324755981036\n",
      "h_val:  tensor(0.0625, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.485508302453697\n",
      "loss: 41.58326793108241\n",
      "penalty: 0.20527626332103954\n",
      "h_val:  tensor(0.0602, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.492291291093647\n",
      "loss: 41.57544214308737\n",
      "penalty: 0.1907830911224461\n",
      "h_val:  tensor(0.0589, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.497162944264131\n",
      "loss: 41.572557257950756\n",
      "penalty: 0.18305571906382864\n",
      "h_val:  tensor(0.0586, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.496663591680552\n",
      "loss: 41.56994846916453\n",
      "penalty: 0.18096481454853117\n",
      "h_val:  tensor(0.0574, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.500405366725314\n",
      "loss: 41.56677685262761\n",
      "penalty: 0.1741288835770238\n",
      "h_val:  tensor(0.0593, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.487179571142086\n",
      "loss: 41.56496339518255\n",
      "penalty: 0.1855565432313236\n",
      "h_val:  tensor(0.0586, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.490165953804476\n",
      "loss: 41.56353578358283\n",
      "penalty: 0.18118578380607192\n",
      "h_val:  tensor(0.0583, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.490794788291549\n",
      "loss: 41.56238373083496\n",
      "penalty: 0.17945119975977403\n",
      "h_val:  tensor(0.0583, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.490132912988088\n",
      "loss: 41.56174528582429\n",
      "penalty: 0.17948699504265608\n",
      "h_val:  tensor(0.0584, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.488618141006336\n",
      "loss: 41.56086921095781\n",
      "penalty: 0.1801173121548444\n",
      "h_val:  tensor(0.0585, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.487591221881388\n",
      "loss: 41.560262642435085\n",
      "penalty: 0.18050467524678573\n",
      "h_val:  tensor(0.0585, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.486912896328123\n",
      "loss: 41.55976125977057\n",
      "penalty: 0.18063238670934514\n",
      "h_val:  tensor(0.0585, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.48650967378525\n",
      "loss: 41.55929438284999\n",
      "penalty: 0.18053252645205864\n",
      "h_val:  tensor(0.0584, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.485896156372121\n",
      "loss: 41.55833920775106\n",
      "penalty: 0.18014262965350208\n",
      "h_val:  tensor(0.0583, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.485659443758426\n",
      "loss: 41.55733168067741\n",
      "penalty: 0.17935135399952754\n",
      "h_val:  tensor(0.0582, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.485589329052775\n",
      "loss: 41.556559261466845\n",
      "penalty: 0.17866568927685184\n",
      "h_val:  tensor(0.0582, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.485148340873694\n",
      "loss: 41.55614661127904\n",
      "penalty: 0.17872658913220074\n",
      "h_val:  tensor(0.0582, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.484736596070443\n",
      "loss: 41.55565903148345\n",
      "penalty: 0.1786768148427934\n",
      "h_val:  tensor(0.0581, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.483411231487489\n",
      "loss: 41.553772942896565\n",
      "penalty: 0.1781704206102392\n",
      "h_val:  tensor(0.0578, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.482384242208463\n",
      "loss: 41.55088548492656\n",
      "penalty: 0.17636002319394398\n",
      "h_val:  tensor(0.0574, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.481958895904388\n",
      "loss: 41.548393180670246\n",
      "penalty: 0.17428992490754175\n",
      "h_val:  tensor(0.0568, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.484246939051836\n",
      "loss: 41.54704479659638\n",
      "penalty: 0.17060784677809585\n",
      "h_val:  tensor(0.0573, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.480849796255606\n",
      "loss: 41.546671784285586\n",
      "penalty: 0.17359113573381624\n",
      "h_val:  tensor(0.0568, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.483443357777285\n",
      "loss: 41.546335095934424\n",
      "penalty: 0.1706473934907993\n",
      "h_val:  tensor(0.0566, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.484770199627292\n",
      "loss: 41.546048843552725\n",
      "penalty: 0.16902974509016835\n",
      "h_val:  tensor(0.0562, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.48615535256503\n",
      "loss: 41.545544173297756\n",
      "penalty: 0.16714246539789562\n",
      "h_val:  tensor(0.0561, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.486402757121073\n",
      "loss: 41.54516656761121\n",
      "penalty: 0.16653172735631383\n",
      "h_val:  tensor(0.0562, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.485929493300535\n",
      "loss: 41.544982993821684\n",
      "penalty: 0.16683898477663495\n",
      "h_val:  tensor(0.0562, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.48543228976862\n",
      "loss: 41.5449081704307\n",
      "penalty: 0.16727263238617132\n",
      "h_val:  tensor(0.0563, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.485064195041799\n",
      "loss: 41.54484459937844\n",
      "penalty: 0.1675867041968381\n",
      "h_val:  tensor(0.0563, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.484876788844858\n",
      "loss: 41.54474885059608\n",
      "penalty: 0.16769113266805874\n",
      "h_val:  tensor(0.0563, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.485170847612348\n",
      "loss: 41.544617338145706\n",
      "penalty: 0.1672814260901706\n",
      "h_val:  tensor(0.0561, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.486041432331108\n",
      "loss: 41.544503459820476\n",
      "penalty: 0.16630829351084836\n",
      "h_val:  tensor(0.0560, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.486681375492347\n",
      "loss: 41.544436874649655\n",
      "penalty: 0.16560384974821096\n",
      "h_val:  tensor(0.0560, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.486631993464217\n",
      "loss: 41.54438266085709\n",
      "penalty: 0.16559774774536765\n",
      "h_val:  tensor(0.0560, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.48641894039986\n",
      "loss: 41.54433800856567\n",
      "penalty: 0.16576553226325794\n",
      "h_val:  tensor(0.0560, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.486071736379014\n",
      "loss: 41.544281646258455\n",
      "penalty: 0.1660586455452588\n",
      "h_val:  tensor(0.0561, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.485739634479673\n",
      "loss: 41.54418889272814\n",
      "penalty: 0.16630738940861234\n",
      "h_val:  tensor(0.0560, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.485860898705972\n",
      "loss: 41.54402889314403\n",
      "penalty: 0.1660498743454046\n",
      "h_val:  tensor(0.0558, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.487184385222044\n",
      "loss: 41.54381529594606\n",
      "penalty: 0.1645525562001344\n",
      "h_val:  tensor(0.0554, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.489351971781591\n",
      "loss: 41.54364198802486\n",
      "penalty: 0.162249375986202\n",
      "h_val:  tensor(0.0551, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.490698651589831\n",
      "loss: 41.543532010337714\n",
      "penalty: 0.1608200528993204\n",
      "h_val:  tensor(0.0549, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.491790930534926\n",
      "loss: 41.543434424969035\n",
      "penalty: 0.1596506129635334\n",
      "h_val:  tensor(0.0547, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.492705472135995\n",
      "loss: 41.54330408619582\n",
      "penalty: 0.15863119198720477\n",
      "h_val:  tensor(0.0545, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.49364703856872\n",
      "loss: 41.54308452463149\n",
      "penalty: 0.1575159749578123\n",
      "h_val:  tensor(0.0544, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.494155190302306\n",
      "loss: 41.54281880508329\n",
      "penalty: 0.1568031569720967\n",
      "h_val:  tensor(0.0544, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.494043864758567\n",
      "loss: 41.54258992159094\n",
      "penalty: 0.15673917520763306\n",
      "h_val:  tensor(0.0544, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.493631278685113\n",
      "loss: 41.54242787293285\n",
      "penalty: 0.15702126879960446\n",
      "h_val:  tensor(0.0545, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.493345814944128\n",
      "loss: 41.54227879152742\n",
      "penalty: 0.157179532737368\n",
      "h_val:  tensor(0.0544, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.493493433534027\n",
      "loss: 41.542065685603674\n",
      "penalty: 0.15685162693568047\n",
      "h_val:  tensor(0.0542, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.494483159712015\n",
      "loss: 41.54174270991164\n",
      "penalty: 0.15560340512669454\n",
      "h_val:  tensor(0.0538, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.496176445886425\n",
      "loss: 41.54136451108902\n",
      "penalty: 0.15363800152054105\n",
      "h_val:  tensor(0.0536, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.497452874228467\n",
      "loss: 41.54108399655243\n",
      "penalty: 0.15217978613335228\n",
      "h_val:  tensor(0.0535, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.497946633894237\n",
      "loss: 41.5409471199918\n",
      "penalty: 0.15160678793081056\n",
      "h_val:  tensor(0.0535, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.497830650653778\n",
      "loss: 41.54087881471535\n",
      "penalty: 0.1516775710725507\n",
      "h_val:  tensor(0.0535, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.497466646992237\n",
      "loss: 41.54078765230936\n",
      "penalty: 0.15197509238753515\n",
      "h_val:  tensor(0.0536, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.497066577436902\n",
      "loss: 41.54062330950984\n",
      "penalty: 0.15225576006029623\n",
      "h_val:  tensor(0.0535, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.497271957135286\n",
      "loss: 41.54032392529906\n",
      "penalty: 0.1518397008167021\n",
      "h_val:  tensor(0.0531, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.499160961375374\n",
      "loss: 41.53991431549162\n",
      "penalty: 0.14967634851097564\n",
      "h_val:  tensor(0.0526, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.501592560121674\n",
      "loss: 41.539618028866435\n",
      "penalty: 0.14705771118406327\n",
      "h_val:  tensor(0.0523, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.503141669009105\n",
      "loss: 41.539477114848715\n",
      "penalty: 0.14541133471470916\n",
      "h_val:  tensor(0.0522, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.50377599484732\n",
      "loss: 41.53939343996558\n",
      "penalty: 0.14470362659669792\n",
      "h_val:  tensor(0.0521, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.504215507446004\n",
      "loss: 41.539254109981385\n",
      "penalty: 0.14413967033443847\n",
      "h_val:  tensor(0.0520, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.504423203734227\n",
      "loss: 41.53896827891863\n",
      "penalty: 0.1436922096938009\n",
      "h_val:  tensor(0.0520, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.504104382107931\n",
      "loss: 41.5385220012526\n",
      "penalty: 0.14367018859025937\n",
      "h_val:  tensor(0.0521, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.50314084036175\n",
      "loss: 41.53809682312258\n",
      "penalty: 0.1443481742101255\n",
      "h_val:  tensor(0.0523, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.502283204120728\n",
      "loss: 41.53787015448656\n",
      "penalty: 0.14507370768497707\n",
      "h_val:  tensor(0.0523, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.502057584106627\n",
      "loss: 41.5377457892516\n",
      "penalty: 0.14521918021960206\n",
      "h_val:  tensor(0.0522, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.502358516530686\n",
      "loss: 41.53757282059531\n",
      "penalty: 0.14479577012696965\n",
      "h_val:  tensor(0.0519, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.503605497324797\n",
      "loss: 41.5371758123864\n",
      "penalty: 0.14327546326392498\n",
      "h_val:  tensor(0.0513, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.506279424886744\n",
      "loss: 41.53627230603531\n",
      "penalty: 0.14002123999313712\n",
      "h_val:  tensor(0.0502, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.511535860625045\n",
      "loss: 41.53509875359514\n",
      "penalty: 0.13409114171915304\n",
      "h_val:  tensor(0.0494, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.51516193735008\n",
      "loss: 41.53425227470228\n",
      "penalty: 0.1300093909660062\n",
      "h_val:  tensor(0.0491, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.516300704890437\n",
      "loss: 41.53380305030328\n",
      "penalty: 0.1285998562955256\n",
      "h_val:  tensor(0.0492, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.515893913115699\n",
      "loss: 41.53352421391895\n",
      "penalty: 0.12877466679457306\n",
      "h_val:  tensor(0.0492, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.515116798535715\n",
      "loss: 41.53298623085681\n",
      "penalty: 0.12910203084373847\n",
      "h_val:  tensor(0.0491, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.514749110607974\n",
      "loss: 41.53169916499668\n",
      "penalty: 0.12849178353137441\n",
      "h_val:  tensor(0.0486, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.516362437480893\n",
      "loss: 41.52995468707173\n",
      "penalty: 0.12572524407220606\n",
      "h_val:  tensor(0.0477, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.520036960882063\n",
      "loss: 41.52866984396593\n",
      "penalty: 0.12137754607017481\n",
      "h_val:  tensor(0.0471, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.522632106280692\n",
      "loss: 41.52822952622887\n",
      "penalty: 0.11860217649349698\n",
      "h_val:  tensor(0.0469, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.52348125219268\n",
      "loss: 41.52806937769746\n",
      "penalty: 0.11763070533843413\n",
      "h_val:  tensor(0.0466, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.524483450457172\n",
      "loss: 41.527658875941235\n",
      "penalty: 0.11627599395244696\n",
      "h_val:  tensor(0.0459, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.526922007816648\n",
      "loss: 41.52619797269366\n",
      "penalty: 0.11265020602697189\n",
      "h_val:  tensor(0.0446, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.531489800909362\n",
      "loss: 41.524315407253056\n",
      "penalty: 0.10667242526365828\n",
      "h_val:  tensor(0.0439, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.533628376964332\n",
      "loss: 41.52264201463545\n",
      "penalty: 0.10336662203688358\n",
      "h_val:  tensor(0.0437, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.5337605123325\n",
      "loss: 41.52172782583732\n",
      "penalty: 0.10263885134556405\n",
      "h_val:  tensor(0.0438, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.533017609681542\n",
      "loss: 41.52144295253839\n",
      "penalty: 0.103150781233082\n",
      "h_val:  tensor(0.0439, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.532205795596456\n",
      "loss: 41.520832967810826\n",
      "penalty: 0.10343106786655513\n",
      "h_val:  tensor(0.0439, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.529838007633659\n",
      "loss: 41.51804565722716\n",
      "penalty: 0.1034845442448482\n",
      "h_val:  tensor(0.0435, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.529885800610053\n",
      "loss: 41.51575178683701\n",
      "penalty: 0.10165239817567476\n",
      "h_val:  tensor(0.0430, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.531342048886247\n",
      "loss: 41.51463673772655\n",
      "penalty: 0.09940467996374394\n",
      "h_val:  tensor(0.0427, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.53231041251962\n",
      "loss: 41.51433421060817\n",
      "penalty: 0.0982081127490735\n",
      "h_val:  tensor(0.0427, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.532430494974141\n",
      "loss: 41.514155380575374\n",
      "penalty: 0.09791847784915467\n",
      "h_val:  tensor(0.0419, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.535290773003537\n",
      "loss: 41.51342920336273\n",
      "penalty: 0.09452577643222076\n",
      "h_val:  tensor(0.0422, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.533443210230887\n",
      "loss: 41.51269567889415\n",
      "penalty: 0.09568915958410505\n",
      "h_val:  tensor(0.0425, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.53156380970778\n",
      "loss: 41.51214582817512\n",
      "penalty: 0.09710220517825056\n",
      "h_val:  tensor(0.0426, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.530976712313729\n",
      "loss: 41.51202641697657\n",
      "penalty: 0.09760151802400081\n",
      "h_val:  tensor(0.0426, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.530841641537554\n",
      "loss: 41.511966278225614\n",
      "penalty: 0.0976832983900502\n",
      "h_val:  tensor(0.0427, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.530430387227488\n",
      "loss: 41.51168729222794\n",
      "penalty: 0.09785329300577336\n",
      "h_val:  tensor(0.0426, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.53003420248917\n",
      "loss: 41.51106346279679\n",
      "penalty: 0.09773034971560311\n",
      "h_val:  tensor(0.0425, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.529972893540398\n",
      "loss: 41.51024340091106\n",
      "penalty: 0.09712974458293834\n",
      "h_val:  tensor(0.0422, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.530594853244088\n",
      "loss: 41.50936317293693\n",
      "penalty: 0.09582166355660682\n",
      "h_val:  tensor(0.0420, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.531246873379144\n",
      "loss: 41.508974653840816\n",
      "penalty: 0.09486518393925122\n",
      "h_val:  tensor(0.0419, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.531359755111906\n",
      "loss: 41.50877972626801\n",
      "penalty: 0.09456636100816032\n",
      "h_val:  tensor(0.0417, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.530831781045809\n",
      "loss: 41.50708812628787\n",
      "penalty: 0.0935747647697132\n",
      "h_val:  tensor(0.0413, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.524026060231268\n",
      "loss: 41.49746432588148\n",
      "penalty: 0.09206693895862425\n",
      "h_val:  tensor(0.0402, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.523888482461894\n",
      "loss: 41.49136749749302\n",
      "penalty: 0.08712647222028179\n",
      "h_val:  tensor(0.0400, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.521748457957106\n",
      "loss: 41.487996459452916\n",
      "penalty: 0.08652922760389517\n",
      "h_val:  tensor(0.0404, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.519053033516292\n",
      "loss: 41.486939501836616\n",
      "penalty: 0.08831486339672147\n",
      "h_val:  tensor(0.0407, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.517371386462298\n",
      "loss: 41.48614496364459\n",
      "penalty: 0.08922251044245019\n",
      "h_val:  tensor(0.0416, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.509899182988093\n",
      "loss: 41.482371814720835\n",
      "penalty: 0.09312504545670149\n",
      "h_val:  tensor(0.0425, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.500961294658318\n",
      "loss: 41.477120707115965\n",
      "penalty: 0.09731999703307376\n",
      "h_val:  tensor(0.0434, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.490867300807318\n",
      "loss: 41.46964723398409\n",
      "penalty: 0.1010397168752003\n",
      "h_val:  tensor(0.0431, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.488255996769157\n",
      "loss: 41.46464053962383\n",
      "penalty: 0.0996586444104182\n",
      "h_val:  tensor(0.0423, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.490122387706775\n",
      "loss: 41.462560162244934\n",
      "penalty: 0.09617295471706558\n",
      "h_val:  tensor(0.0420, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.489689798100494\n",
      "loss: 41.46062738827001\n",
      "penalty: 0.09491776764080946\n",
      "h_val:  tensor(0.0409, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.486558471270028\n",
      "loss: 41.45167512429188\n",
      "penalty: 0.09027359662077587\n",
      "h_val:  tensor(0.0409, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.475210721706942\n",
      "loss: 41.43849165872993\n",
      "penalty: 0.09038690575204805\n",
      "h_val:  tensor(0.0411, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.45457771248145\n",
      "loss: 41.414920887613064\n",
      "penalty: 0.09118763023088963\n",
      "h_val:  tensor(0.0418, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.432690005681499\n",
      "loss: 41.39193520049839\n",
      "penalty: 0.09397268666020774\n",
      "h_val:  tensor(0.0428, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.417963451975266\n",
      "loss: 41.38029772992936\n",
      "penalty: 0.09869466575046676\n",
      "h_val:  tensor(0.0433, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.41079797209623\n",
      "loss: 41.3750810094508\n",
      "penalty: 0.10067447734601886\n",
      "h_val:  tensor(0.0439, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.396954434768208\n",
      "loss: 41.3635147048837\n",
      "penalty: 0.10348943958502055\n",
      "h_val:  tensor(0.0439, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.368105417845047\n",
      "loss: 41.331803993790274\n",
      "penalty: 0.10325835463066509\n",
      "h_val:  tensor(0.0435, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.335934688301162\n",
      "loss: 41.292609227636525\n",
      "penalty: 0.1014087646400434\n",
      "h_val:  tensor(0.0390, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.318320897202836\n",
      "loss: 41.2475749628606\n",
      "penalty: 0.08224238904583131\n",
      "h_val:  tensor(0.0360, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.32019158370494\n",
      "loss: 41.23415068648275\n",
      "penalty: 0.07044064897881538\n",
      "h_val:  tensor(0.0344, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.320536915148423\n",
      "loss: 41.22778015012061\n",
      "penalty: 0.06488799796758922\n",
      "h_val:  tensor(0.0337, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.31328470753558\n",
      "loss: 41.21648443373162\n",
      "penalty: 0.06234126664594114\n",
      "h_val:  tensor(0.0324, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.299769316064813\n",
      "loss: 41.19560790581027\n",
      "penalty: 0.05769125802824078\n",
      "h_val:  tensor(0.0343, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.268391667816537\n",
      "loss: 41.167825007965234\n",
      "penalty: 0.06448316922631064\n",
      "h_val:  tensor(0.0392, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.215204965423565\n",
      "loss: 41.12809517248364\n",
      "penalty: 0.08318522980223769\n",
      "h_val:  tensor(0.0399, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.194398003451655\n",
      "loss: 41.10774082571857\n",
      "penalty: 0.08614844681770197\n",
      "h_val:  tensor(0.0401, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.182181278721625\n",
      "loss: 41.0954202110193\n",
      "penalty: 0.08690858790798839\n",
      "h_val:  tensor(0.0402, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.173745991903235\n",
      "loss: 41.087241518685865\n",
      "penalty: 0.08713333599478454\n",
      "h_val:  tensor(0.0410, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.137582951645483\n",
      "loss: 41.05401693665018\n",
      "penalty: 0.09079979121896618\n",
      "h_val:  tensor(0.0426, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.067457565398525\n",
      "loss: 40.98713139447089\n",
      "penalty: 0.09742436119697649\n",
      "h_val:  tensor(0.0417, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.965473874376176\n",
      "loss: 40.87344017503989\n",
      "penalty: 0.09388102445686931\n",
      "h_val:  tensor(0.0393, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.8922052460903\n",
      "loss: 40.781337044126644\n",
      "penalty: 0.08340028207480324\n",
      "h_val:  tensor(0.0408, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.848360346490045\n",
      "loss: 40.74034712404297\n",
      "penalty: 0.08999562828627235\n",
      "h_val:  tensor(0.0418, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.831037244228694\n",
      "loss: 40.726298266372865\n",
      "penalty: 0.09412742470240427\n",
      "h_val:  tensor(0.0416, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.817680729670533\n",
      "loss: 40.71129957125296\n",
      "penalty: 0.09335078662901013\n",
      "h_val:  tensor(0.0407, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.78933372700424\n",
      "loss: 40.67634538745635\n",
      "penalty: 0.08955163546745104\n",
      "h_val:  tensor(0.0378, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.76007666524782\n",
      "loss: 40.631341588390754\n",
      "penalty: 0.07772784722821852\n",
      "h_val:  tensor(0.0328, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.727883183305076\n",
      "loss: 40.57668117068867\n",
      "penalty: 0.0590274143973525\n",
      "h_val:  tensor(0.0269, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.696049069579448\n",
      "loss: 40.52477981162223\n",
      "penalty: 0.04063899135528325\n",
      "h_val:  tensor(0.0243, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.687315968552191\n",
      "loss: 40.508979499134234\n",
      "penalty: 0.033492977062734734\n",
      "h_val:  tensor(0.0236, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.680802854672283\n",
      "loss: 40.50087892837669\n",
      "penalty: 0.031759920528843175\n",
      "h_val:  tensor(0.0238, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.551258199566238\n",
      "loss: 40.386111105108014\n",
      "penalty: 0.03212018176026166\n",
      "h_val:  tensor(0.0212, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.444180200470438\n",
      "loss: 40.28555328985409\n",
      "penalty: 0.025925019831590904\n",
      "h_val:  tensor(0.0213, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.404863711754812\n",
      "loss: 40.25157476395258\n",
      "penalty: 0.026232197121550917\n",
      "h_val:  tensor(0.0224, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.391884507863184\n",
      "loss: 40.23842497147331\n",
      "penalty: 0.028804719834989927\n",
      "h_val:  tensor(0.0232, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.386722325890158\n",
      "loss: 40.232170884482585\n",
      "penalty: 0.03069642181292506\n",
      "h_val:  tensor(0.0250, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.365614340111568\n",
      "loss: 40.21162332197073\n",
      "penalty: 0.03524147679033776\n",
      "h_val:  tensor(0.0286, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.310336324908162\n",
      "loss: 40.16417335838654\n",
      "penalty: 0.0456170466333138\n",
      "h_val:  tensor(0.0313, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.237040510553518\n",
      "loss: 40.103669580225024\n",
      "penalty: 0.05392834394628494\n",
      "h_val:  tensor(0.0312, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.182297795655357\n",
      "loss: 40.061282207203284\n",
      "penalty: 0.053592463748874976\n",
      "h_val:  tensor(0.0303, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.166443206119492\n",
      "loss: 40.05005017978126\n",
      "penalty: 0.05075343190621732\n",
      "h_val:  tensor(0.0296, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.15164856692325\n",
      "loss: 40.03879085907151\n",
      "penalty: 0.04849206536549716\n",
      "h_val:  tensor(0.0294, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.111113165103378\n",
      "loss: 40.00992820134084\n",
      "penalty: 0.04799950059224521\n",
      "h_val:  tensor(0.0322, grad_fn=<SubBackward0>)\n",
      "squared loss: 8.027278530672728\n",
      "loss: 39.9536163185412\n",
      "penalty: 0.056871034759585715\n",
      "h_val:  tensor(0.0462, grad_fn=<SubBackward0>)\n",
      "squared loss: 7.832966443434941\n",
      "loss: 39.85182262552143\n",
      "penalty: 0.11439111773477027\n",
      "h_val:  tensor(0.0519, grad_fn=<SubBackward0>)\n",
      "squared loss: 7.736506762363827\n",
      "loss: 39.78159016240374\n",
      "penalty: 0.14305968729606036\n",
      "h_val:  tensor(0.0438, grad_fn=<SubBackward0>)\n",
      "squared loss: 7.77167764844434\n",
      "loss: 39.74938642321904\n",
      "penalty: 0.10299919375180998\n",
      "h_val:  tensor(0.0450, grad_fn=<SubBackward0>)\n",
      "squared loss: 7.735266419436892\n",
      "loss: 39.718692144229856\n",
      "penalty: 0.10869161122926271\n",
      "h_val:  tensor(0.0479, grad_fn=<SubBackward0>)\n",
      "squared loss: 7.542685482111637\n",
      "loss: 39.53601800643802\n",
      "penalty: 0.12233349684266653\n",
      "h_val:  tensor(0.0520, grad_fn=<SubBackward0>)\n",
      "squared loss: 7.398116912388382\n",
      "loss: 39.41980359204183\n",
      "penalty: 0.14342508470742177\n",
      "h_val:  tensor(0.0681, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.942740875346509\n",
      "loss: 39.109502980687985\n",
      "penalty: 0.24304017026735705\n",
      "h_val:  tensor(0.0708, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.7115203994393395\n",
      "loss: 38.923850503535995\n",
      "penalty: 0.2619795520392336\n",
      "h_val:  tensor(0.0769, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.390540625044951\n",
      "loss: 38.697527030770615\n",
      "penalty: 0.3080628244408629\n",
      "h_val:  tensor(0.0701, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.215661021877407\n",
      "loss: 38.51565620160031\n",
      "penalty: 0.2567406576233506\n",
      "h_val:  tensor(0.0778, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.9147625185445145\n",
      "loss: 38.37163677183403\n",
      "penalty: 0.3152505479794731\n",
      "h_val:  tensor(0.0777, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.8288795845679555\n",
      "loss: 38.315523530783956\n",
      "penalty: 0.3141828250971254\n",
      "h_val:  tensor(0.0745, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.787210397789794\n",
      "loss: 38.25665772173943\n",
      "penalty: 0.28917174722437194\n",
      "h_val:  tensor(0.0723, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.774864556210679\n",
      "loss: 38.22987573815347\n",
      "penalty: 0.27272284452285234\n",
      "h_val:  tensor(0.0685, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.781541741092242\n",
      "loss: 38.20835564764915\n",
      "penalty: 0.2457587930926123\n",
      "h_val:  tensor(0.0628, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.78870684024349\n",
      "loss: 38.181739935534395\n",
      "penalty: 0.20746506729593675\n",
      "h_val:  tensor(0.0592, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.8027097225163615\n",
      "loss: 38.17128528726834\n",
      "penalty: 0.18484656555053045\n",
      "h_val:  tensor(0.0579, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.800215992029079\n",
      "loss: 38.16582751964574\n",
      "penalty: 0.17670180707349123\n",
      "h_val:  tensor(0.0577, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.7908216522780815\n",
      "loss: 38.16287367043731\n",
      "penalty: 0.1759647363563563\n",
      "h_val:  tensor(0.0584, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.778301866415408\n",
      "loss: 38.16144765475253\n",
      "penalty: 0.18011063476938735\n",
      "h_val:  tensor(0.0590, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.772081684590144\n",
      "loss: 38.160933183722356\n",
      "penalty: 0.18368443605019763\n",
      "h_val:  tensor(0.0596, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.768329124100216\n",
      "loss: 38.16037723969413\n",
      "penalty: 0.1869238145261847\n",
      "h_val:  tensor(0.0606, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.762695336031425\n",
      "loss: 38.159028516084426\n",
      "penalty: 0.19347311729528113\n",
      "h_val:  tensor(0.0616, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.759209385295929\n",
      "loss: 38.15736867176318\n",
      "penalty: 0.1997546908625181\n",
      "h_val:  tensor(0.0621, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.7604201803636395\n",
      "loss: 38.155927997996\n",
      "penalty: 0.2026308557491545\n",
      "h_val:  tensor(0.0620, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.763459052316349\n",
      "loss: 38.1550043002154\n",
      "penalty: 0.20198921617815685\n",
      "h_val:  tensor(0.0616, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.766956641222602\n",
      "loss: 38.154382870724596\n",
      "penalty: 0.19971718593237905\n",
      "h_val:  tensor(0.0613, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.768772196789382\n",
      "loss: 38.15379259332115\n",
      "penalty: 0.19793664540074998\n",
      "h_val:  tensor(0.0612, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.769001004795988\n",
      "loss: 38.15330516837488\n",
      "penalty: 0.1973389202307927\n",
      "h_val:  tensor(0.0614, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.767740737833299\n",
      "loss: 38.1530398952336\n",
      "penalty: 0.19810824477094993\n",
      "h_val:  tensor(0.0615, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.766316807206931\n",
      "loss: 38.15289327561142\n",
      "penalty: 0.19917309564212105\n",
      "h_val:  tensor(0.0617, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.765290664686604\n",
      "loss: 38.15274480702521\n",
      "penalty: 0.2000278333753025\n",
      "h_val:  tensor(0.0617, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.7649260317502025\n",
      "loss: 38.15251742612609\n",
      "penalty: 0.2005602924274602\n",
      "h_val:  tensor(0.0617, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.766110769280031\n",
      "loss: 38.152248723486935\n",
      "penalty: 0.20020906877431907\n",
      "h_val:  tensor(0.0615, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.769044934232853\n",
      "loss: 38.151914884595804\n",
      "penalty: 0.19900733413953942\n",
      "h_val:  tensor(0.0612, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.773791881392349\n",
      "loss: 38.15140380060675\n",
      "penalty: 0.19700251639072214\n",
      "h_val:  tensor(0.0608, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.780638362293973\n",
      "loss: 38.150531216460145\n",
      "penalty: 0.19445473423548137\n",
      "h_val:  tensor(0.0600, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.79042423981614\n",
      "loss: 38.14948136695443\n",
      "penalty: 0.18959068217322456\n",
      "h_val:  tensor(0.0602, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.795082319295125\n",
      "loss: 38.14818449369212\n",
      "penalty: 0.1909930342982288\n",
      "h_val:  tensor(0.0601, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.796271506734983\n",
      "loss: 38.14696843811745\n",
      "penalty: 0.19000905237861743\n",
      "h_val:  tensor(0.0602, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.797167913263254\n",
      "loss: 38.143895792634275\n",
      "penalty: 0.19066926739818754\n",
      "h_val:  tensor(0.0605, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.797436052257697\n",
      "loss: 38.142614959927855\n",
      "penalty: 0.19269014607877627\n",
      "h_val:  tensor(0.0609, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.798863439101606\n",
      "loss: 38.14139060718499\n",
      "penalty: 0.19542015211707844\n",
      "h_val:  tensor(0.0611, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.800507003682919\n",
      "loss: 38.14080759766891\n",
      "penalty: 0.19621061260070308\n",
      "h_val:  tensor(0.0612, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.802795274223495\n",
      "loss: 38.13948130032304\n",
      "penalty: 0.19705645960782472\n",
      "h_val:  tensor(0.0619, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.806881068175714\n",
      "loss: 38.13494479906772\n",
      "penalty: 0.2012806945801893\n",
      "h_val:  tensor(0.0623, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.816404630298303\n",
      "loss: 38.12908426651624\n",
      "penalty: 0.20382754108828416\n",
      "h_val:  tensor(0.0622, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.8248972548167055\n",
      "loss: 38.124976867307595\n",
      "penalty: 0.2036732426405066\n",
      "h_val:  tensor(0.0619, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.826687030291082\n",
      "loss: 38.12376014561305\n",
      "penalty: 0.2015270260142802\n",
      "h_val:  tensor(0.0616, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.826486731681164\n",
      "loss: 38.123306012211955\n",
      "penalty: 0.19971832532980777\n",
      "h_val:  tensor(0.0609, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.82857761242225\n",
      "loss: 38.122118951360534\n",
      "penalty: 0.19539178184159373\n",
      "h_val:  tensor(0.0589, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.839475850890012\n",
      "loss: 38.11862799679748\n",
      "penalty: 0.18267477098324192\n",
      "h_val:  tensor(0.0568, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.855427019876097\n",
      "loss: 38.11516981202025\n",
      "penalty: 0.1701920286128244\n",
      "h_val:  tensor(0.0550, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.87443377820216\n",
      "loss: 38.11195277108599\n",
      "penalty: 0.16001178231663818\n",
      "h_val:  tensor(0.0546, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.883702379156903\n",
      "loss: 38.110369305803985\n",
      "penalty: 0.15793776861068393\n",
      "h_val:  tensor(0.0550, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.884820177332833\n",
      "loss: 38.10839533830687\n",
      "penalty: 0.16025522344167284\n",
      "h_val:  tensor(0.0569, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.8807759626218505\n",
      "loss: 38.1020458027956\n",
      "penalty: 0.17127882066337996\n",
      "h_val:  tensor(0.0591, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.866433862816355\n",
      "loss: 38.09799176551205\n",
      "penalty: 0.18389260789817785\n",
      "h_val:  tensor(0.0603, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.851966596284495\n",
      "loss: 38.09598855683649\n",
      "penalty: 0.19167379382662555\n",
      "h_val:  tensor(0.0602, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.8479005800691\n",
      "loss: 38.0952165805361\n",
      "penalty: 0.1906360358964807\n",
      "h_val:  tensor(0.0598, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.842339289921626\n",
      "loss: 38.09189862828969\n",
      "penalty: 0.18871411951911468\n",
      "h_val:  tensor(0.0584, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.810926416761712\n",
      "loss: 38.07214411427698\n",
      "penalty: 0.17981968169148488\n",
      "h_val:  tensor(0.0580, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.787749297416375\n",
      "loss: 38.052186359253895\n",
      "penalty: 0.1774127027337278\n",
      "h_val:  tensor(0.0588, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.766640649628698\n",
      "loss: 38.03256391798369\n",
      "penalty: 0.1820890364652475\n",
      "h_val:  tensor(0.0590, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.763368984384929\n",
      "loss: 38.02142469323589\n",
      "penalty: 0.18353539236377348\n",
      "h_val:  tensor(0.0592, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.762099715774528\n",
      "loss: 38.01063664761552\n",
      "penalty: 0.18463253514022368\n",
      "h_val:  tensor(0.0606, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.747937955362459\n",
      "loss: 37.9893183012354\n",
      "penalty: 0.19348638696852422\n",
      "h_val:  tensor(0.0661, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.694161033110963\n",
      "loss: 37.9422425457928\n",
      "penalty: 0.2292788160576545\n",
      "h_val:  tensor(0.0682, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.650956323494752\n",
      "loss: 37.8915509099605\n",
      "penalty: 0.2439051416139271\n",
      "h_val:  tensor(0.0695, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.598053382413577\n",
      "loss: 37.84331551179645\n",
      "penalty: 0.253061577777178\n",
      "h_val:  tensor(0.0641, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.594463701390626\n",
      "loss: 37.81409069167228\n",
      "penalty: 0.21586869593805988\n",
      "h_val:  tensor(0.0672, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.548907818026022\n",
      "loss: 37.796878524067424\n",
      "penalty: 0.23692356686283053\n",
      "h_val:  tensor(0.0655, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.509363385195293\n",
      "loss: 37.76410042510293\n",
      "penalty: 0.22526070916448052\n",
      "h_val:  tensor(0.0652, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.348290242697847\n",
      "loss: 37.6606702331352\n",
      "penalty: 0.223270842056767\n",
      "h_val:  tensor(0.0661, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.224549454722389\n",
      "loss: 37.58284986238269\n",
      "penalty: 0.2288226094517802\n",
      "h_val:  tensor(0.0684, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.060859284139389\n",
      "loss: 37.46592142192708\n",
      "penalty: 0.24512860318597832\n",
      "h_val:  tensor(0.0763, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.840942027960863\n",
      "loss: 37.32932613963874\n",
      "penalty: 0.30368694657087275\n",
      "h_val:  tensor(0.0713, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.838569604838315\n",
      "loss: 37.2980554043113\n",
      "penalty: 0.26573174839100955\n",
      "h_val:  tensor(0.0671, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.803279078807261\n",
      "loss: 37.2427865468254\n",
      "penalty: 0.23624982634981712\n",
      "h_val:  tensor(0.0533, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.716080136904776\n",
      "loss: 37.07409112654613\n",
      "penalty: 0.150552053029901\n",
      "h_val:  tensor(0.0443, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.642398712844997\n",
      "loss: 36.940889580656474\n",
      "penalty: 0.1054303696802398\n",
      "h_val:  tensor(0.0405, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.637958922701057\n",
      "loss: 36.8977282598699\n",
      "penalty: 0.08875089557460471\n",
      "h_val:  tensor(0.0409, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.649520989906275\n",
      "loss: 36.87814789752615\n",
      "penalty: 0.09010133474803048\n",
      "h_val:  tensor(0.0428, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.663163411524208\n",
      "loss: 36.86141588308631\n",
      "penalty: 0.09851862898363674\n",
      "h_val:  tensor(0.0447, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.6578402722275944\n",
      "loss: 36.84623143029806\n",
      "penalty: 0.107085387849299\n",
      "h_val:  tensor(0.0514, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.609586090371722\n",
      "loss: 36.79488693543438\n",
      "penalty: 0.14013147907903897\n",
      "h_val:  tensor(0.0553, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.542356275903357\n",
      "loss: 36.74319006239939\n",
      "penalty: 0.161847486570099\n",
      "h_val:  tensor(0.0572, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.440104054388695\n",
      "loss: 36.680151911023025\n",
      "penalty: 0.1730265726548532\n",
      "h_val:  tensor(0.0560, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.380980274149547\n",
      "loss: 36.65087833233794\n",
      "penalty: 0.16604666786675215\n",
      "h_val:  tensor(0.0548, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.35534013074666\n",
      "loss: 36.6306870921051\n",
      "penalty: 0.1592158812957935\n",
      "h_val:  tensor(0.0533, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.27536924619529\n",
      "loss: 36.58787908603488\n",
      "penalty: 0.15038073935288238\n",
      "h_val:  tensor(0.0545, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.243656570329104\n",
      "loss: 36.56393549550779\n",
      "penalty: 0.1572137242225247\n",
      "h_val:  tensor(0.0559, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.232208307270682\n",
      "loss: 36.5303988369589\n",
      "penalty: 0.16524291236294128\n",
      "h_val:  tensor(0.0544, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.26760261960556\n",
      "loss: 36.5030791372035\n",
      "penalty: 0.1567081377727551\n",
      "h_val:  tensor(0.0520, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.303560610362118\n",
      "loss: 36.48813936523083\n",
      "penalty: 0.14348223592740764\n",
      "h_val:  tensor(0.0520, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.314556795290627\n",
      "loss: 36.47234753340239\n",
      "penalty: 0.1435684618964089\n",
      "h_val:  tensor(0.0520, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.303720996525089\n",
      "loss: 36.454755983600926\n",
      "penalty: 0.14337471836108126\n",
      "h_val:  tensor(0.0525, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.280713656316358\n",
      "loss: 36.44754605664072\n",
      "penalty: 0.14638769449985542\n",
      "h_val:  tensor(0.0535, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.259694125345771\n",
      "loss: 36.44454182765662\n",
      "penalty: 0.15151752092589107\n",
      "h_val:  tensor(0.0543, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.245828169645499\n",
      "loss: 36.442143767736525\n",
      "penalty: 0.15618885761587709\n",
      "h_val:  tensor(0.0554, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.221582779324904\n",
      "loss: 36.43190557832051\n",
      "penalty: 0.16224995261769234\n",
      "h_val:  tensor(0.0579, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.191692713107072\n",
      "loss: 36.41447342060104\n",
      "penalty: 0.17724802900776881\n",
      "h_val:  tensor(0.0574, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.199054865491871\n",
      "loss: 36.403510089894475\n",
      "penalty: 0.1739484760494811\n",
      "h_val:  tensor(0.0558, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.217909832427483\n",
      "loss: 36.39867961685005\n",
      "penalty: 0.1648894667312201\n",
      "h_val:  tensor(0.0550, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.222473037701182\n",
      "loss: 36.39619155095087\n",
      "penalty: 0.1602997046968679\n",
      "h_val:  tensor(0.0544, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.216369066726105\n",
      "loss: 36.39111926071531\n",
      "penalty: 0.15651060501378275\n",
      "h_val:  tensor(0.0546, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.199351035480452\n",
      "loss: 36.3874374468019\n",
      "penalty: 0.15758539310653244\n",
      "h_val:  tensor(0.0552, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.177914513309886\n",
      "loss: 36.38458807590253\n",
      "penalty: 0.16108213532634097\n",
      "h_val:  tensor(0.0559, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.1568281663450115\n",
      "loss: 36.38184887710897\n",
      "penalty: 0.1651657560384227\n",
      "h_val:  tensor(0.0564, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.136578580081923\n",
      "loss: 36.37770187496023\n",
      "penalty: 0.16827245375642594\n",
      "h_val:  tensor(0.0568, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.1155056088773785\n",
      "loss: 36.37137453470235\n",
      "penalty: 0.17043898154801354\n",
      "h_val:  tensor(0.0562, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.1138750636903\n",
      "loss: 36.36590714470054\n",
      "penalty: 0.16707552799039777\n",
      "h_val:  tensor(0.0548, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.128791954871177\n",
      "loss: 36.36156182280047\n",
      "penalty: 0.159097657176574\n",
      "h_val:  tensor(0.0541, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.13879020230097\n",
      "loss: 36.35982543350226\n",
      "penalty: 0.155282763763287\n",
      "h_val:  tensor(0.0544, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.136359861646063\n",
      "loss: 36.35630206914945\n",
      "penalty: 0.1568285659298129\n",
      "h_val:  tensor(0.0546, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.1321528434796555\n",
      "loss: 36.35027970229281\n",
      "penalty: 0.15761737299929415\n",
      "h_val:  tensor(0.0549, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.122038347024493\n",
      "loss: 36.34554079241412\n",
      "penalty: 0.159690118954417\n",
      "h_val:  tensor(0.0551, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.114185808423807\n",
      "loss: 36.34305638453855\n",
      "penalty: 0.1604070227196959\n",
      "h_val:  tensor(0.0549, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.111253546284515\n",
      "loss: 36.342023985639884\n",
      "penalty: 0.1595681605285147\n",
      "h_val:  tensor(0.0548, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.111028702748163\n",
      "loss: 36.3415134607109\n",
      "penalty: 0.15884088858024634\n",
      "h_val:  tensor(0.0546, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.111400999236752\n",
      "loss: 36.34049908908362\n",
      "penalty: 0.15785091204754498\n",
      "h_val:  tensor(0.0545, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.112410130740785\n",
      "loss: 36.33908556376646\n",
      "penalty: 0.15736254130554866\n",
      "h_val:  tensor(0.0546, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.114040650815587\n",
      "loss: 36.336917892356496\n",
      "penalty: 0.15801585766393483\n",
      "h_val:  tensor(0.0551, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.115319830319144\n",
      "loss: 36.33486111011503\n",
      "penalty: 0.1604286621654925\n",
      "h_val:  tensor(0.0554, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.115526795371069\n",
      "loss: 36.33382339036564\n",
      "penalty: 0.162500044100432\n",
      "h_val:  tensor(0.0555, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.1156227672674754\n",
      "loss: 36.33336083546496\n",
      "penalty: 0.1629592761882803\n",
      "h_val:  tensor(0.0555, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.115896187310397\n",
      "loss: 36.332938504726314\n",
      "penalty: 0.16280080871142918\n",
      "h_val:  tensor(0.0553, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.11682967008045\n",
      "loss: 36.332460269949735\n",
      "penalty: 0.16193810982239748\n",
      "h_val:  tensor(0.0550, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.119098485938523\n",
      "loss: 36.33181488937856\n",
      "penalty: 0.1600130869476718\n",
      "h_val:  tensor(0.0546, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.1214953039523055\n",
      "loss: 36.33135771729722\n",
      "penalty: 0.1581304342156258\n",
      "h_val:  tensor(0.0545, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.122188254104153\n",
      "loss: 36.331024248543976\n",
      "penalty: 0.1573485666433776\n",
      "h_val:  tensor(0.0544, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.121165176917747\n",
      "loss: 36.33012404160332\n",
      "penalty: 0.15680445530525075\n",
      "h_val:  tensor(0.0547, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.117216799679555\n",
      "loss: 36.328754464015546\n",
      "penalty: 0.15831604172834624\n",
      "h_val:  tensor(0.0552, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.113499092234672\n",
      "loss: 36.32766085022747\n",
      "penalty: 0.16127858931147357\n",
      "h_val:  tensor(0.0556, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.111329103880494\n",
      "loss: 36.32709661471094\n",
      "penalty: 0.16365686817791159\n",
      "h_val:  tensor(0.0557, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.1113676435836135\n",
      "loss: 36.326881086687614\n",
      "penalty: 0.16408163527955927\n",
      "h_val:  tensor(0.0556, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.1124506837341315\n",
      "loss: 36.32657725819988\n",
      "penalty: 0.16378877212640103\n",
      "h_val:  tensor(0.0554, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.115001855604042\n",
      "loss: 36.32614064918069\n",
      "penalty: 0.16248477790069496\n",
      "h_val:  tensor(0.0550, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.118257258752143\n",
      "loss: 36.325716604542734\n",
      "penalty: 0.16039393818446931\n",
      "h_val:  tensor(0.0548, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.120189962611296\n",
      "loss: 36.32546215317162\n",
      "penalty: 0.15871679552499762\n",
      "h_val:  tensor(0.0546, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.120549302832764\n",
      "loss: 36.32529175340969\n",
      "penalty: 0.157956746349305\n",
      "h_val:  tensor(0.0545, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.120330026942125\n",
      "loss: 36.32503850793754\n",
      "penalty: 0.1573774811561697\n",
      "h_val:  tensor(0.0545, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.119274868898819\n",
      "loss: 36.32467882587953\n",
      "penalty: 0.1572573257591096\n",
      "h_val:  tensor(0.0546, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.117567227775909\n",
      "loss: 36.32429462825548\n",
      "penalty: 0.157917769743056\n",
      "h_val:  tensor(0.0548, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.116166906673193\n",
      "loss: 36.32402686010283\n",
      "penalty: 0.15900873043182873\n",
      "h_val:  tensor(0.0549, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.11585154679601\n",
      "loss: 36.32390925908466\n",
      "penalty: 0.1596245000938099\n",
      "h_val:  tensor(0.0550, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.115811869099304\n",
      "loss: 36.323748695032975\n",
      "penalty: 0.15991110187632798\n",
      "h_val:  tensor(0.0551, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.115551643947655\n",
      "loss: 36.32314331120568\n",
      "penalty: 0.16068367081280746\n",
      "h_val:  tensor(0.0552, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.11485678229536\n",
      "loss: 36.322321462826245\n",
      "penalty: 0.16140886377798566\n",
      "h_val:  tensor(0.0554, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.113008931354399\n",
      "loss: 36.32102177329877\n",
      "penalty: 0.16237212889835564\n",
      "h_val:  tensor(0.0555, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.110830253821464\n",
      "loss: 36.320038376818275\n",
      "penalty: 0.16280641957499295\n",
      "h_val:  tensor(0.0555, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.108756710263326\n",
      "loss: 36.31935364916736\n",
      "penalty: 0.16280343673161396\n",
      "h_val:  tensor(0.0556, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.105274443067844\n",
      "loss: 36.31849231627933\n",
      "penalty: 0.16341217492487914\n",
      "h_val:  tensor(0.0560, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.098388042292087\n",
      "loss: 36.31715448546784\n",
      "penalty: 0.16596947335099294\n",
      "h_val:  tensor(0.0569, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.087909569458779\n",
      "loss: 36.31541630010827\n",
      "penalty: 0.17126545269374854\n",
      "h_val:  tensor(0.0580, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.076846295137233\n",
      "loss: 36.313498237509\n",
      "penalty: 0.17773453747093232\n",
      "h_val:  tensor(0.0590, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.066439437610545\n",
      "loss: 36.310922101400244\n",
      "penalty: 0.18378340920947853\n",
      "h_val:  tensor(0.0601, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.053956764672379\n",
      "loss: 36.306233141737\n",
      "penalty: 0.1900806628259632\n",
      "h_val:  tensor(0.0610, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.03885982298933\n",
      "loss: 36.29810297213747\n",
      "penalty: 0.1956736140263736\n",
      "h_val:  tensor(0.0619, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.019724427413733\n",
      "loss: 36.28611194781043\n",
      "penalty: 0.20129658708744266\n",
      "h_val:  tensor(0.0626, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.004209323727078\n",
      "loss: 36.277279997021594\n",
      "penalty: 0.20618449207655415\n",
      "h_val:  tensor(0.0624, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9994966321917924\n",
      "loss: 36.27222244676388\n",
      "penalty: 0.20465899140577656\n",
      "h_val:  tensor(0.0605, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.999143935389093\n",
      "loss: 36.26294400758794\n",
      "penalty: 0.19270162816160724\n",
      "h_val:  tensor(0.0599, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.995667037674939\n",
      "loss: 36.25731500103093\n",
      "penalty: 0.18928770248491866\n",
      "h_val:  tensor(0.0598, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.978384901155518\n",
      "loss: 36.24156060026259\n",
      "penalty: 0.1885905349883293\n",
      "h_val:  tensor(0.0608, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9645640275800953\n",
      "loss: 36.23330122084081\n",
      "penalty: 0.1948154883955372\n",
      "h_val:  tensor(0.0619, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.955082293638134\n",
      "loss: 36.22823974904781\n",
      "penalty: 0.20135514886325873\n",
      "h_val:  tensor(0.0609, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9583079770018355\n",
      "loss: 36.22575001366661\n",
      "penalty: 0.1953346332679064\n",
      "h_val:  tensor(0.0618, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9495656556088283\n",
      "loss: 36.22022702822161\n",
      "penalty: 0.20091036007546345\n",
      "h_val:  tensor(0.0618, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9476885080401884\n",
      "loss: 36.21090615997863\n",
      "penalty: 0.2009930519429881\n",
      "h_val:  tensor(0.0621, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9460085260423234\n",
      "loss: 36.20854601280619\n",
      "penalty: 0.20261433038886048\n",
      "h_val:  tensor(0.0622, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9423698362710664\n",
      "loss: 36.20452318402037\n",
      "penalty: 0.20349185371987935\n",
      "h_val:  tensor(0.0625, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.929882322911198\n",
      "loss: 36.19308266289216\n",
      "penalty: 0.2053165293959055\n",
      "h_val:  tensor(0.0623, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9165877247483114\n",
      "loss: 36.18055716631195\n",
      "penalty: 0.20418828745124012\n",
      "h_val:  tensor(0.0617, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9064576133791866\n",
      "loss: 36.170219724894416\n",
      "penalty: 0.20050657823806528\n",
      "h_val:  tensor(0.0616, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9009187953495723\n",
      "loss: 36.166909384629626\n",
      "penalty: 0.19972946135090008\n",
      "h_val:  tensor(0.0615, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.899908061217086\n",
      "loss: 36.16536112816646\n",
      "penalty: 0.19884563964001004\n",
      "h_val:  tensor(0.0609, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.900766062822442\n",
      "loss: 36.16296805470925\n",
      "penalty: 0.19504077234593273\n",
      "h_val:  tensor(0.0595, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9058474846237425\n",
      "loss: 36.15690674914643\n",
      "penalty: 0.18680217355657544\n",
      "h_val:  tensor(0.0582, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.912875506202608\n",
      "loss: 36.14979416642797\n",
      "penalty: 0.17851469399964204\n",
      "h_val:  tensor(0.0583, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.912496658693837\n",
      "loss: 36.145671679398994\n",
      "penalty: 0.17940813614434772\n",
      "h_val:  tensor(0.0592, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.907975113318741\n",
      "loss: 36.1430572935503\n",
      "penalty: 0.18453694628689882\n",
      "h_val:  tensor(0.0596, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9054762126018283\n",
      "loss: 36.14057254381559\n",
      "penalty: 0.187423987864672\n",
      "h_val:  tensor(0.0607, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.8995579671893577\n",
      "loss: 36.13048046706812\n",
      "penalty: 0.19424536047951224\n",
      "h_val:  tensor(0.0615, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.8956223415729814\n",
      "loss: 36.111835847276666\n",
      "penalty: 0.19886152435576068\n",
      "h_val:  tensor(0.0610, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.901072991017179\n",
      "loss: 36.077325770578895\n",
      "penalty: 0.19617452826186094\n",
      "h_val:  tensor(0.0591, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.91724580953569\n",
      "loss: 36.04837460267741\n",
      "penalty: 0.18400035207338275\n",
      "h_val:  tensor(0.0564, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.930179556656822\n",
      "loss: 36.02450849443239\n",
      "penalty: 0.1683193900619845\n",
      "h_val:  tensor(0.0533, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9471082306635514\n",
      "loss: 36.00541197820508\n",
      "penalty: 0.15060554954528516\n",
      "h_val:  tensor(0.0530, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9448029271197496\n",
      "loss: 35.99578738038298\n",
      "penalty: 0.1489874335040157\n",
      "h_val:  tensor(0.0528, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.941782183215562\n",
      "loss: 35.98445297480381\n",
      "penalty: 0.1481357539968837\n",
      "h_val:  tensor(0.0528, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9398749967711617\n",
      "loss: 35.97125009671915\n",
      "penalty: 0.14811787503022467\n",
      "h_val:  tensor(0.0524, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.943822636565343\n",
      "loss: 35.96323282824734\n",
      "penalty: 0.14557702890867805\n",
      "h_val:  tensor(0.0520, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9451123160574877\n",
      "loss: 35.959659374254265\n",
      "penalty: 0.14372248899980278\n",
      "h_val:  tensor(0.0516, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.945863413081781\n",
      "loss: 35.95581204077408\n",
      "penalty: 0.14148318313458533\n",
      "h_val:  tensor(0.0510, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.950282952666012\n",
      "loss: 35.94941721529657\n",
      "penalty: 0.13839618103551243\n",
      "h_val:  tensor(0.0503, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.9618623949061815\n",
      "loss: 35.94141127004712\n",
      "penalty: 0.13443570753454492\n",
      "h_val:  tensor(0.0490, grad_fn=<SubBackward0>)\n",
      "squared loss: 3.983980395924265\n",
      "loss: 35.93308961720411\n",
      "penalty: 0.12812637261645513\n",
      "h_val:  tensor(0.0481, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.000432665139154\n",
      "loss: 35.92859732938206\n",
      "penalty: 0.12340770199497353\n",
      "h_val:  tensor(0.0481, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.004658656269311\n",
      "loss: 35.92535817766869\n",
      "penalty: 0.12341038042853894\n",
      "h_val:  tensor(0.0481, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.009818790393228\n",
      "loss: 35.91906575748878\n",
      "penalty: 0.12329599350639736\n",
      "h_val:  tensor(0.0478, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.018726166864358\n",
      "loss: 35.91114687905552\n",
      "penalty: 0.12207909554296727\n",
      "h_val:  tensor(0.0470, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.029028778521967\n",
      "loss: 35.90497870564647\n",
      "penalty: 0.11785179206256201\n",
      "h_val:  tensor(0.0459, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.03802852651783\n",
      "loss: 35.90040557656767\n",
      "penalty: 0.11269912622463621\n",
      "h_val:  tensor(0.0453, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.040728118089528\n",
      "loss: 35.89827759421328\n",
      "penalty: 0.10969678916497932\n",
      "h_val:  tensor(0.0441, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.042444290816495\n",
      "loss: 35.89533731154466\n",
      "penalty: 0.10445859023963897\n",
      "h_val:  tensor(0.0435, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.042998048837039\n",
      "loss: 35.89287165917394\n",
      "penalty: 0.10164281285126829\n",
      "h_val:  tensor(0.0426, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.04388382821871\n",
      "loss: 35.88678849765562\n",
      "penalty: 0.09776734995526008\n",
      "h_val:  tensor(0.0424, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.045574320443536\n",
      "loss: 35.88001745248176\n",
      "penalty: 0.09656218980789757\n",
      "h_val:  tensor(0.0424, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.050327071045705\n",
      "loss: 35.87561929673253\n",
      "penalty: 0.0965351231913362\n",
      "h_val:  tensor(0.0421, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.054463294442796\n",
      "loss: 35.873589408284886\n",
      "penalty: 0.09539282654734542\n",
      "h_val:  tensor(0.0421, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.0548032579251565\n",
      "loss: 35.87278681778452\n",
      "penalty: 0.09533493522271393\n",
      "h_val:  tensor(0.0421, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.054296189164152\n",
      "loss: 35.872041155399536\n",
      "penalty: 0.09528379713055556\n",
      "h_val:  tensor(0.0421, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.052346798402215\n",
      "loss: 35.869627936049476\n",
      "penalty: 0.09560801177042108\n",
      "h_val:  tensor(0.0422, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.050326134819303\n",
      "loss: 35.866251917980904\n",
      "penalty: 0.09586513035385784\n",
      "h_val:  tensor(0.0421, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.049650884744341\n",
      "loss: 35.862222661062276\n",
      "penalty: 0.09521424686117741\n",
      "h_val:  tensor(0.0418, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.05067636940232\n",
      "loss: 35.86031603650785\n",
      "penalty: 0.09412738996445176\n",
      "h_val:  tensor(0.0417, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.051592869136527\n",
      "loss: 35.85970116605362\n",
      "penalty: 0.09350083047551228\n",
      "h_val:  tensor(0.0416, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.052264847568077\n",
      "loss: 35.85921012251243\n",
      "penalty: 0.09309898729785078\n",
      "h_val:  tensor(0.0414, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.05386606824961\n",
      "loss: 35.85801459338974\n",
      "penalty: 0.0923564643937153\n",
      "h_val:  tensor(0.0412, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.056151095086886\n",
      "loss: 35.85628783021285\n",
      "penalty: 0.0915197489353707\n",
      "h_val:  tensor(0.0408, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.060650202408195\n",
      "loss: 35.85323871491347\n",
      "penalty: 0.09000236768254204\n",
      "h_val:  tensor(0.0405, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.06543373207107\n",
      "loss: 35.850150617132776\n",
      "penalty: 0.08860985261813677\n",
      "h_val:  tensor(0.0405, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.067204952600058\n",
      "loss: 35.84878891166984\n",
      "penalty: 0.08860256193532985\n",
      "h_val:  tensor(0.0405, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.06683957643017\n",
      "loss: 35.84844187509388\n",
      "penalty: 0.08860054431901887\n",
      "h_val:  tensor(0.0405, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.066053692774504\n",
      "loss: 35.84798738864214\n",
      "penalty: 0.08843529965959353\n",
      "h_val:  tensor(0.0404, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.0661878639756495\n",
      "loss: 35.847698944298834\n",
      "penalty: 0.08794644433879867\n",
      "h_val:  tensor(0.0401, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.06759039096724\n",
      "loss: 35.84739125050622\n",
      "penalty: 0.08694177711365197\n",
      "h_val:  tensor(0.0400, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.069056404037176\n",
      "loss: 35.84721614980818\n",
      "penalty: 0.08630270134950273\n",
      "h_val:  tensor(0.0399, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.06999183309603\n",
      "loss: 35.84694399279764\n",
      "penalty: 0.08617379768484328\n",
      "h_val:  tensor(0.0401, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.0699247767712965\n",
      "loss: 35.846657139623765\n",
      "penalty: 0.08688748939788288\n",
      "h_val:  tensor(0.0402, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.0696002086705505\n",
      "loss: 35.8465723646785\n",
      "penalty: 0.08728696689239951\n",
      "h_val:  tensor(0.0403, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.06927641642961\n",
      "loss: 35.846447299363746\n",
      "penalty: 0.08766341791494812\n",
      "h_val:  tensor(0.0403, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.069160906401808\n",
      "loss: 35.846277293176975\n",
      "penalty: 0.08781529879711295\n",
      "h_val:  tensor(0.0403, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.06967363577166\n",
      "loss: 35.84603027491268\n",
      "penalty: 0.0875411616781791\n",
      "h_val:  tensor(0.0401, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.07085029659872\n",
      "loss: 35.84582374573282\n",
      "penalty: 0.0867906697669394\n",
      "h_val:  tensor(0.0399, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.071824025445942\n",
      "loss: 35.84573713000114\n",
      "penalty: 0.08607786848119395\n",
      "h_val:  tensor(0.0398, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.072098386693184\n",
      "loss: 35.845708469833745\n",
      "penalty: 0.08579230664888465\n",
      "h_new:  0.03984122702334014\n",
      "layer: 0 shape: torch.Size([20, 2])\n",
      "layer: 1 shape: torch.Size([20])\n",
      "layer: 2 shape: torch.Size([20, 2])\n",
      "layer: 3 shape: torch.Size([20])\n",
      "layer: 4 shape: torch.Size([2, 10, 1])\n",
      "layer: 5 shape: torch.Size([2, 1])\n",
      "rho:  100.0\n",
      "h_val:  tensor(0.0398, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.072098386693184\n",
      "loss: 36.00444080690628\n",
      "penalty: 0.24452464372141752\n",
      "h_val:  tensor(1153.1677, grad_fn=<SubBackward0>)\n",
      "squared loss: 45.75676450657683\n",
      "loss: 66494644.03497556\n",
      "penalty: 66494566.593658656\n",
      "h_val:  tensor(5.7578, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.46516790708247\n",
      "loss: 1756.656103563269\n",
      "penalty: 1681.5052992642325\n",
      "h_val:  tensor(0.1197, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.59160066438948\n",
      "loss: 69.49082869485923\n",
      "penalty: 1.2120333088361104\n",
      "h_val:  tensor(0.0388, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.078899465873303\n",
      "loss: 36.002465679326725\n",
      "penalty: 0.23575178911353012\n",
      "h_val:  tensor(0.0388, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.0781441135978405\n",
      "loss: 36.00242277243602\n",
      "penalty: 0.23646863173680938\n",
      "h_val:  tensor(0.0389, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.07770260675047\n",
      "loss: 36.00237576968323\n",
      "penalty: 0.23687378806272946\n",
      "h_val:  tensor(0.0390, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.077098771530773\n",
      "loss: 36.0022434195496\n",
      "penalty: 0.23738750110567097\n",
      "h_val:  tensor(0.0389, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.077157770999859\n",
      "loss: 36.002098090326\n",
      "penalty: 0.2372474133182173\n",
      "h_val:  tensor(0.0388, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.077918610460895\n",
      "loss: 36.00199917102171\n",
      "penalty: 0.23645017629560455\n",
      "h_val:  tensor(0.0388, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.0785887565232075\n",
      "loss: 36.00196173061254\n",
      "penalty: 0.23577150360704013\n",
      "h_val:  tensor(0.0387, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.0790739051030345\n",
      "loss: 36.00193632646435\n",
      "penalty: 0.23528207841152604\n",
      "h_new:  0.03869625268656396\n",
      "rho:  1000.0\n",
      "h_val:  tensor(0.0387, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.0790739051030345\n",
      "loss: 36.675766313856435\n",
      "penalty: 0.9091120658036098\n",
      "h_val:  tensor(951.6513, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.98862864591949\n",
      "loss: 452824087.7470539\n",
      "penalty: 452824012.0493017\n",
      "h_val:  tensor(5.2700, grad_fn=<SubBackward0>)\n",
      "squared loss: 43.20718236047741\n",
      "loss: 13983.279306039796\n",
      "penalty: 13908.379060210296\n",
      "h_val:  tensor(0.1113, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.55306990484327\n",
      "loss: 74.8945270734235\n",
      "penalty: 6.652629505974953\n",
      "h_val:  tensor(0.0292, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.378425799143686\n",
      "loss: 36.61344573812265\n",
      "penalty: 0.547379661179216\n",
      "h_val:  tensor(0.0328, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.206224983906644\n",
      "loss: 36.567771650159564\n",
      "penalty: 0.6739333254428306\n",
      "h_val:  tensor(0.0327, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.2080396357310335\n",
      "loss: 36.567610471943155\n",
      "penalty: 0.6719602203569084\n",
      "h_val:  tensor(0.0326, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.211762775390364\n",
      "loss: 36.56705786393351\n",
      "penalty: 0.6677081497364661\n",
      "h_val:  tensor(0.0327, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.210703570908622\n",
      "loss: 36.56687284588727\n",
      "penalty: 0.6686064883274794\n",
      "h_val:  tensor(0.0328, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.206013011176398\n",
      "loss: 36.56612224862105\n",
      "penalty: 0.6726916019377919\n",
      "h_val:  tensor(0.0328, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.203137084484204\n",
      "loss: 36.56536847275934\n",
      "penalty: 0.6749964476598015\n",
      "h_val:  tensor(0.0329, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.200959976612174\n",
      "loss: 36.56383006952521\n",
      "penalty: 0.67604838852383\n",
      "h_val:  tensor(0.0328, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.202178282026169\n",
      "loss: 36.561647429063015\n",
      "penalty: 0.6732558497058372\n",
      "h_val:  tensor(0.0325, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.208585896001958\n",
      "loss: 36.55821191062694\n",
      "penalty: 0.6643876979317023\n",
      "h_val:  tensor(0.0321, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.219980163903402\n",
      "loss: 36.55358318217644\n",
      "penalty: 0.6496760983965706\n",
      "h_val:  tensor(0.0316, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.234765762524838\n",
      "loss: 36.54674176865227\n",
      "penalty: 0.6299548873725164\n",
      "h_val:  tensor(0.0310, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.249336507534789\n",
      "loss: 36.536509797838164\n",
      "penalty: 0.6079994228909714\n",
      "h_val:  tensor(0.0306, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.253321350356549\n",
      "loss: 36.52435461495224\n",
      "penalty: 0.5953125842111309\n",
      "h_val:  tensor(0.0306, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.245869034230281\n",
      "loss: 36.51472803496516\n",
      "penalty: 0.5957480703634341\n",
      "h_val:  tensor(0.0306, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.2391673534985514\n",
      "loss: 36.506330916707185\n",
      "penalty: 0.5959054981871774\n",
      "h_val:  tensor(0.0304, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.235563218824244\n",
      "loss: 36.493047073440636\n",
      "penalty: 0.5891501364204983\n",
      "h_val:  tensor(0.0298, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.243218874714866\n",
      "loss: 36.473385802837605\n",
      "penalty: 0.566704376180395\n",
      "h_val:  tensor(0.0293, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.240884728926824\n",
      "loss: 36.44636823820693\n",
      "penalty: 0.5497341673438726\n",
      "h_val:  tensor(0.0261, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.330952009933773\n",
      "loss: 36.42065214275136\n",
      "penalty: 0.4481276526922627\n",
      "h_val:  tensor(0.0264, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.296266686775595\n",
      "loss: 36.3947815993151\n",
      "penalty: 0.4578988268896955\n",
      "h_val:  tensor(0.0264, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.267764377327735\n",
      "loss: 36.36487030594696\n",
      "penalty: 0.45917506639573036\n",
      "h_val:  tensor(0.0258, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.275253087426461\n",
      "loss: 36.34751340689913\n",
      "penalty: 0.43933696138856937\n",
      "h_val:  tensor(0.0248, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.297450086978999\n",
      "loss: 36.335683484017615\n",
      "penalty: 0.41057957370126313\n",
      "h_val:  tensor(0.0243, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.3082811622463195\n",
      "loss: 36.33054257266655\n",
      "penalty: 0.3967069319047245\n",
      "h_val:  tensor(0.0239, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.314502947376179\n",
      "loss: 36.324613015070014\n",
      "penalty: 0.38602062691343964\n",
      "h_val:  tensor(0.0232, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.3260589598634125\n",
      "loss: 36.31242812225931\n",
      "penalty: 0.36513225648729775\n",
      "h_val:  tensor(0.0227, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.335647044347815\n",
      "loss: 36.30311470430521\n",
      "penalty: 0.35073861028858666\n",
      "h_val:  tensor(0.0224, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.338927275734287\n",
      "loss: 36.298432060515836\n",
      "penalty: 0.34500630888547845\n",
      "h_val:  tensor(0.0221, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.344793813229037\n",
      "loss: 36.292903080437576\n",
      "penalty: 0.3365743403184299\n",
      "h_val:  tensor(0.0218, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.349435999787968\n",
      "loss: 36.28486662254518\n",
      "penalty: 0.32779005893273394\n",
      "h_val:  tensor(0.0211, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.359479530422803\n",
      "loss: 36.272215244593085\n",
      "penalty: 0.3108697225433282\n",
      "h_val:  tensor(0.0207, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.3623637976940755\n",
      "loss: 36.260722159065914\n",
      "penalty: 0.3008196915306131\n",
      "h_val:  tensor(0.0204, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.364397153794417\n",
      "loss: 36.251873562752806\n",
      "penalty: 0.2915660052444368\n",
      "h_val:  tensor(0.0207, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.349083142787598\n",
      "loss: 36.24546200411573\n",
      "penalty: 0.3004111315752295\n",
      "h_val:  tensor(0.0203, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.3523689264651315\n",
      "loss: 36.23836635095839\n",
      "penalty: 0.2892186169580267\n",
      "h_val:  tensor(0.0202, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.34587717457839\n",
      "loss: 36.231384862083466\n",
      "penalty: 0.28811697995836216\n",
      "h_val:  tensor(0.0202, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.3318169288869495\n",
      "loss: 36.21754053739399\n",
      "penalty: 0.2885129131826451\n",
      "h_val:  tensor(0.0201, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.328593639294701\n",
      "loss: 36.2091860133527\n",
      "penalty: 0.2853064705458943\n",
      "h_val:  tensor(0.0197, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.331108515943267\n",
      "loss: 36.199412769462505\n",
      "penalty: 0.27654019516975226\n",
      "h_val:  tensor(0.0195, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.330402830895967\n",
      "loss: 36.18967673427656\n",
      "penalty: 0.2704332126044606\n",
      "h_val:  tensor(0.0193, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.327497326695546\n",
      "loss: 36.181212145689344\n",
      "penalty: 0.26686957997705507\n",
      "h_val:  tensor(0.0193, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.323747834814976\n",
      "loss: 36.17746732136663\n",
      "penalty: 0.26674881297615327\n",
      "h_val:  tensor(0.0193, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.320857341295752\n",
      "loss: 36.1755815789719\n",
      "penalty: 0.2666913803179508\n",
      "h_val:  tensor(0.0193, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.31963175377595\n",
      "loss: 36.174629454609565\n",
      "penalty: 0.26604750368195423\n",
      "h_val:  tensor(0.0193, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.3179572773759105\n",
      "loss: 36.173691591388916\n",
      "penalty: 0.26624734595084765\n",
      "h_val:  tensor(0.0193, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.317871365225999\n",
      "loss: 36.17240304973066\n",
      "penalty: 0.26510486095059316\n",
      "h_val:  tensor(0.0193, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.316513245965631\n",
      "loss: 36.17101680999708\n",
      "penalty: 0.2659121835528961\n",
      "h_val:  tensor(0.0191, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.321457186622972\n",
      "loss: 36.169678588721204\n",
      "penalty: 0.2613652385918483\n",
      "h_val:  tensor(0.0191, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.322522222062121\n",
      "loss: 36.16851124718339\n",
      "penalty: 0.26091810895371637\n",
      "h_val:  tensor(0.0189, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.3271927207285925\n",
      "loss: 36.16723129051874\n",
      "penalty: 0.25686762727794293\n",
      "h_val:  tensor(0.0187, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.332401907735844\n",
      "loss: 36.16576494189634\n",
      "penalty: 0.25203869394354467\n",
      "h_val:  tensor(0.0185, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.337736095995386\n",
      "loss: 36.16450521549586\n",
      "penalty: 0.2467171572512156\n",
      "h_val:  tensor(0.0183, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.34135410458964\n",
      "loss: 36.16369849129038\n",
      "penalty: 0.24280034562098063\n",
      "h_val:  tensor(0.0182, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.342961024450423\n",
      "loss: 36.16320250743622\n",
      "penalty: 0.24088367514324968\n",
      "h_val:  tensor(0.0181, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.344152579088744\n",
      "loss: 36.162799928944345\n",
      "penalty: 0.2396080125341211\n",
      "h_val:  tensor(0.0181, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.345922546145895\n",
      "loss: 36.16242815340228\n",
      "penalty: 0.23810283824039402\n",
      "h_val:  tensor(0.0180, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.348691672966029\n",
      "loss: 36.1620668103737\n",
      "penalty: 0.23594891206235266\n",
      "h_val:  tensor(0.0179, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.351972444059286\n",
      "loss: 36.16175380326432\n",
      "penalty: 0.23344391428286923\n",
      "h_val:  tensor(0.0178, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.354586064594239\n",
      "loss: 36.16145794150454\n",
      "penalty: 0.2314805028812239\n",
      "h_val:  tensor(0.0176, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.358956117707557\n",
      "loss: 36.161043679446486\n",
      "penalty: 0.22780124011427932\n",
      "h_val:  tensor(0.0175, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.361001238042893\n",
      "loss: 36.160660172585246\n",
      "penalty: 0.22632915906828205\n",
      "h_val:  tensor(0.0175, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.362406588378327\n",
      "loss: 36.16037127660188\n",
      "penalty: 0.22506387403389547\n",
      "h_val:  tensor(0.0175, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.362411684094415\n",
      "loss: 36.16021083733362\n",
      "penalty: 0.22492381181361343\n",
      "h_val:  tensor(0.0175, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.36212390739288\n",
      "loss: 36.16013394195165\n",
      "penalty: 0.22508468750928082\n",
      "h_val:  tensor(0.0175, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.362157273586147\n",
      "loss: 36.16006036507412\n",
      "penalty: 0.22504097248663257\n",
      "h_val:  tensor(0.0175, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.362681024845519\n",
      "loss: 36.15995657561964\n",
      "penalty: 0.22468598087841252\n",
      "h_val:  tensor(0.0174, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.363724383691753\n",
      "loss: 36.159836823273665\n",
      "penalty: 0.22400803399019908\n",
      "h_val:  tensor(0.0174, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.36504655209425\n",
      "loss: 36.15970892583329\n",
      "penalty: 0.22315967183720792\n",
      "h_val:  tensor(0.0173, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.366533897078468\n",
      "loss: 36.159551443974195\n",
      "penalty: 0.222191043686522\n",
      "h_val:  tensor(0.0173, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.368004363136866\n",
      "loss: 36.15934960608319\n",
      "penalty: 0.2212361487533666\n",
      "h_val:  tensor(0.0173, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.369002115925913\n",
      "loss: 36.159153310040516\n",
      "penalty: 0.22053224935070126\n",
      "h_val:  tensor(0.0172, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.36936531582393\n",
      "loss: 36.15898901837254\n",
      "penalty: 0.22016326657020202\n",
      "h_val:  tensor(0.0172, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.369358984290503\n",
      "loss: 36.15886179799302\n",
      "penalty: 0.21997756992608553\n",
      "h_val:  tensor(0.0172, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.369464086672776\n",
      "loss: 36.15872193439112\n",
      "penalty: 0.21968916738472652\n",
      "h_val:  tensor(0.0172, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.370052903330829\n",
      "loss: 36.15845848594378\n",
      "penalty: 0.2190168584414836\n",
      "h_val:  tensor(0.0171, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.371568323998924\n",
      "loss: 36.15803579599218\n",
      "penalty: 0.21774296676910243\n",
      "h_val:  tensor(0.0171, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.373870081532636\n",
      "loss: 36.15759458543184\n",
      "penalty: 0.2161178883025697\n",
      "h_val:  tensor(0.0170, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.376247782410817\n",
      "loss: 36.15722269462819\n",
      "penalty: 0.21461900509287887\n",
      "h_val:  tensor(0.0169, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.3778697442553485\n",
      "loss: 36.156896379587536\n",
      "penalty: 0.2136916391354498\n",
      "h_val:  tensor(0.0169, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.379958466458333\n",
      "loss: 36.15638186569752\n",
      "penalty: 0.21234776577093756\n",
      "h_val:  tensor(0.0168, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.382126450414854\n",
      "loss: 36.15551569654243\n",
      "penalty: 0.21116184044165245\n",
      "h_val:  tensor(0.0167, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.385906761755684\n",
      "loss: 36.15442797846247\n",
      "penalty: 0.2084098159335786\n",
      "h_val:  tensor(0.0166, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.389218691161316\n",
      "loss: 36.15333318203966\n",
      "penalty: 0.2058583299651502\n",
      "h_val:  tensor(0.0165, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.391670574039463\n",
      "loss: 36.15245147157929\n",
      "penalty: 0.2036943144801377\n",
      "h_val:  tensor(0.0164, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.392996635153121\n",
      "loss: 36.15148264801566\n",
      "penalty: 0.20242554578657623\n",
      "h_val:  tensor(0.0163, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.3955952117057135\n",
      "loss: 36.14957075063456\n",
      "penalty: 0.2002303094344649\n",
      "h_val:  tensor(0.0162, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.398989491682718\n",
      "loss: 36.14679949290957\n",
      "penalty: 0.19836109747123556\n",
      "h_val:  tensor(0.0160, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.405496382699837\n",
      "loss: 36.14372382568186\n",
      "penalty: 0.19483787744576833\n",
      "h_val:  tensor(0.0158, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.412307301854486\n",
      "loss: 36.141362077401695\n",
      "penalty: 0.19109432989792235\n",
      "h_val:  tensor(0.0157, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.416206879527194\n",
      "loss: 36.139382622705455\n",
      "penalty: 0.1889794761873008\n",
      "h_val:  tensor(0.0151, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.432186382258912\n",
      "loss: 36.135431753450916\n",
      "penalty: 0.17688578793427648\n",
      "h_val:  tensor(0.0150, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.441018854500942\n",
      "loss: 36.12944150414012\n",
      "penalty: 0.17547418522454503\n",
      "h_val:  tensor(0.0145, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.450730901165212\n",
      "loss: 36.12381669220893\n",
      "penalty: 0.16596317000698857\n",
      "h_val:  tensor(0.0140, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.461639946220668\n",
      "loss: 36.119101111105124\n",
      "penalty: 0.15540011846064358\n",
      "h_val:  tensor(0.0140, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.460855093123532\n",
      "loss: 36.118228714192554\n",
      "penalty: 0.1553892358001662\n",
      "h_val:  tensor(0.0141, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.457077480744662\n",
      "loss: 36.11601824314983\n",
      "penalty: 0.15739436899357417\n",
      "h_val:  tensor(0.0141, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.455578194929794\n",
      "loss: 36.11440801797136\n",
      "penalty: 0.15859788823128979\n",
      "h_val:  tensor(0.0141, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.456476896291945\n",
      "loss: 36.112891044004165\n",
      "penalty: 0.15841616787197751\n",
      "h_val:  tensor(0.0141, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.4575373384046415\n",
      "loss: 36.11244994774622\n",
      "penalty: 0.15768743009816505\n",
      "h_val:  tensor(0.0141, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.457886362208147\n",
      "loss: 36.11217689888957\n",
      "penalty: 0.1572920870585109\n",
      "h_val:  tensor(0.0141, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.4575330650676195\n",
      "loss: 36.111642425759115\n",
      "penalty: 0.15710618676210356\n",
      "h_val:  tensor(0.0141, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.456232091335356\n",
      "loss: 36.11097434768802\n",
      "penalty: 0.15735394818523504\n",
      "h_val:  tensor(0.0141, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.4538646060840925\n",
      "loss: 36.110321968922214\n",
      "penalty: 0.1582123621853764\n",
      "h_val:  tensor(0.0142, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.450996273114655\n",
      "loss: 36.109864213754676\n",
      "penalty: 0.15950133447725884\n",
      "h_val:  tensor(0.0142, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.448854460892701\n",
      "loss: 36.10951070686001\n",
      "penalty: 0.16044259751455028\n",
      "h_val:  tensor(0.0144, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.444352609956764\n",
      "loss: 36.1087125042423\n",
      "penalty: 0.16291350277058306\n",
      "h_val:  tensor(0.0147, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.433808380542304\n",
      "loss: 36.10679804540925\n",
      "penalty: 0.16840338939976718\n",
      "h_val:  tensor(0.0149, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.425476020446202\n",
      "loss: 36.1053413128217\n",
      "penalty: 0.17335871303228584\n",
      "h_val:  tensor(0.0151, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.420437174372818\n",
      "loss: 36.104294862804345\n",
      "penalty: 0.17641877050537375\n",
      "h_val:  tensor(0.0151, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.419037483765085\n",
      "loss: 36.10378086057772\n",
      "penalty: 0.17728455020742967\n",
      "h_val:  tensor(0.0151, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.41744952450997\n",
      "loss: 36.10271280439674\n",
      "penalty: 0.17737859048228613\n",
      "h_val:  tensor(0.0154, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.41052231082418\n",
      "loss: 36.10137028811005\n",
      "penalty: 0.18183507373002888\n",
      "h_val:  tensor(0.0154, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.408603804968001\n",
      "loss: 36.10049412304371\n",
      "penalty: 0.1815236402547331\n",
      "h_val:  tensor(0.0154, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.405128842491909\n",
      "loss: 36.099869448863\n",
      "penalty: 0.18290072930734852\n",
      "h_val:  tensor(0.0155, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.402207339284103\n",
      "loss: 36.099189237254755\n",
      "penalty: 0.18389591745783768\n",
      "h_val:  tensor(0.0158, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.392686359757861\n",
      "loss: 36.09791483466716\n",
      "penalty: 0.1896235546145327\n",
      "h_val:  tensor(0.0160, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.386908237365108\n",
      "loss: 36.097136668891245\n",
      "penalty: 0.1934652698796443\n",
      "h_val:  tensor(0.0161, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.383238623090969\n",
      "loss: 36.0966602736715\n",
      "penalty: 0.19632168310935896\n",
      "h_val:  tensor(0.0162, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.381434821029552\n",
      "loss: 36.09635281661725\n",
      "penalty: 0.19782545260321116\n",
      "h_val:  tensor(0.0163, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.377811253716721\n",
      "loss: 36.095683242941064\n",
      "penalty: 0.20052855960349278\n",
      "h_val:  tensor(0.0165, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.372484930747933\n",
      "loss: 36.094796473891336\n",
      "penalty: 0.20406083766546296\n",
      "h_val:  tensor(0.0166, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.368746247240199\n",
      "loss: 36.09420749009465\n",
      "penalty: 0.20601800846305407\n",
      "h_val:  tensor(0.0166, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.367826186670146\n",
      "loss: 36.09399767323666\n",
      "penalty: 0.2060299729622307\n",
      "h_val:  tensor(0.0166, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.367635541336947\n",
      "loss: 36.09391123623049\n",
      "penalty: 0.20586868557967608\n",
      "h_val:  tensor(0.0166, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.36729625304993\n",
      "loss: 36.09379708569686\n",
      "penalty: 0.20582677726381346\n",
      "h_val:  tensor(0.0166, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.366401982862954\n",
      "loss: 36.093646811826744\n",
      "penalty: 0.2063068565720167\n",
      "h_val:  tensor(0.0166, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.364767236856664\n",
      "loss: 36.09348402293562\n",
      "penalty: 0.20757521144877775\n",
      "h_val:  tensor(0.0167, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.363345392075959\n",
      "loss: 36.093394419320916\n",
      "penalty: 0.20888999730120406\n",
      "h_val:  tensor(0.0167, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.362833677628215\n",
      "loss: 36.09335212120866\n",
      "penalty: 0.20942573053757202\n",
      "h_val:  tensor(0.0168, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.362170636510568\n",
      "loss: 36.093257268281576\n",
      "penalty: 0.21008773656049684\n",
      "h_val:  tensor(0.0168, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.361132767072112\n",
      "loss: 36.093046440452206\n",
      "penalty: 0.21110825318040194\n",
      "h_val:  tensor(0.0168, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.360871242575531\n",
      "loss: 36.092908752108706\n",
      "penalty: 0.21126318494409593\n",
      "h_val:  tensor(0.0168, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.361180761689042\n",
      "loss: 36.0928261597185\n",
      "penalty: 0.21077783058907226\n",
      "h_val:  tensor(0.0168, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.361545995139093\n",
      "loss: 36.092799356483\n",
      "penalty: 0.21031796651856885\n",
      "h_new:  0.016778742143834346\n",
      "rho:  10000.0\n",
      "h_val:  tensor(0.0168, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.361545995139093\n",
      "loss: 37.35966720216477\n",
      "penalty: 1.4771858122003416\n",
      "h_val:  tensor(900.7985, grad_fn=<SubBackward0>)\n",
      "squared loss: 40.87092420359091\n",
      "loss: 4057193598.943479\n",
      "penalty: 4057193526.5270844\n",
      "h_val:  tensor(5.4482, grad_fn=<SubBackward0>)\n",
      "squared loss: 40.163062660590406\n",
      "loss: 148508.14312751548\n",
      "penalty: 148436.45271747076\n",
      "h_val:  tensor(0.1461, grad_fn=<SubBackward0>)\n",
      "squared loss: 33.40711189289067\n",
      "loss: 172.19746433178685\n",
      "penalty: 107.26796295289664\n",
      "h_val:  tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "squared loss: 10.112877569759709\n",
      "loss: 41.63556147191052\n",
      "penalty: 0.001427968207419406\n",
      "h_val:  tensor(0.0113, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.704455639094774\n",
      "loss: 36.9148775295887\n",
      "penalty: 0.6894218734987687\n",
      "h_val:  tensor(0.0113, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.7084704897317184\n",
      "loss: 36.9091084465326\n",
      "penalty: 0.6796385226254225\n",
      "h_val:  tensor(0.0111, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.710914399805728\n",
      "loss: 36.897238769781865\n",
      "penalty: 0.665337617823352\n",
      "h_val:  tensor(0.0111, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.711817791484462\n",
      "loss: 36.896996231193825\n",
      "penalty: 0.6642014569046671\n",
      "h_val:  tensor(0.0111, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.712382597258408\n",
      "loss: 36.896654750576126\n",
      "penalty: 0.6633247510580647\n",
      "h_val:  tensor(0.0111, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.712305773779589\n",
      "loss: 36.89628157305821\n",
      "penalty: 0.6630746107917593\n",
      "h_val:  tensor(0.0111, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.711694189369151\n",
      "loss: 36.89553851677416\n",
      "penalty: 0.6630498501011854\n",
      "h_val:  tensor(0.0111, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.7109895536566055\n",
      "loss: 36.89428662341665\n",
      "penalty: 0.6626987411673372\n",
      "h_val:  tensor(0.0111, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.71134816801355\n",
      "loss: 36.892583831516305\n",
      "penalty: 0.6609289053890702\n",
      "h_val:  tensor(0.0111, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.712729118244832\n",
      "loss: 36.89134814172813\n",
      "penalty: 0.6585336443741411\n",
      "h_val:  tensor(0.0111, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.713530206698749\n",
      "loss: 36.89079396984334\n",
      "penalty: 0.6572386523056761\n",
      "h_val:  tensor(0.0110, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.715104913169832\n",
      "loss: 36.88956647172253\n",
      "penalty: 0.6545427018947283\n",
      "h_val:  tensor(0.0111, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.706482825512493\n",
      "loss: 36.88542569124273\n",
      "penalty: 0.6595054363936678\n",
      "h_val:  tensor(0.0109, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.72875209560032\n",
      "loss: 36.88209705635882\n",
      "penalty: 0.6344224061733928\n",
      "h_val:  tensor(0.0109, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.7262292521744715\n",
      "loss: 36.87824659104185\n",
      "penalty: 0.6336210343280316\n",
      "h_val:  tensor(0.0108, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.723015156827929\n",
      "loss: 36.870478438732476\n",
      "penalty: 0.630233504157357\n",
      "h_val:  tensor(0.0108, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.72284877318289\n",
      "loss: 36.86461983619924\n",
      "penalty: 0.6254440906261535\n",
      "h_val:  tensor(0.0107, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.725958609808223\n",
      "loss: 36.85933978032806\n",
      "penalty: 0.6178569804067774\n",
      "h_val:  tensor(0.0107, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.729410528286687\n",
      "loss: 36.856689413561526\n",
      "penalty: 0.6120333881968624\n",
      "h_val:  tensor(0.0106, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.731150243090128\n",
      "loss: 36.85277341417062\n",
      "penalty: 0.6066814804283572\n",
      "h_val:  tensor(0.0105, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.732921403250777\n",
      "loss: 36.83813115878021\n",
      "penalty: 0.5916456974706704\n",
      "h_val:  tensor(0.0102, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.736303782441929\n",
      "loss: 36.81276123125511\n",
      "penalty: 0.5658448911404703\n",
      "h_val:  tensor(0.0098, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.748119891752462\n",
      "loss: 36.7740301937074\n",
      "penalty: 0.520706257021858\n",
      "h_val:  tensor(0.0092, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.771636169592532\n",
      "loss: 36.73518849309224\n",
      "penalty: 0.4647450440529718\n",
      "h_val:  tensor(0.0089, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.784882411479345\n",
      "loss: 36.70983382019346\n",
      "penalty: 0.43040431538940027\n",
      "h_val:  tensor(0.0087, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.787998347229964\n",
      "loss: 36.6946822861368\n",
      "penalty: 0.41376181037015614\n",
      "h_val:  tensor(0.0087, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.769792353531147\n",
      "loss: 36.67861864779859\n",
      "penalty: 0.41715775116647874\n",
      "h_val:  tensor(0.0083, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.794084975666281\n",
      "loss: 36.66656054777075\n",
      "penalty: 0.382066144124688\n",
      "h_val:  tensor(0.0084, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.781543062610762\n",
      "loss: 36.65968059282551\n",
      "penalty: 0.38865310617299237\n",
      "h_val:  tensor(0.0083, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.780005704483229\n",
      "loss: 36.64804279567902\n",
      "penalty: 0.38044461329602175\n",
      "h_val:  tensor(0.0081, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.784610622644016\n",
      "loss: 36.63343856519876\n",
      "penalty: 0.36380735709724404\n",
      "h_val:  tensor(0.0078, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.796695223450808\n",
      "loss: 36.613479244471506\n",
      "penalty: 0.33548773624795275\n",
      "h_val:  tensor(0.0075, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.807847010393091\n",
      "loss: 36.59775348471111\n",
      "penalty: 0.31140047260453346\n",
      "h_val:  tensor(0.0074, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.80819170501402\n",
      "loss: 36.58914072700169\n",
      "penalty: 0.30335955995905467\n",
      "h_val:  tensor(0.0074, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.802301084215223\n",
      "loss: 36.58454237589574\n",
      "penalty: 0.3045225648742681\n",
      "h_val:  tensor(0.0074, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.795409820354203\n",
      "loss: 36.578414545777825\n",
      "penalty: 0.30516792158831973\n",
      "h_val:  tensor(0.0074, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.789895185972206\n",
      "loss: 36.571221710877076\n",
      "penalty: 0.30369850528391173\n",
      "h_val:  tensor(0.0073, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.791370569385609\n",
      "loss: 36.56611092594944\n",
      "penalty: 0.2978280685179015\n",
      "h_val:  tensor(0.0072, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.798586999471663\n",
      "loss: 36.56280174972665\n",
      "penalty: 0.28830016737570363\n",
      "h_val:  tensor(0.0071, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.8035014870167725\n",
      "loss: 36.56058026460931\n",
      "penalty: 0.2818883676107176\n",
      "h_val:  tensor(0.0071, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.804631634353025\n",
      "loss: 36.55759704230144\n",
      "penalty: 0.27846383646706724\n",
      "h_val:  tensor(0.0071, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.802466657939838\n",
      "loss: 36.55573581397214\n",
      "penalty: 0.27897187635545856\n",
      "h_val:  tensor(0.0071, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.798112326276747\n",
      "loss: 36.5548398946905\n",
      "penalty: 0.2823405531801499\n",
      "h_val:  tensor(0.0071, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.794980079845173\n",
      "loss: 36.55393455916545\n",
      "penalty: 0.28441932884303645\n",
      "h_val:  tensor(0.0072, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.79083525715817\n",
      "loss: 36.552475214847355\n",
      "penalty: 0.28699971096406074\n",
      "h_val:  tensor(0.0072, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.789060525851389\n",
      "loss: 36.55037643341875\n",
      "penalty: 0.2867708258735416\n",
      "h_val:  tensor(0.0071, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.792191675733497\n",
      "loss: 36.54827518887072\n",
      "penalty: 0.2819738986212361\n",
      "h_val:  tensor(0.0070, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.797791435551651\n",
      "loss: 36.54705418273935\n",
      "penalty: 0.27571272291765375\n",
      "h_val:  tensor(0.0070, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.801045503881082\n",
      "loss: 36.546371730116334\n",
      "penalty: 0.2721880448422451\n",
      "h_val:  tensor(0.0069, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.804520167639849\n",
      "loss: 36.54539929825874\n",
      "penalty: 0.26823840493020507\n",
      "h_val:  tensor(0.0069, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.806390034220462\n",
      "loss: 36.544271470350644\n",
      "penalty: 0.26585530368848964\n",
      "h_val:  tensor(0.0069, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.806719040068416\n",
      "loss: 36.543542527987206\n",
      "penalty: 0.26512982382977734\n",
      "h_val:  tensor(0.0069, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.805902749677143\n",
      "loss: 36.54300806652869\n",
      "penalty: 0.2655601735765506\n",
      "h_val:  tensor(0.0069, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.805581186381527\n",
      "loss: 36.54250744836485\n",
      "penalty: 0.26549735275515907\n",
      "h_val:  tensor(0.0069, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.806657782954077\n",
      "loss: 36.541733302557006\n",
      "penalty: 0.2639274192776474\n",
      "h_val:  tensor(0.0068, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.809376205725017\n",
      "loss: 36.54109826003726\n",
      "penalty: 0.2609538210793413\n",
      "h_val:  tensor(0.0068, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.812628914866974\n",
      "loss: 36.54068492586089\n",
      "penalty: 0.25766361578540636\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.814541140050401\n",
      "loss: 36.54045536464356\n",
      "penalty: 0.25575365294381536\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.815834853603937\n",
      "loss: 36.54016356729805\n",
      "penalty: 0.25439700163786444\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.817325358020288\n",
      "loss: 36.53956836321526\n",
      "penalty: 0.2527033067177287\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.818268641319764\n",
      "loss: 36.53873415481905\n",
      "penalty: 0.25141943189562266\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.818472942958202\n",
      "loss: 36.53788702434772\n",
      "penalty: 0.25079719891218794\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.818091086405018\n",
      "loss: 36.53724340917655\n",
      "penalty: 0.2507547553131707\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.817972899651988\n",
      "loss: 36.53672126509382\n",
      "penalty: 0.2504301247629252\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.818662089183519\n",
      "loss: 36.536155347319095\n",
      "penalty: 0.24924170074211555\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.820325631764809\n",
      "loss: 36.53567641442537\n",
      "penalty: 0.247208348320528\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.82194242843762\n",
      "loss: 36.535358539244555\n",
      "penalty: 0.2454054663198242\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.822760022556179\n",
      "loss: 36.53506888252289\n",
      "penalty: 0.24440321332026815\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.822866879826627\n",
      "loss: 36.53463637398935\n",
      "penalty: 0.24397033664913156\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.821825275007524\n",
      "loss: 36.53418072636275\n",
      "penalty: 0.24460027234388404\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.819908149791023\n",
      "loss: 36.533795459322505\n",
      "penalty: 0.24607964297030446\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.818165613105505\n",
      "loss: 36.53356345978697\n",
      "penalty: 0.24747969179076837\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.817207056649165\n",
      "loss: 36.53342079499217\n",
      "penalty: 0.24820686580279055\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.816439278407033\n",
      "loss: 36.533196547912354\n",
      "penalty: 0.24866600030877295\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.815779832217508\n",
      "loss: 36.53282870107184\n",
      "penalty: 0.24886692503255384\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.815838008080255\n",
      "loss: 36.53257284879324\n",
      "penalty: 0.24854472261801627\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.81619744005265\n",
      "loss: 36.532430240031694\n",
      "penalty: 0.24809308529930557\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.816333920714266\n",
      "loss: 36.53235176144932\n",
      "penalty: 0.24792981633409555\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.816238021841022\n",
      "loss: 36.53224703270253\n",
      "penalty: 0.24797906220483473\n",
      "h_val:  tensor(0.0066, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.8158058283266545\n",
      "loss: 36.53212793044372\n",
      "penalty: 0.24834423823507876\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.815305913250098\n",
      "loss: 36.53204883735693\n",
      "penalty: 0.2487789168464741\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.815005810858398\n",
      "loss: 36.53200347393879\n",
      "penalty: 0.24902674102046396\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.814986603863028\n",
      "loss: 36.53196910292423\n",
      "penalty: 0.24901273811733365\n",
      "h_new:  0.006654715210518081\n",
      "layer: 0 shape: torch.Size([20, 2])\n",
      "layer: 1 shape: torch.Size([20])\n",
      "layer: 2 shape: torch.Size([20, 2])\n",
      "layer: 3 shape: torch.Size([20])\n",
      "layer: 4 shape: torch.Size([2, 10, 1])\n",
      "layer: 5 shape: torch.Size([2, 1])\n",
      "rho:  10000.0\n",
      "h_val:  tensor(0.0067, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.814986603863028\n",
      "loss: 36.974821448255234\n",
      "penalty: 0.6918650834483406\n",
      "h_val:  tensor(1026.5461, grad_fn=<SubBackward0>)\n",
      "squared loss: 39.11488155898218\n",
      "loss: 5269057086.870151\n",
      "penalty: 5269057016.266345\n",
      "h_val:  tensor(6.0019, grad_fn=<SubBackward0>)\n",
      "squared loss: 38.457554590415754\n",
      "loss: 180609.52538927345\n",
      "penalty: 180539.59456700084\n",
      "h_val:  tensor(0.1892, grad_fn=<SubBackward0>)\n",
      "squared loss: 32.290940245116154\n",
      "loss: 256.07159288766684\n",
      "penalty: 192.311505748365\n",
      "h_val:  tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "squared loss: 9.428607336314068\n",
      "loss: 40.91637554644244\n",
      "penalty: 0.019587257395705923\n",
      "h_val:  tensor(0.0055, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.928630653943792\n",
      "loss: 36.93333130523424\n",
      "penalty: 0.536713708465288\n",
      "h_val:  tensor(0.0055, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.9307355849700505\n",
      "loss: 36.93265597295418\n",
      "penalty: 0.5339345794494715\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.93329831003375\n",
      "loss: 36.93167578352683\n",
      "penalty: 0.5304017092163831\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.933357860935648\n",
      "loss: 36.93164130254974\n",
      "penalty: 0.5303144404959189\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.9336059721082846\n",
      "loss: 36.93153011538745\n",
      "penalty: 0.5299821946440901\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.93362040703199\n",
      "loss: 36.931291844960846\n",
      "penalty: 0.5298214147328071\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.9334387136051685\n",
      "loss: 36.93120035422965\n",
      "penalty: 0.5299626710509394\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.933254146761414\n",
      "loss: 36.93109034257187\n",
      "penalty: 0.5300990217151841\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.9332318624704525\n",
      "loss: 36.930965032025895\n",
      "penalty: 0.5300643370600279\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.933436577302737\n",
      "loss: 36.93086888529064\n",
      "penalty: 0.5298102514997463\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.933673566352998\n",
      "loss: 36.93079723416779\n",
      "penalty: 0.5295251899659483\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.934033636769267\n",
      "loss: 36.93064249122084\n",
      "penalty: 0.529071203917248\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.934854263980201\n",
      "loss: 36.93032785285341\n",
      "penalty: 0.5280947305514776\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.935898391105303\n",
      "loss: 36.92986661760314\n",
      "penalty: 0.5268722308965272\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.937266564778696\n",
      "loss: 36.92924362881853\n",
      "penalty: 0.5253414109889097\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.93798448513693\n",
      "loss: 36.92878528101969\n",
      "penalty: 0.5245594622324528\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.9377326947849705\n",
      "loss: 36.92852707523388\n",
      "penalty: 0.5247388891910664\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.937524087242006\n",
      "loss: 36.928110259280956\n",
      "penalty: 0.5247437816447345\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.938067879227583\n",
      "loss: 36.927139063608784\n",
      "penalty: 0.5237981768002665\n",
      "h_val:  tensor(0.0054, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.937763435681543\n",
      "loss: 36.925926150021034\n",
      "penalty: 0.5236332513331998\n",
      "h_val:  tensor(0.0053, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.9508298715848404\n",
      "loss: 36.923437235585055\n",
      "penalty: 0.5099227239355952\n",
      "h_val:  tensor(0.0053, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.945122440779848\n",
      "loss: 36.92100641442711\n",
      "penalty: 0.5151388178157275\n",
      "h_val:  tensor(0.0052, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.950763270208432\n",
      "loss: 36.91920721714877\n",
      "penalty: 0.5088898189281076\n",
      "h_val:  tensor(0.0052, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.9544439138609935\n",
      "loss: 36.91832734203536\n",
      "penalty: 0.5048122826660306\n",
      "h_val:  tensor(0.0052, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.954553264842108\n",
      "loss: 36.91814093175329\n",
      "penalty: 0.5045050552654455\n",
      "h_val:  tensor(0.0052, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.954387277350342\n",
      "loss: 36.91788247544841\n",
      "penalty: 0.5044563118170111\n",
      "h_val:  tensor(0.0052, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.954238113312617\n",
      "loss: 36.91740480540521\n",
      "penalty: 0.504343968941906\n",
      "h_val:  tensor(0.0052, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.9545441811877575\n",
      "loss: 36.91662204772324\n",
      "penalty: 0.503805690564154\n",
      "h_val:  tensor(0.0052, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.955999336407307\n",
      "loss: 36.915463417957525\n",
      "penalty: 0.5022528401146888\n",
      "h_val:  tensor(0.0052, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.95887852753473\n",
      "loss: 36.914255203037094\n",
      "penalty: 0.4994447908530024\n",
      "h_val:  tensor(0.0051, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.96188647901674\n",
      "loss: 36.91333185427697\n",
      "penalty: 0.49642351808490215\n",
      "h_val:  tensor(0.0051, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.964515424772567\n",
      "loss: 36.91263883222653\n",
      "penalty: 0.4935104346306507\n",
      "h_val:  tensor(0.0051, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.965762169062155\n",
      "loss: 36.91186515827849\n",
      "penalty: 0.4917631793761994\n",
      "h_val:  tensor(0.0051, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.966992677386165\n",
      "loss: 36.91107389201643\n",
      "penalty: 0.49002167849092526\n",
      "h_val:  tensor(0.0051, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.9660532460709\n",
      "loss: 36.91042085272465\n",
      "penalty: 0.4906110343299739\n",
      "h_val:  tensor(0.0051, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.965658883793034\n",
      "loss: 36.909734727845674\n",
      "penalty: 0.4907594834361035\n",
      "h_val:  tensor(0.0051, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.965620964798985\n",
      "loss: 36.908903130667206\n",
      "penalty: 0.4906209591118352\n",
      "h_val:  tensor(0.0051, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.9665767457589896\n",
      "loss: 36.90780901153964\n",
      "penalty: 0.489530125539726\n",
      "h_val:  tensor(0.0051, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.968988457836182\n",
      "loss: 36.90663324950517\n",
      "penalty: 0.48700892472022395\n",
      "h_val:  tensor(0.0050, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.972137545862816\n",
      "loss: 36.90572414357689\n",
      "penalty: 0.4836780978775548\n",
      "h_val:  tensor(0.0050, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.974687499140254\n",
      "loss: 36.90507925976821\n",
      "penalty: 0.48076579348019594\n",
      "h_val:  tensor(0.0050, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.976489681919392\n",
      "loss: 36.90415592561289\n",
      "penalty: 0.4783033789503931\n",
      "h_val:  tensor(0.0050, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.9791975394049\n",
      "loss: 36.90218232658312\n",
      "penalty: 0.4742993521466338\n",
      "h_val:  tensor(0.0049, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.980763918001486\n",
      "loss: 36.89944185385347\n",
      "penalty: 0.47121295844553335\n",
      "h_val:  tensor(0.0049, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.981937898535319\n",
      "loss: 36.89607714987262\n",
      "penalty: 0.4685394848862468\n",
      "h_val:  tensor(0.0049, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.982250116988694\n",
      "loss: 36.892915884978294\n",
      "penalty: 0.4670748582598973\n",
      "h_val:  tensor(0.0049, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.982638556649248\n",
      "loss: 36.88994779828747\n",
      "penalty: 0.4655436968329586\n",
      "h_val:  tensor(0.0049, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.983954691230459\n",
      "loss: 36.88665531207377\n",
      "penalty: 0.46274002789896584\n",
      "h_val:  tensor(0.0048, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.986821486523526\n",
      "loss: 36.88367354113097\n",
      "penalty: 0.4584399963925123\n",
      "h_val:  tensor(0.0048, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.99008218522197\n",
      "loss: 36.88169785605222\n",
      "penalty: 0.45410246078220934\n",
      "h_val:  tensor(0.0048, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.993194023760683\n",
      "loss: 36.880195513668646\n",
      "penalty: 0.4500269077483535\n",
      "h_val:  tensor(0.0047, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.996020000551856\n",
      "loss: 36.87870888934424\n",
      "penalty: 0.44624447777489096\n",
      "h_val:  tensor(0.0047, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.998196605993616\n",
      "loss: 36.877082386959756\n",
      "penalty: 0.4431517711711026\n",
      "h_val:  tensor(0.0047, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.999172472778774\n",
      "loss: 36.87556807713753\n",
      "penalty: 0.4415262056807693\n",
      "h_val:  tensor(0.0047, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.998858025990862\n",
      "loss: 36.8745763050139\n",
      "penalty: 0.44158224432078647\n",
      "h_val:  tensor(0.0047, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.998507357584369\n",
      "loss: 36.873983653777266\n",
      "penalty: 0.4418221081031481\n",
      "h_val:  tensor(0.0047, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.998222743037076\n",
      "loss: 36.87307676586284\n",
      "penalty: 0.44180445088090603\n",
      "h_val:  tensor(0.0047, grad_fn=<SubBackward0>)\n",
      "squared loss: 4.999811612773879\n",
      "loss: 36.87100633037771\n",
      "penalty: 0.4396471398319546\n",
      "h_val:  tensor(0.0046, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.003335217758749\n",
      "loss: 36.869006014053454\n",
      "penalty: 0.435756837827636\n",
      "h_val:  tensor(0.0046, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.008406178149397\n",
      "loss: 36.86739919540481\n",
      "penalty: 0.43045981262497934\n",
      "h_val:  tensor(0.0046, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.0110693735300025\n",
      "loss: 36.86667669449122\n",
      "penalty: 0.42749753211352504\n",
      "h_val:  tensor(0.0046, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.011766140761205\n",
      "loss: 36.866152454498526\n",
      "penalty: 0.4263910683548511\n",
      "h_val:  tensor(0.0046, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.012040098195653\n",
      "loss: 36.86550953208553\n",
      "penalty: 0.4257174426985596\n",
      "h_val:  tensor(0.0046, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.0114919804972375\n",
      "loss: 36.865177991922586\n",
      "penalty: 0.4261911433603276\n",
      "h_val:  tensor(0.0046, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.0115840710357\n",
      "loss: 36.864939328171\n",
      "penalty: 0.4261134451415761\n",
      "h_val:  tensor(0.0046, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.011556001814994\n",
      "loss: 36.864594254543455\n",
      "penalty: 0.4261757574782914\n",
      "h_val:  tensor(0.0046, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.012261720790871\n",
      "loss: 36.86402099212652\n",
      "penalty: 0.4254828043340957\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.0138964878737\n",
      "loss: 36.86322254472483\n",
      "penalty: 0.42378983063487863\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.0158869374372195\n",
      "loss: 36.862540733948975\n",
      "penalty: 0.42162648238164013\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.016807125995355\n",
      "loss: 36.86219722659132\n",
      "penalty: 0.4204224190025651\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.016814250653988\n",
      "loss: 36.8619883291813\n",
      "penalty: 0.42010887935302277\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.016389744596596\n",
      "loss: 36.86175212577029\n",
      "penalty: 0.4201738475552092\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.015869390430764\n",
      "loss: 36.86154533426669\n",
      "penalty: 0.4204725720024289\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.01547589034274\n",
      "loss: 36.861353965886536\n",
      "penalty: 0.4208134621232659\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.015429732544876\n",
      "loss: 36.861240973735214\n",
      "penalty: 0.4209546022455483\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.015596423766255\n",
      "loss: 36.86111811565517\n",
      "penalty: 0.4208755020451404\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.016331022681226\n",
      "loss: 36.86086921464929\n",
      "penalty: 0.42024152368391626\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.017248045571874\n",
      "loss: 36.86059608029629\n",
      "penalty: 0.4193949469962318\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.018466229738916\n",
      "loss: 36.86033201083309\n",
      "penalty: 0.4181904051575015\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.019674331040165\n",
      "loss: 36.86006524501791\n",
      "penalty: 0.41694522836385967\n",
      "h_val:  tensor(0.0045, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.0211136772311065\n",
      "loss: 36.85969033498931\n",
      "penalty: 0.41547413752912404\n",
      "h_val:  tensor(0.0044, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.023492248887315\n",
      "loss: 36.8590157762043\n",
      "penalty: 0.41320384704135116\n",
      "h_val:  tensor(0.0044, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.027427459597982\n",
      "loss: 36.85792378980937\n",
      "penalty: 0.40979774704019256\n",
      "h_val:  tensor(0.0044, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.032538928994881\n",
      "loss: 36.85659041060446\n",
      "penalty: 0.4058298644102423\n",
      "h_val:  tensor(0.0044, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.037511358657009\n",
      "loss: 36.85532642742512\n",
      "penalty: 0.4022693986716568\n",
      "h_val:  tensor(0.0043, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.044298152460255\n",
      "loss: 36.853543687769864\n",
      "penalty: 0.3970659544035592\n",
      "h_val:  tensor(0.0042, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.061217771673179\n",
      "loss: 36.850333191846644\n",
      "penalty: 0.3836057682032422\n",
      "h_val:  tensor(0.0041, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.0758607221425\n",
      "loss: 36.84789836563529\n",
      "penalty: 0.37218370238910764\n",
      "h_val:  tensor(0.0040, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.088962827165971\n",
      "loss: 36.84621970535237\n",
      "penalty: 0.3611027894164051\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.093928060455024\n",
      "loss: 36.845261634066986\n",
      "penalty: 0.35667929791283665\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.100824288120534\n",
      "loss: 36.84451615300837\n",
      "penalty: 0.3501373720738423\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.095441786871412\n",
      "loss: 36.84415695273013\n",
      "penalty: 0.35603625570417835\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.099733843825496\n",
      "loss: 36.84389529197053\n",
      "penalty: 0.35163048838418604\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.101497508461224\n",
      "loss: 36.8436831667049\n",
      "penalty: 0.34986019319722356\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.102577115185703\n",
      "loss: 36.84337739534726\n",
      "penalty: 0.348840775784799\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.102805477193914\n",
      "loss: 36.84301810893158\n",
      "penalty: 0.3487097586736491\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.101912100348323\n",
      "loss: 36.842757500237866\n",
      "penalty: 0.3494859507926781\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1005455578405625\n",
      "loss: 36.84262325126973\n",
      "penalty: 0.35046722094401006\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.099639648461163\n",
      "loss: 36.84255684027161\n",
      "penalty: 0.3509821481707208\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.098776597875235\n",
      "loss: 36.8424655310004\n",
      "penalty: 0.3513757422922178\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.097416438752079\n",
      "loss: 36.84231858280881\n",
      "penalty: 0.35204279208309724\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.096151516404927\n",
      "loss: 36.842171983999556\n",
      "penalty: 0.3527573676204741\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.095030395289602\n",
      "loss: 36.84203790271894\n",
      "penalty: 0.35358003825062856\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.094089992976659\n",
      "loss: 36.841911455501155\n",
      "penalty: 0.35441761474232797\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.092988617226352\n",
      "loss: 36.841709884629694\n",
      "penalty: 0.35535963801870163\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.091790830918247\n",
      "loss: 36.84142777394717\n",
      "penalty: 0.3562439274314364\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.091473834064295\n",
      "loss: 36.84114490525631\n",
      "penalty: 0.3562001850939521\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.091282714747051\n",
      "loss: 36.84079901978991\n",
      "penalty: 0.35603745298192946\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.092690277487204\n",
      "loss: 36.84029685009729\n",
      "penalty: 0.3543822273132849\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.094622643440893\n",
      "loss: 36.83969180476436\n",
      "penalty: 0.35247670089362493\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.09715184662558\n",
      "loss: 36.83907575161108\n",
      "penalty: 0.350412686053854\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.098984720033512\n",
      "loss: 36.838627350895756\n",
      "penalty: 0.34931217038199736\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.099339302470047\n",
      "loss: 36.83840187480926\n",
      "penalty: 0.3494434327938145\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.099646902801007\n",
      "loss: 36.83811937340377\n",
      "penalty: 0.34943002624815267\n",
      "h_val:  tensor(0.0039, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.102403547715195\n",
      "loss: 36.837061302933094\n",
      "penalty: 0.3478754672783069\n",
      "h_val:  tensor(0.0038, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.109328220674813\n",
      "loss: 36.83546279574819\n",
      "penalty: 0.343169392378989\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.122005965598528\n",
      "loss: 36.83320850676364\n",
      "penalty: 0.33415523635251354\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1380651881805885\n",
      "loss: 36.831065712058724\n",
      "penalty: 0.3219482945644464\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.149325366474809\n",
      "loss: 36.82949163268733\n",
      "penalty: 0.3132141336442393\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.159087868440083\n",
      "loss: 36.828291459541255\n",
      "penalty: 0.30489917168147246\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.149128130035316\n",
      "loss: 36.82805624666711\n",
      "penalty: 0.3166572532845833\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.157498046672948\n",
      "loss: 36.82719340326624\n",
      "penalty: 0.3071930688600604\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.159770334349389\n",
      "loss: 36.82676761977217\n",
      "penalty: 0.3045768627167368\n",
      "h_val:  tensor(0.0034, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.164580232784228\n",
      "loss: 36.825589903644534\n",
      "penalty: 0.29998425718985944\n",
      "h_val:  tensor(0.0034, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.172848897321151\n",
      "loss: 36.82348545783957\n",
      "penalty: 0.2934557427704877\n",
      "h_val:  tensor(0.0032, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.188870157568081\n",
      "loss: 36.81974741057459\n",
      "penalty: 0.2822751775902761\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.206171620438235\n",
      "loss: 36.816306501966835\n",
      "penalty: 0.27133052369709276\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.21391271220123\n",
      "loss: 36.81471516196822\n",
      "penalty: 0.26693694108437005\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.213338441341014\n",
      "loss: 36.8143489520191\n",
      "penalty: 0.2673449533533708\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.212054205096945\n",
      "loss: 36.814222430671435\n",
      "penalty: 0.26798698532528953\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.210722918424408\n",
      "loss: 36.81401551851034\n",
      "penalty: 0.26845894830302947\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.2106011335490265\n",
      "loss: 36.81374203300103\n",
      "penalty: 0.26807706232696016\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.212448267062541\n",
      "loss: 36.81337947767549\n",
      "penalty: 0.2664673435828414\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.2154341297950895\n",
      "loss: 36.81307127380549\n",
      "penalty: 0.2645408225332726\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.217377460248948\n",
      "loss: 36.812842650402814\n",
      "penalty: 0.2637178098680977\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.217996529505849\n",
      "loss: 36.812640147307235\n",
      "penalty: 0.2637968050835074\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.218418429178972\n",
      "loss: 36.81247515391874\n",
      "penalty: 0.2636067148225486\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.217065295856952\n",
      "loss: 36.81238077946794\n",
      "penalty: 0.26454653910019876\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.217500311974127\n",
      "loss: 36.81227015036869\n",
      "penalty: 0.26363887709722583\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.2155689655683\n",
      "loss: 36.8121052337007\n",
      "penalty: 0.2647563893841991\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.213147818963088\n",
      "loss: 36.811731886611476\n",
      "penalty: 0.26580749031014783\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.210222236006218\n",
      "loss: 36.811225704614145\n",
      "penalty: 0.2673946910498701\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.208569325790753\n",
      "loss: 36.810806860618975\n",
      "penalty: 0.26870684685724294\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.208528209312751\n",
      "loss: 36.81055572690564\n",
      "penalty: 0.2693332427716519\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.208528999571036\n",
      "loss: 36.81018581960373\n",
      "penalty: 0.27017114331594666\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.212617629145136\n",
      "loss: 36.809037066753795\n",
      "penalty: 0.26899030209314895\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.217389096083101\n",
      "loss: 36.807353461059705\n",
      "penalty: 0.2682484191968293\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.231134438117898\n",
      "loss: 36.80520475507847\n",
      "penalty: 0.26026986662318297\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.238178243421096\n",
      "loss: 36.80382362311413\n",
      "penalty: 0.2563650435461296\n",
      "h_val:  tensor(0.0029, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.243684270000947\n",
      "loss: 36.80321767074172\n",
      "penalty: 0.2514568821722419\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.240903785764817\n",
      "loss: 36.802915932009434\n",
      "penalty: 0.25347303422699546\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.241420969362846\n",
      "loss: 36.802619873766744\n",
      "penalty: 0.2523604095452803\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.239614802194089\n",
      "loss: 36.802311072369235\n",
      "penalty: 0.2538224530282206\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.2386812296418155\n",
      "loss: 36.80200816107597\n",
      "penalty: 0.25508647297575665\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.238536831660632\n",
      "loss: 36.80176803530529\n",
      "penalty: 0.2557882607005816\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.238475425300005\n",
      "loss: 36.801491789108134\n",
      "penalty: 0.25619593893346976\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.238065998537779\n",
      "loss: 36.80120307409816\n",
      "penalty: 0.25623174009576416\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.2368369287836805\n",
      "loss: 36.80096653464515\n",
      "penalty: 0.25618107761148556\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.235438177609873\n",
      "loss: 36.80078645211229\n",
      "penalty: 0.256259585947854\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.233109879929766\n",
      "loss: 36.800547664883055\n",
      "penalty: 0.25694036287138655\n",
      "h_val:  tensor(0.0030, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.228983796906335\n",
      "loss: 36.800205131132785\n",
      "penalty: 0.2589443706445894\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.223690768196329\n",
      "loss: 36.799807827129754\n",
      "penalty: 0.2623231230113882\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.219223930593655\n",
      "loss: 36.79945863219773\n",
      "penalty: 0.2659416433878307\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.217742743248062\n",
      "loss: 36.799240265767395\n",
      "penalty: 0.2677435752161899\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.218004980502826\n",
      "loss: 36.798983063250866\n",
      "penalty: 0.2679267287878661\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.21552310153736\n",
      "loss: 36.798398098390685\n",
      "penalty: 0.2710610276232856\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.218488737152905\n",
      "loss: 36.79773107853927\n",
      "penalty: 0.2687108733838154\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.216465939184146\n",
      "loss: 36.797015026107715\n",
      "penalty: 0.2705920115100586\n",
      "h_val:  tensor(0.0031, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.2142997258373915\n",
      "loss: 36.79592983143026\n",
      "penalty: 0.27218151585830863\n",
      "h_val:  tensor(0.0032, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.211731430833083\n",
      "loss: 36.7946565917942\n",
      "penalty: 0.27444827184182685\n",
      "h_val:  tensor(0.0032, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.20901715967882\n",
      "loss: 36.792752345987665\n",
      "penalty: 0.2778794350773011\n",
      "h_val:  tensor(0.0032, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.207624503457058\n",
      "loss: 36.7909128730268\n",
      "penalty: 0.28152696319893417\n",
      "h_val:  tensor(0.0033, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.20778485226183\n",
      "loss: 36.78983065489654\n",
      "penalty: 0.28368427660683027\n",
      "h_val:  tensor(0.0033, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.208089058933974\n",
      "loss: 36.78923334433633\n",
      "penalty: 0.2844233678704756\n",
      "h_val:  tensor(0.0033, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.207748816690935\n",
      "loss: 36.7886100622574\n",
      "penalty: 0.2851622540546136\n",
      "h_val:  tensor(0.0033, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.206691418393737\n",
      "loss: 36.78778480072617\n",
      "penalty: 0.2860766450486443\n",
      "h_val:  tensor(0.0033, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.2035473925168345\n",
      "loss: 36.78661982101457\n",
      "penalty: 0.2884197068645565\n",
      "h_val:  tensor(0.0033, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.199496088950192\n",
      "loss: 36.78549083185647\n",
      "penalty: 0.2912248583948893\n",
      "h_val:  tensor(0.0034, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.196349880435346\n",
      "loss: 36.784807409412934\n",
      "penalty: 0.29329053584037634\n",
      "h_val:  tensor(0.0034, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.193096902193422\n",
      "loss: 36.78408730161847\n",
      "penalty: 0.29521416902178876\n",
      "h_val:  tensor(0.0034, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.183003278505469\n",
      "loss: 36.782321320590796\n",
      "penalty: 0.3016838747478466\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.174671716200844\n",
      "loss: 36.780976867085286\n",
      "penalty: 0.30733006702947707\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.16738995708732\n",
      "loss: 36.7800641773825\n",
      "penalty: 0.3130830704677786\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.16383362745082\n",
      "loss: 36.77939375370128\n",
      "penalty: 0.31572967446106703\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.159471694422157\n",
      "loss: 36.77877253921061\n",
      "penalty: 0.319197136373263\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.157697140978644\n",
      "loss: 36.778312372033284\n",
      "penalty: 0.3201355838142428\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1560950062723725\n",
      "loss: 36.77808989347235\n",
      "penalty: 0.32117106722244937\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.155587826832774\n",
      "loss: 36.777970131855355\n",
      "penalty: 0.32132766029971366\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.154917343139764\n",
      "loss: 36.7778420946555\n",
      "penalty: 0.32168624747276076\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.153854449891562\n",
      "loss: 36.77764825039658\n",
      "penalty: 0.32241173237354315\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.152750590818547\n",
      "loss: 36.77742541180339\n",
      "penalty: 0.3233323603334525\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.151996365238086\n",
      "loss: 36.777242742662814\n",
      "penalty: 0.3241413299746692\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.151859268194762\n",
      "loss: 36.777108508544096\n",
      "penalty: 0.3244229676161638\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.152094681786695\n",
      "loss: 36.77691115349321\n",
      "penalty: 0.32434823815543323\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.152824712379637\n",
      "loss: 36.77661012437444\n",
      "penalty: 0.32383871026579564\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.153787778907439\n",
      "loss: 36.77638379780265\n",
      "penalty: 0.3229754865913271\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.154461218333195\n",
      "loss: 36.776239373102285\n",
      "penalty: 0.3222633975770234\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.154862828298047\n",
      "loss: 36.776129388533526\n",
      "penalty: 0.3217963688359957\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.155308496137941\n",
      "loss: 36.77599309373121\n",
      "penalty: 0.3213320653307952\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.155662321287034\n",
      "loss: 36.775882234138884\n",
      "penalty: 0.3210749845964297\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1559319886632515\n",
      "loss: 36.77580818773167\n",
      "penalty: 0.3209826475009223\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.156102664668231\n",
      "loss: 36.77576794483278\n",
      "penalty: 0.32095228632571343\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.156275638190959\n",
      "loss: 36.77572386879934\n",
      "penalty: 0.3208846433247915\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.156668129817028\n",
      "loss: 36.77563142348181\n",
      "penalty: 0.3206457371197084\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.15730709020314\n",
      "loss: 36.775502930886375\n",
      "penalty: 0.3201559498346595\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1580710714741125\n",
      "loss: 36.7753687518924\n",
      "penalty: 0.31946797574798574\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.158588998377964\n",
      "loss: 36.7752763359572\n",
      "penalty: 0.3189104053238044\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.158782924095489\n",
      "loss: 36.775204250020195\n",
      "penalty: 0.31862387991008284\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.158936732645198\n",
      "loss: 36.77507719891849\n",
      "penalty: 0.3183499218933687\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.159091985329385\n",
      "loss: 36.774902262641255\n",
      "penalty: 0.3181290154508172\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.159216486451611\n",
      "loss: 36.77477447447757\n",
      "penalty: 0.3180743472408445\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.159327612721206\n",
      "loss: 36.77469383234674\n",
      "penalty: 0.31809272160963703\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.159480709242895\n",
      "loss: 36.77462461673899\n",
      "penalty: 0.3180416187822609\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.159924075500329\n",
      "loss: 36.77449823529625\n",
      "penalty: 0.3177514661305188\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.160684954527101\n",
      "loss: 36.77435134090469\n",
      "penalty: 0.31715068848500505\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.161596993208876\n",
      "loss: 36.77421976382477\n",
      "penalty: 0.31633961427444396\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.162251877371756\n",
      "loss: 36.77413611238854\n",
      "penalty: 0.3156868139879507\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.16262507094457\n",
      "loss: 36.77406702613482\n",
      "penalty: 0.3152791280812234\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.163162257509273\n",
      "loss: 36.773934071970615\n",
      "penalty: 0.31473579446150396\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.163932316989109\n",
      "loss: 36.77374329021776\n",
      "penalty: 0.31408629066204125\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.164627317332687\n",
      "loss: 36.773579819986296\n",
      "penalty: 0.31363601575466804\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.165078745361089\n",
      "loss: 36.77347151656156\n",
      "penalty: 0.3134340855115444\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.165382282612013\n",
      "loss: 36.77338530108143\n",
      "penalty: 0.313296889147138\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.166022994164036\n",
      "loss: 36.773232041355925\n",
      "penalty: 0.31287237694012365\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.167192990565443\n",
      "loss: 36.773028503113515\n",
      "penalty: 0.31197862548614025\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.168461649435203\n",
      "loss: 36.77286157115187\n",
      "penalty: 0.3109046538509851\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1693340818636475\n",
      "loss: 36.77275482474072\n",
      "penalty: 0.3100846980342986\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169709887110022\n",
      "loss: 36.772666244968626\n",
      "penalty: 0.30967382904712715\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170008323766329\n",
      "loss: 36.77251089260163\n",
      "penalty: 0.3093136175137371\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170118211344081\n",
      "loss: 36.772337161711064\n",
      "penalty: 0.30919859992545917\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170041990090095\n",
      "loss: 36.77219258128626\n",
      "penalty: 0.30935019281517234\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169893684068399\n",
      "loss: 36.7721047604507\n",
      "penalty: 0.30958821146945215\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169803173392823\n",
      "loss: 36.772034801227015\n",
      "penalty: 0.30973152056612396\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169736405233189\n",
      "loss: 36.771893781091606\n",
      "penalty: 0.30982605895495696\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169788593303881\n",
      "loss: 36.77166075755317\n",
      "penalty: 0.309766477661005\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170021820734754\n",
      "loss: 36.77144262476458\n",
      "penalty: 0.30946080506567025\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170320753289574\n",
      "loss: 36.771283093047764\n",
      "penalty: 0.3090376244361619\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170415366906387\n",
      "loss: 36.77116917568565\n",
      "penalty: 0.30880542721481385\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170252661853351\n",
      "loss: 36.77100759441508\n",
      "penalty: 0.3087787080529272\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1697716346081375\n",
      "loss: 36.77081656015253\n",
      "penalty: 0.3090810502451773\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169186471537371\n",
      "loss: 36.770675249048885\n",
      "penalty: 0.30959887816266723\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.168753530599698\n",
      "loss: 36.77059234590082\n",
      "penalty: 0.3100416140734942\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.168554767239008\n",
      "loss: 36.770530141802546\n",
      "penalty: 0.31025558704151435\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.168412978623242\n",
      "loss: 36.77040809448734\n",
      "penalty: 0.31039335821384273\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.168461452116918\n",
      "loss: 36.77022701453916\n",
      "penalty: 0.3103245610864837\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.168781479297811\n",
      "loss: 36.77006098897318\n",
      "penalty: 0.30995434251500786\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.16920914941001\n",
      "loss: 36.7699408872481\n",
      "penalty: 0.3094485037622053\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169438100689469\n",
      "loss: 36.7698618199277\n",
      "penalty: 0.3091401224301144\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169540564708725\n",
      "loss: 36.76972711448477\n",
      "penalty: 0.308933875871643\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.16948009327953\n",
      "loss: 36.769495503601775\n",
      "penalty: 0.3088919139487304\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169245160279045\n",
      "loss: 36.769306407421325\n",
      "penalty: 0.30912994710569114\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1689983570077995\n",
      "loss: 36.769183256282574\n",
      "penalty: 0.3094405931188188\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.168881799037756\n",
      "loss: 36.769107935052105\n",
      "penalty: 0.3096052017061489\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1689167754467595\n",
      "loss: 36.76900178543532\n",
      "penalty: 0.3095993826325203\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169260730037946\n",
      "loss: 36.7688381884106\n",
      "penalty: 0.309290648521905\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169845558515838\n",
      "loss: 36.768696962154166\n",
      "penalty: 0.3087195920112854\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170409657687994\n",
      "loss: 36.768596872094506\n",
      "penalty: 0.30813347507095107\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170638416842182\n",
      "loss: 36.76852326822948\n",
      "penalty: 0.3078522843732146\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170680885439771\n",
      "loss: 36.76838758359447\n",
      "penalty: 0.30771233809728266\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170410881727197\n",
      "loss: 36.768204300267826\n",
      "penalty: 0.30788660791858286\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169946778237295\n",
      "loss: 36.76806198330587\n",
      "penalty: 0.3083223723829608\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169525951662169\n",
      "loss: 36.76797252150338\n",
      "penalty: 0.30875419432839873\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169337184471426\n",
      "loss: 36.76792064079729\n",
      "penalty: 0.30895607541237696\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169207039706261\n",
      "loss: 36.76782053751253\n",
      "penalty: 0.30907279519112785\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169167714753767\n",
      "loss: 36.767583929720104\n",
      "penalty: 0.30907148320058725\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169393642027491\n",
      "loss: 36.76734372624787\n",
      "penalty: 0.30879418660123514\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1698188092712725\n",
      "loss: 36.76712400567333\n",
      "penalty: 0.3082980646200127\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170063324089096\n",
      "loss: 36.766960232199345\n",
      "penalty: 0.30796116263295475\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.170011508323126\n",
      "loss: 36.76674787289003\n",
      "penalty: 0.30786560996021367\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.169531331271803\n",
      "loss: 36.766472845147874\n",
      "penalty: 0.3081727737816755\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.168750762024457\n",
      "loss: 36.76623776381319\n",
      "penalty: 0.30884894779729366\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.168040514760243\n",
      "loss: 36.76608425629232\n",
      "penalty: 0.3095241706116644\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.167661513019475\n",
      "loss: 36.76600142583214\n",
      "penalty: 0.3098995759504398\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.167335307172802\n",
      "loss: 36.76585309301998\n",
      "penalty: 0.3101788510912456\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.166669515155226\n",
      "loss: 36.76540178578344\n",
      "penalty: 0.31072707206483713\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.166376862402549\n",
      "loss: 36.76493589737987\n",
      "penalty: 0.3109171457722235\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.166558677057215\n",
      "loss: 36.764427576569894\n",
      "penalty: 0.3106362755672304\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.166940652463891\n",
      "loss: 36.764109866833586\n",
      "penalty: 0.3101580711144305\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.167047337944535\n",
      "loss: 36.76375322604743\n",
      "penalty: 0.30986758154317773\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.166612360035783\n",
      "loss: 36.762950162433995\n",
      "penalty: 0.30991657674654877\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.165342053876262\n",
      "loss: 36.76183594292561\n",
      "penalty: 0.3108060021053153\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.163836236270454\n",
      "loss: 36.76091310074831\n",
      "penalty: 0.31213465581174443\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.162634831684893\n",
      "loss: 36.76037317219477\n",
      "penalty: 0.31329324526472363\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1619273907764756\n",
      "loss: 36.75999333341352\n",
      "penalty: 0.31387652693500273\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.161211130368777\n",
      "loss: 36.75932607848684\n",
      "penalty: 0.3143523898359029\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.160900217451122\n",
      "loss: 36.758524008596495\n",
      "penalty: 0.31444273256089966\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.161246059077723\n",
      "loss: 36.75775191223269\n",
      "penalty: 0.31396480259812276\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.161820826347929\n",
      "loss: 36.75723655832505\n",
      "penalty: 0.31333065287214046\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.16184521313681\n",
      "loss: 36.75668121374919\n",
      "penalty: 0.3130872487402742\n",
      "h_val:  tensor(0.0035, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.160921174851165\n",
      "loss: 36.755312054090346\n",
      "penalty: 0.3134188026352913\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.158732209619031\n",
      "loss: 36.75361326933854\n",
      "penalty: 0.3149816964058699\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.156027601525226\n",
      "loss: 36.752076508729814\n",
      "penalty: 0.31716186657463824\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.154009540826271\n",
      "loss: 36.75111852050383\n",
      "penalty: 0.3188110156713738\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.152764545131918\n",
      "loss: 36.75041782519594\n",
      "penalty: 0.3196529432165768\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1510931957208275\n",
      "loss: 36.74898232196189\n",
      "penalty: 0.32053555682629054\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.149208427655368\n",
      "loss: 36.74670718052982\n",
      "penalty: 0.3214583055359696\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.148621989053539\n",
      "loss: 36.7449415937026\n",
      "penalty: 0.3215138519890971\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.148666901741211\n",
      "loss: 36.74380844227592\n",
      "penalty: 0.32122585004011256\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1480549903232715\n",
      "loss: 36.74290983912374\n",
      "penalty: 0.321470372298847\n",
      "h_val:  tensor(0.0036, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.146107520988664\n",
      "loss: 36.741487538085835\n",
      "penalty: 0.32279395616510453\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.143309463056826\n",
      "loss: 36.740187096967524\n",
      "penalty: 0.3251108512174834\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1404126413617925\n",
      "loss: 36.73916897519833\n",
      "penalty: 0.32767836368448977\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.138781773501084\n",
      "loss: 36.73861988536015\n",
      "penalty: 0.3290818276749587\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.137717219809397\n",
      "loss: 36.73807829545936\n",
      "penalty: 0.3298371539584129\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.136592541536008\n",
      "loss: 36.73720034466708\n",
      "penalty: 0.33051422924917595\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.136062683169917\n",
      "loss: 36.736451194468465\n",
      "penalty: 0.3307635573818668\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.1360699571854935\n",
      "loss: 36.735894431313284\n",
      "penalty: 0.330596011823595\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.136084852668096\n",
      "loss: 36.73549832182085\n",
      "penalty: 0.3304689093908055\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.135602386367428\n",
      "loss: 36.734975091440496\n",
      "penalty: 0.3307400735199032\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.134239576386286\n",
      "loss: 36.73419886161509\n",
      "penalty: 0.33175056878439363\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.13247010824097\n",
      "loss: 36.733567191110474\n",
      "penalty: 0.3332185179862158\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.131156092963267\n",
      "loss: 36.73323466165976\n",
      "penalty: 0.33431340321907294\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.130589181976707\n",
      "loss: 36.733073150870084\n",
      "penalty: 0.3347112951089224\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.130320892053389\n",
      "loss: 36.732906294082284\n",
      "penalty: 0.3347928154896734\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.130336326920996\n",
      "loss: 36.732720542081616\n",
      "penalty: 0.3345958511211765\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.130633308229805\n",
      "loss: 36.73258861837684\n",
      "penalty: 0.33421394665279347\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.130950802649391\n",
      "loss: 36.73251769827095\n",
      "penalty: 0.3338746907345192\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.131073628809803\n",
      "loss: 36.73247900337042\n",
      "penalty: 0.3337434057442247\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.131066906820398\n",
      "loss: 36.73241448180318\n",
      "penalty: 0.33370666876453126\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.130866257298701\n",
      "loss: 36.73231559075145\n",
      "penalty: 0.33381830239405547\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.130612467987101\n",
      "loss: 36.73225424104211\n",
      "penalty: 0.3339964634659325\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.130418833063551\n",
      "loss: 36.73221488021974\n",
      "penalty: 0.3341257154388866\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.130354578164734\n",
      "loss: 36.73218725239047\n",
      "penalty: 0.33414734004081026\n",
      "h_new:  0.0037383266185164743\n",
      "rho:  100000.0\n",
      "h_val:  tensor(0.0037, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.130354578164734\n",
      "loss: 37.36106611819236\n",
      "penalty: 0.963026205842707\n",
      "h_val:  tensor(918.3304, grad_fn=<SubBackward0>)\n",
      "squared loss: 38.26381023835195\n",
      "loss: 42166601873.45812\n",
      "penalty: 42166601803.902306\n",
      "h_val:  tensor(5.8205, grad_fn=<SubBackward0>)\n",
      "squared loss: 37.53350074497292\n",
      "loss: 1694419.6269046485\n",
      "penalty: 1694350.81936959\n",
      "h_val:  tensor(0.1938, grad_fn=<SubBackward0>)\n",
      "squared loss: 31.615704535909536\n",
      "loss: 1954.3763416887566\n",
      "penalty: 1891.4915326233174\n",
      "h_val:  tensor(0.0017, grad_fn=<SubBackward0>)\n",
      "squared loss: 10.89452722409881\n",
      "loss: 42.427510031969824\n",
      "penalty: 0.2650102013757083\n",
      "h_val:  tensor(0.0019, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.529977940714781\n",
      "loss: 37.100758492867044\n",
      "penalty: 0.3030445782446468\n",
      "h_val:  tensor(0.0021, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.43492443521174\n",
      "loss: 37.08265996197461\n",
      "penalty: 0.3800091441170389\n",
      "h_val:  tensor(0.0022, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.41558487104695\n",
      "loss: 37.08141478988902\n",
      "penalty: 0.3981063495827828\n",
      "h_val:  tensor(0.0022, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.413778940563539\n",
      "loss: 37.08097113643491\n",
      "penalty: 0.39947001695450124\n",
      "h_val:  tensor(0.0022, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.418793907351178\n",
      "loss: 37.08074617295935\n",
      "penalty: 0.39423283156535793\n",
      "h_val:  tensor(0.0022, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.419604056389922\n",
      "loss: 37.08072463741941\n",
      "penalty: 0.39340355174597286\n",
      "h_new:  0.0021857918884227168\n",
      "rho:  1000000.0\n",
      "h_val:  tensor(0.0022, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.419604056389922\n",
      "loss: 39.23068341819195\n",
      "penalty: 2.5433623325185186\n",
      "h_val:  tensor(904.5673, grad_fn=<SubBackward0>)\n",
      "squared loss: 38.23208485875191\n",
      "loss: 409121053593.2845\n",
      "penalty: 409121053523.75964\n",
      "h_val:  tensor(5.8543, grad_fn=<SubBackward0>)\n",
      "squared loss: 37.37366981206985\n",
      "loss: 17137058.944072444\n",
      "penalty: 17136990.296087097\n",
      "h_val:  tensor(0.2030, grad_fn=<SubBackward0>)\n",
      "squared loss: 31.66311115809619\n",
      "loss: 20691.35761121554\n",
      "penalty: 20628.42530958059\n",
      "h_val:  tensor(0.0027, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.92403940245105\n",
      "loss: 47.06671424884997\n",
      "penalty: 3.874666961536469\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.987741618128573\n",
      "loss: 38.27175262925672\n",
      "penalty: 0.016189224833014375\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.519995358709628\n",
      "loss: 37.88400054282061\n",
      "penalty: 0.09620788393983612\n",
      "h_val:  tensor(0.0012, grad_fn=<SubBackward0>)\n",
      "squared loss: 5.840179984230502\n",
      "loss: 37.86377146994227\n",
      "penalty: 0.7558385036671911\n",
      "h_val:  tensor(0.0007, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.193372369400903\n",
      "loss: 37.73242355407633\n",
      "penalty: 0.2712735572708346\n",
      "h_val:  tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.097511658492715\n",
      "loss: 37.72585385786501\n",
      "penalty: 0.3605712040762918\n",
      "h_val:  tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.119645949475374\n",
      "loss: 37.72519319075711\n",
      "penalty: 0.3377749703908446\n",
      "h_val:  tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.119308087193551\n",
      "loss: 37.72516031530539\n",
      "penalty: 0.338080258742515\n",
      "h_new:  0.0007546303723815484\n",
      "layer: 0 shape: torch.Size([20, 2])\n",
      "layer: 1 shape: torch.Size([20])\n",
      "layer: 2 shape: torch.Size([20, 2])\n",
      "layer: 3 shape: torch.Size([20])\n",
      "layer: 4 shape: torch.Size([2, 10, 1])\n",
      "layer: 5 shape: torch.Size([2, 1])\n",
      "rho:  1000000.0\n",
      "h_val:  tensor(0.0008, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.119308087193551\n",
      "loss: 38.294627314226105\n",
      "penalty: 0.9075472576632294\n",
      "h_val:  tensor(946.5923, grad_fn=<SubBackward0>)\n",
      "squared loss: 38.20401370819121\n",
      "loss: 448019277082.3211\n",
      "penalty: 448019277012.825\n",
      "h_val:  tensor(6.0692, grad_fn=<SubBackward0>)\n",
      "squared loss: 37.460983377102224\n",
      "loss: 18422488.13186545\n",
      "penalty: 18422419.396766506\n",
      "h_val:  tensor(0.2222, grad_fn=<SubBackward0>)\n",
      "squared loss: 32.156582525421975\n",
      "loss: 24935.091376040353\n",
      "penalty: 24871.665612006374\n",
      "h_val:  tensor(0.0043, grad_fn=<SubBackward0>)\n",
      "squared loss: 13.20384766103424\n",
      "loss: 57.275598971841696\n",
      "penalty: 12.803718213752543\n",
      "h_val:  tensor(9.6486e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 7.060777860878166\n",
      "loss: 38.41288590447419\n",
      "penalty: 0.0842865901974487\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.453870949571664\n",
      "loss: 38.16088851615181\n",
      "penalty: 0.4392263016707068\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.451477190700598\n",
      "loss: 38.16061778791001\n",
      "penalty: 0.4413496942179187\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.450430449401281\n",
      "loss: 38.16041040450882\n",
      "penalty: 0.4421900160285105\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.450763815718013\n",
      "loss: 38.16034684285879\n",
      "penalty: 0.4417939131076215\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.453443063276503\n",
      "loss: 38.15966338330126\n",
      "penalty: 0.43844265059003285\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.456027997403356\n",
      "loss: 38.158407881074176\n",
      "penalty: 0.43462688951494416\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.459237801253639\n",
      "loss: 38.1547417725057\n",
      "penalty: 0.42782970507863904\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.46040486114936\n",
      "loss: 38.146373147421095\n",
      "penalty: 0.4184857417190662\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.4563801942703565\n",
      "loss: 38.128099974931125\n",
      "penalty: 0.4046823021664927\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.447562781195151\n",
      "loss: 38.09804337502014\n",
      "penalty: 0.384232707416033\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.435958341436857\n",
      "loss: 38.066502672327765\n",
      "penalty: 0.3651914872288359\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.407060001724475\n",
      "loss: 38.04889471280212\n",
      "penalty: 0.3769439048620456\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.395522834151056\n",
      "loss: 38.04246258474451\n",
      "penalty: 0.3820878041175342\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.369648263953532\n",
      "loss: 38.036723629873634\n",
      "penalty: 0.40221317767683157\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.341567158327311\n",
      "loss: 38.02215015032298\n",
      "penalty: 0.4157982548239149\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.278788455984486\n",
      "loss: 37.988844238509905\n",
      "penalty: 0.4457502111433758\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.186552660174916\n",
      "loss: 37.90867382045527\n",
      "penalty: 0.4595045196141945\n",
      "h_val:  tensor(0.0004, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.105802457766073\n",
      "loss: 37.77949141809149\n",
      "penalty: 0.41471107547922914\n",
      "h_val:  tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.113958672409697\n",
      "loss: 37.66300422200279\n",
      "penalty: 0.2945207818618043\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.15099745592159\n",
      "loss: 37.61453697246971\n",
      "penalty: 0.211135466227577\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.1646016851191865\n",
      "loss: 37.60076160023066\n",
      "penalty: 0.18404437515318203\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.167932158271294\n",
      "loss: 37.59678428771521\n",
      "penalty: 0.17666895434952634\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.1672800812097694\n",
      "loss: 37.590792752442276\n",
      "penalty: 0.17126078595325098\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.159828593291828\n",
      "loss: 37.57597716560479\n",
      "penalty: 0.16390755992254416\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.137240327085156\n",
      "loss: 37.54637921351482\n",
      "penalty: 0.15727574728458285\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.109286831427826\n",
      "loss: 37.50041270725919\n",
      "penalty: 0.14038111115680676\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.089401628042095\n",
      "loss: 37.459446603141586\n",
      "penalty: 0.1209888393627486\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.084584050057987\n",
      "loss: 37.44271297901634\n",
      "penalty: 0.10993090777646068\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.069357438235993\n",
      "loss: 37.43997116756216\n",
      "penalty: 0.1225658908161433\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.071906846565233\n",
      "loss: 37.43957024570652\n",
      "penalty: 0.11951693829981622\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.070474120179799\n",
      "loss: 37.439277463821114\n",
      "penalty: 0.12059453447285805\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.068444247032152\n",
      "loss: 37.43876566243913\n",
      "penalty: 0.1220281987211679\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.0684162974653075\n",
      "loss: 37.4386202658015\n",
      "penalty: 0.12193027373322676\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.068969782746694\n",
      "loss: 37.43847093111834\n",
      "penalty: 0.12128226100278536\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.069811240234636\n",
      "loss: 37.438241976505964\n",
      "penalty: 0.12029279487170577\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.071387960303423\n",
      "loss: 37.43762283703732\n",
      "penalty: 0.11827227967282407\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.073402983518734\n",
      "loss: 37.43629112333421\n",
      "penalty: 0.11521325324567674\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.074983762769878\n",
      "loss: 37.433877741493475\n",
      "penalty: 0.11160853962330455\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.074406619264704\n",
      "loss: 37.43131296884602\n",
      "penalty: 0.10985997675475637\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.071616524229993\n",
      "loss: 37.43010554064967\n",
      "penalty: 0.11137783378513223\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.069749843044982\n",
      "loss: 37.42989964314199\n",
      "penalty: 0.11290311590447467\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.069134078406323\n",
      "loss: 37.42987866170988\n",
      "penalty: 0.11344868012082404\n",
      "h_new:  0.0001275964245373018\n",
      "layer: 0 shape: torch.Size([20, 2])\n",
      "layer: 1 shape: torch.Size([20])\n",
      "layer: 2 shape: torch.Size([20, 2])\n",
      "layer: 3 shape: torch.Size([20])\n",
      "layer: 4 shape: torch.Size([2, 10, 1])\n",
      "layer: 5 shape: torch.Size([2, 1])\n",
      "rho:  1000000.0\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.069134078406323\n",
      "loss: 37.44615950926458\n",
      "penalty: 0.1297295276755274\n",
      "h_val:  tensor(1087.2519, grad_fn=<SubBackward0>)\n",
      "squared loss: 38.39239270829318\n",
      "loss: 591059431810.031\n",
      "penalty: 591059431740.3788\n",
      "h_val:  tensor(6.5217, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.04122225290599\n",
      "loss: 21272555.44637856\n",
      "penalty: 21272488.155111954\n",
      "h_val:  tensor(0.2494, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.65674657989819\n",
      "loss: 31407.88574286706\n",
      "penalty: 31345.981139511496\n",
      "h_val:  tensor(0.0063, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.15280708872307\n",
      "loss: 67.99179463637857\n",
      "penalty: 25.591595457702255\n",
      "h_val:  tensor(2.0333e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.384833990868994\n",
      "loss: 37.634081935951635\n",
      "penalty: 0.0019396734216022824\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.0870986860162795\n",
      "loss: 37.44502201546444\n",
      "penalty: 0.11062655572014411\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.08663489709491\n",
      "loss: 37.44500888070625\n",
      "penalty: 0.1110778553081305\n",
      "h_new:  0.00011019447025883977\n",
      "rho:  10000000.0\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.08663489709491\n",
      "loss: 37.49965157644657\n",
      "penalty: 0.16572055104844896\n",
      "h_val:  tensor(986.3986, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.422623884031154\n",
      "loss: 4864912107101.37\n",
      "penalty: 4864912107033.677\n",
      "h_val:  tensor(6.2663, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.69194582666869\n",
      "loss: 196339188.31071442\n",
      "penalty: 196339121.36561632\n",
      "h_val:  tensor(0.2401, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.290610422348664\n",
      "loss: 288421.5857165952\n",
      "penalty: 288360.0465181786\n",
      "h_val:  tensor(0.0062, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.14615992317585\n",
      "loss: 237.45716080071574\n",
      "penalty: 195.06347694873332\n",
      "h_val:  tensor(4.9029e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.6204557046433665\n",
      "loss: 37.926536846784295\n",
      "penalty: 0.05874044693325055\n",
      "h_val:  tensor(5.0228e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.16853705252064\n",
      "loss: 37.47631962642019\n",
      "penalty: 0.060477707724973774\n",
      "h_val:  tensor(6.0095e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.151602947596365\n",
      "loss: 37.4742287195476\n",
      "penalty: 0.07532291492354476\n",
      "h_val:  tensor(6.2489e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.147765338257435\n",
      "loss: 37.47413798698882\n",
      "penalty: 0.0790706191577934\n",
      "h_val:  tensor(6.2390e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.14791449036528\n",
      "loss: 37.47413197862095\n",
      "penalty: 0.07891581803988076\n",
      "h_new:  6.239039213840059e-05\n",
      "rho:  100000000.0\n",
      "h_val:  tensor(6.2390e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.14791449036528\n",
      "loss: 37.649297225024206\n",
      "penalty: 0.25408106444313366\n",
      "h_val:  tensor(942.4477, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.37845435620274\n",
      "loss: 44410384045559.125\n",
      "penalty: 44410384045491.48\n",
      "h_val:  tensor(6.1583, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.53117708879047\n",
      "loss: 1896225813.7810674\n",
      "penalty: 1896225746.9961007\n",
      "h_val:  tensor(0.2374, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.040315668140998\n",
      "loss: 2818739.587327742\n",
      "penalty: 2818678.298272843\n",
      "h_val:  tensor(0.0063, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.250493038533502\n",
      "loss: 2031.0939994801083\n",
      "penalty: 1988.5959528515862\n",
      "h_val:  tensor(8.2362e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.707012203004707\n",
      "loss: 38.37201916430928\n",
      "penalty: 0.4176564030841523\n",
      "h_val:  tensor(3.2838e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.317229154201994\n",
      "loss: 37.568216756062945\n",
      "penalty: 0.003668396605829666\n",
      "h_val:  tensor(1.0201e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.27559991994037\n",
      "loss: 37.53783927464621\n",
      "penalty: 0.0149242461304371\n",
      "h_val:  tensor(3.2471e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.20495036861499\n",
      "loss: 37.53591923798819\n",
      "penalty: 0.08366149173087722\n",
      "h_val:  tensor(1.8584e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.243327233878784\n",
      "loss: 37.5256175399849\n",
      "penalty: 0.03497864711009928\n",
      "h_val:  tensor(2.1821e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.233178227235551\n",
      "loss: 37.52508927218592\n",
      "penalty: 0.04460068290789097\n",
      "h_val:  tensor(2.1020e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.235601448531394\n",
      "loss: 37.52503515269026\n",
      "penalty: 0.04212317143304099\n",
      "h_val:  tensor(2.1050e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.235510202525969\n",
      "loss: 37.52503400601112\n",
      "penalty: 0.042213412336738226\n",
      "h_new:  2.104978243133715e-05\n",
      "layer: 0 shape: torch.Size([20, 2])\n",
      "layer: 1 shape: torch.Size([20])\n",
      "layer: 2 shape: torch.Size([20, 2])\n",
      "layer: 3 shape: torch.Size([20])\n",
      "layer: 4 shape: torch.Size([2, 10, 1])\n",
      "layer: 5 shape: torch.Size([2, 1])\n",
      "rho:  100000000.0\n",
      "h_val:  tensor(2.1050e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.235510202525969\n",
      "loss: 37.56934334005178\n",
      "penalty: 0.08652274637740123\n",
      "h_val:  tensor(999.8368, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.41343977221563\n",
      "loss: 49983680204028.98\n",
      "penalty: 49983680203961.29\n",
      "h_val:  tensor(6.3337, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.71678250413401\n",
      "loss: 2005793039.3743808\n",
      "penalty: 2005792972.404439\n",
      "h_val:  tensor(0.2463, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.45599556230806\n",
      "loss: 3034823.5850168224\n",
      "penalty: 3034761.8804216734\n",
      "h_val:  tensor(0.0068, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.522131454016103\n",
      "loss: 2402.128343643241\n",
      "penalty: 2359.358678801979\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.797703061106973\n",
      "loss: 39.25093838689469\n",
      "penalty: 1.205884492840761\n",
      "h_val:  tensor(2.6396e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.323381045335473\n",
      "loss: 37.579118985741836\n",
      "penalty: 0.008419940825197739\n",
      "h_val:  tensor(1.1793e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.2685663981233075\n",
      "loss: 37.55889672470875\n",
      "penalty: 0.043016985759225815\n",
      "h_val:  tensor(1.1834e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.268366803253534\n",
      "loss: 37.5588700568653\n",
      "penalty: 0.04319006188628409\n",
      "h_new:  1.1834170651869869e-05\n",
      "rho:  1000000000.0\n",
      "h_val:  tensor(1.1834e-05, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.268366803253534\n",
      "loss: 37.62189147462321\n",
      "penalty: 0.10621147964419424\n",
      "h_val:  tensor(947.9738, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.3686402503097\n",
      "loss: 449327163118531.9\n",
      "penalty: 449327163118464.25\n",
      "h_val:  tensor(6.1969, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.47507036951692\n",
      "loss: 19200685609.708836\n",
      "penalty: 19200685542.980057\n",
      "h_val:  tensor(0.2417, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.055775375118056\n",
      "loss: 29202509.916301187\n",
      "penalty: 29202448.611797784\n",
      "h_val:  tensor(0.0068, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.520775701778328\n",
      "loss: 23172.29437069538\n",
      "penalty: 23129.52603767958\n",
      "h_val:  tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.829852019939745\n",
      "loss: 48.811732905723844\n",
      "penalty: 10.734523975432069\n",
      "h_val:  tensor(6.2769e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.382363956171384\n",
      "loss: 37.629881502414825\n",
      "penalty: 0.00019391146810315477\n",
      "h_val:  tensor(3.9716e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.311599903533765\n",
      "loss: 37.57894896405608\n",
      "penalty: 0.020031766688203168\n",
      "h_val:  tensor(4.1679e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.3101051018236545\n",
      "loss: 37.57885285126827\n",
      "penalty: 0.021430633300413893\n",
      "h_val:  tensor(4.3093e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.309048909489632\n",
      "loss: 37.57882827373327\n",
      "penalty: 0.02246244158734604\n",
      "h_new:  4.309301381510977e-06\n",
      "layer: 0 shape: torch.Size([20, 2])\n",
      "layer: 1 shape: torch.Size([20])\n",
      "layer: 2 shape: torch.Size([20, 2])\n",
      "layer: 3 shape: torch.Size([20])\n",
      "layer: 4 shape: torch.Size([2, 10, 1])\n",
      "layer: 5 shape: torch.Size([2, 1])\n",
      "rho:  1000000000.0\n",
      "h_val:  tensor(4.3093e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.309048909489632\n",
      "loss: 37.597398352129964\n",
      "penalty: 0.04103251998403845\n",
      "h_val:  tensor(998.0751, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.407834770081834\n",
      "loss: 498076926114718.9\n",
      "penalty: 498076926114651.2\n",
      "h_val:  tensor(6.3418, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.69140908116994\n",
      "loss: 20109140331.223343\n",
      "penalty: 20109140264.278866\n",
      "h_val:  tensor(0.2482, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.44723842841911\n",
      "loss: 30806892.24055818\n",
      "penalty: 30806830.54473757\n",
      "h_val:  tensor(0.0071, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.670134743937224\n",
      "loss: 25402.59867260831\n",
      "penalty: 25359.681004003698\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.872535944778384\n",
      "loss: 53.592843503695065\n",
      "penalty: 15.472952937987738\n",
      "h_val:  tensor(7.7508e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.402565357452042\n",
      "loss: 37.65590019813887\n",
      "penalty: 0.006010563419238142\n",
      "h_val:  tensor(2.2314e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.326978372151973\n",
      "loss: 37.59322566655033\n",
      "penalty: 0.018928910466827046\n",
      "h_val:  tensor(2.4399e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.324841606688575\n",
      "loss: 37.59311107009462\n",
      "penalty: 0.020951314150823474\n",
      "h_val:  tensor(2.4804e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.324436805234007\n",
      "loss: 37.59310456174275\n",
      "penalty: 0.02134972726842997\n",
      "h_new:  2.4803933804662393e-06\n",
      "rho:  10000000000.0\n",
      "h_val:  tensor(2.4804e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.324436805234007\n",
      "loss: 37.62079014269112\n",
      "penalty: 0.04903530821680329\n",
      "h_val:  tensor(952.3927, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.37536057869928\n",
      "loss: 4535259211238370.0\n",
      "penalty: 4535259211238303.0\n",
      "h_val:  tensor(6.2190, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.54683570072364\n",
      "loss: 193380198182.45517\n",
      "penalty: 193380198115.65457\n",
      "h_val:  tensor(0.2437, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.17746447671314\n",
      "loss: 296926207.289807\n",
      "penalty: 296926145.8635978\n",
      "h_val:  tensor(0.0070, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.642456503474396\n",
      "loss: 246490.05515234373\n",
      "penalty: 246447.16513320996\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.882673256693436\n",
      "loss: 190.12445459894266\n",
      "penalty: 151.9944211427756\n",
      "h_val:  tensor(1.8433e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.419303471587159\n",
      "loss: 37.69719809856159\n",
      "penalty: 0.03056821957086843\n",
      "h_val:  tensor(3.6052e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.355075852440562\n",
      "loss: 37.605702524679444\n",
      "penalty: 0.003305857058193136\n",
      "h_val:  tensor(6.4829e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.348557242314017\n",
      "loss: 37.60275495528588\n",
      "penalty: 0.006877505931958516\n",
      "h_val:  tensor(1.0239e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.342021635666246\n",
      "loss: 37.60212577766194\n",
      "penalty: 0.012784593061161621\n",
      "h_val:  tensor(9.0042e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.344006901363103\n",
      "loss: 37.602013902445094\n",
      "penalty: 0.010687282734598475\n",
      "h_val:  tensor(9.1326e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.343793829366639\n",
      "loss: 37.60201183960857\n",
      "penalty: 0.010898337631153589\n",
      "h_new:  9.132569904757304e-07\n",
      "layer: 0 shape: torch.Size([20, 2])\n",
      "layer: 1 shape: torch.Size([20])\n",
      "layer: 2 shape: torch.Size([20, 2])\n",
      "layer: 3 shape: torch.Size([20])\n",
      "layer: 4 shape: torch.Size([2, 10, 1])\n",
      "layer: 5 shape: torch.Size([2, 1])\n",
      "rho:  10000000000.0\n",
      "h_val:  tensor(9.1326e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.343793829366639\n",
      "loss: 37.6103522229151\n",
      "penalty: 0.019238720937681468\n",
      "h_val:  tensor(1010.0042, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.408919667724184\n",
      "loss: 5100541955610873.0\n",
      "penalty: 5100541955610806.0\n",
      "h_val:  tensor(6.3800, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.72623798302798\n",
      "loss: 203524371784.21005\n",
      "penalty: 203524371717.23074\n",
      "h_val:  tensor(0.2504, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.547693021045866\n",
      "loss: 313549840.85557246\n",
      "penalty: 313549779.0592894\n",
      "h_val:  tensor(0.0073, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.753588032685153\n",
      "loss: 265171.66430340766\n",
      "penalty: 265128.66317868955\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.905948218141866\n",
      "loss: 219.85717513926542\n",
      "penalty: 181.70387037595017\n",
      "h_val:  tensor(3.0910e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.432450918089988\n",
      "loss: 37.778547202526\n",
      "penalty: 0.09876982051244554\n",
      "h_val:  tensor(2.6496e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.357841081884259\n",
      "loss: 37.60988474080737\n",
      "penalty: 0.004722874024675699\n",
      "h_val:  tensor(4.8580e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.351989016010318\n",
      "loss: 37.60850485230532\n",
      "penalty: 0.009195545399206072\n",
      "h_val:  tensor(5.3793e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.35082820379956\n",
      "loss: 37.60847100318172\n",
      "penalty: 0.010322643538741901\n",
      "h_new:  5.379336305288973e-07\n",
      "rho:  100000000000.0\n",
      "h_val:  tensor(5.3793e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.35082820379956\n",
      "loss: 37.62149276977015\n",
      "penalty: 0.02334441012717191\n",
      "h_val:  tensor(953.3642, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.375863386038226\n",
      "loss: 4.544516408325932e+16\n",
      "penalty: 4.544516408325925e+16\n",
      "h_val:  tensor(6.2261, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.55743079045181\n",
      "loss: 1938229076091.4612\n",
      "penalty: 1938229076024.65\n",
      "h_val:  tensor(0.2445, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.205250801324024\n",
      "loss: 2988805725.535919\n",
      "penalty: 2988805664.0819182\n",
      "h_val:  tensor(0.0071, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.693908409275961\n",
      "loss: 2532939.664144919\n",
      "penalty: 2532896.722671864\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.906339975594498\n",
      "loss: 1804.4879324708515\n",
      "penalty: 1766.334230958303\n",
      "h_val:  tensor(3.6216e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.437865792276298\n",
      "loss: 38.400754625146725\n",
      "penalty: 0.7155611238050731\n",
      "h_val:  tensor(1.3870e-09, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.373269912498982\n",
      "loss: 37.62061505307338\n",
      "penalty: 2.298151316245963e-05\n",
      "h_val:  tensor(6.1341e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.366376475137858\n",
      "loss: 37.614898251631566\n",
      "penalty: 0.0012002421328639193\n",
      "h_val:  tensor(4.6833e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.352389579048973\n",
      "loss: 37.618403651491676\n",
      "penalty: 0.018693859626505258\n",
      "h_val:  tensor(1.8073e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.3606676401853885\n",
      "loss: 37.612603974030556\n",
      "penalty: 0.004615336810947499\n",
      "h_val:  tensor(2.0338e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.359839055585037\n",
      "loss: 37.612583714211695\n",
      "penalty: 0.005423759236523336\n",
      "h_new:  2.033763357722762e-07\n",
      "layer: 0 shape: torch.Size([20, 2])\n",
      "layer: 1 shape: torch.Size([20])\n",
      "layer: 2 shape: torch.Size([20, 2])\n",
      "layer: 3 shape: torch.Size([20])\n",
      "layer: 4 shape: torch.Size([2, 10, 1])\n",
      "layer: 5 shape: torch.Size([2, 1])\n",
      "rho:  100000000000.0\n",
      "h_val:  tensor(2.0338e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.359839055585037\n",
      "loss: 37.61671990760691\n",
      "penalty: 0.0095599526317391\n",
      "h_val:  tensor(1003.9675, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.4007819281167\n",
      "loss: 5.0397538757794136e+16\n",
      "penalty: 5.039753875779406e+16\n",
      "h_val:  tensor(6.3665, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.71520829551878\n",
      "loss: 2026599533622.071\n",
      "penalty: 2026599533555.1025\n",
      "h_val:  tensor(0.2502, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.52656350013845\n",
      "loss: 3130015813.0772953\n",
      "penalty: 3130015751.302114\n",
      "h_val:  tensor(0.0073, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.776991831148823\n",
      "loss: 2677825.955275639\n",
      "penalty: 2677782.9307417017\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.919793125216273\n",
      "loss: 1990.1097267598993\n",
      "penalty: 1951.942575553712\n",
      "h_val:  tensor(4.4221e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.44444782581793\n",
      "loss: 38.8324298554738\n",
      "penalty: 1.1406545855524375\n",
      "h_val:  tensor(4.1626e-09, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.376078017205073\n",
      "loss: 37.62355441452889\n",
      "penalty: 0.00015420421300565943\n",
      "h_val:  tensor(1.0665e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.36383609220182\n",
      "loss: 37.615654656828454\n",
      "penalty: 0.004497345017846724\n",
      "h_val:  tensor(1.1123e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.363609120968924\n",
      "loss: 37.61564642113313\n",
      "penalty: 0.004716111724523167\n",
      "h_new:  1.112317056239931e-07\n",
      "rho:  1000000000000.0\n",
      "h_val:  tensor(1.1123e-07, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.363609120968924\n",
      "loss: 37.621214042684336\n",
      "penalty: 0.010283733275733363\n",
      "h_val:  tensor(952.7410, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.36772480594059\n",
      "loss: 4.538577151772803e+17\n",
      "penalty: 4.5385771517728026e+17\n",
      "h_val:  tensor(6.2264, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.489809546697444\n",
      "loss: 19384035531883.094\n",
      "penalty: 19384035531816.35\n",
      "h_val:  tensor(0.2447, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.128360408719097\n",
      "loss: 29951280951.292004\n",
      "penalty: 29951280889.91491\n",
      "h_val:  tensor(0.0072, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.715571874108011\n",
      "loss: 25632729.525442023\n",
      "penalty: 25632686.56230816\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.917536733834098\n",
      "loss: 18969.631157398515\n",
      "penalty: 18931.46625908962\n",
      "h_val:  tensor(4.6427e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.446543616036906\n",
      "loss: 48.64244625760625\n",
      "penalty: 10.9485744199282\n",
      "h_val:  tensor(3.2593e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.38025693651198\n",
      "loss: 37.629311355363306\n",
      "penalty: 0.0017317778565533036\n",
      "h_val:  tensor(2.8141e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.368952853468028\n",
      "loss: 37.61770708970782\n",
      "penalty: 0.0014325791546664734\n",
      "h_val:  tensor(3.6230e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.3682219069839805\n",
      "loss: 37.617534446302535\n",
      "penalty: 0.001990950518816796\n",
      "h_val:  tensor(4.2912e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.367678486682676\n",
      "loss: 37.617501464074756\n",
      "penalty: 0.0025014469060780056\n",
      "h_new:  4.291150368374019e-08\n",
      "layer: 0 shape: torch.Size([20, 2])\n",
      "layer: 1 shape: torch.Size([20])\n",
      "layer: 2 shape: torch.Size([20, 2])\n",
      "layer: 3 shape: torch.Size([20])\n",
      "layer: 4 shape: torch.Size([2, 10, 1])\n",
      "layer: 5 shape: torch.Size([2, 1])\n",
      "rho:  1000000000000.0\n",
      "h_val:  tensor(4.2912e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.367678486682676\n",
      "loss: 37.61934286122315\n",
      "penalty: 0.004342844054477654\n",
      "h_val:  tensor(1002.9334, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.401489309519455\n",
      "loss: 5.029377114144485e+17\n",
      "penalty: 5.0293771141444845e+17\n",
      "h_val:  tensor(6.3648, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.70532412821547\n",
      "loss: 20255424493397.746\n",
      "penalty: 20255424493330.79\n",
      "h_val:  tensor(0.2503, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.510594989989908\n",
      "loss: 31321852286.50592\n",
      "penalty: 31321852224.746727\n",
      "h_val:  tensor(0.0073, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.792178606504203\n",
      "loss: 26952488.97070473\n",
      "penalty: 26952445.930986874\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.9267776370664045\n",
      "loss: 20327.593379668248\n",
      "penalty: 20289.419244105695\n",
      "h_val:  tensor(5.1031e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.44991143804056\n",
      "loss: 51.12506816797668\n",
      "penalty: 13.427828969656982\n",
      "h_val:  tensor(6.6229e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.382699388832836\n",
      "loss: 37.63749696171519\n",
      "penalty: 0.007474871376513717\n",
      "h_val:  tensor(1.6224e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.370260811211055\n",
      "loss: 37.619008014608546\n",
      "penalty: 0.0014254704642189915\n",
      "h_val:  tensor(2.2876e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.3694841234469095\n",
      "loss: 37.6188918319519\n",
      "penalty: 0.002086042912271451\n",
      "h_val:  tensor(2.4315e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.369332333916109\n",
      "loss: 37.61888866245622\n",
      "penalty: 0.0022346835402696236\n",
      "h_new:  2.431480083942006e-08\n",
      "rho:  10000000000000.0\n",
      "h_val:  tensor(2.4315e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.369332333916109\n",
      "loss: 37.62154910538559\n",
      "penalty: 0.004895126469642604\n",
      "h_val:  tensor(954.5642, grad_fn=<SubBackward0>)\n",
      "squared loss: 36.375113998087535\n",
      "loss: 4.555963774757682e+18\n",
      "penalty: 4.555963774757682e+18\n",
      "h_val:  tensor(6.2325, grad_fn=<SubBackward0>)\n",
      "squared loss: 35.55601377134448\n",
      "loss: 194219072222585.4\n",
      "penalty: 194219072222518.6\n",
      "h_val:  tensor(0.2451, grad_fn=<SubBackward0>)\n",
      "squared loss: 30.2135355996444\n",
      "loss: 300370708674.77216\n",
      "penalty: 300370708613.3099\n",
      "h_val:  tensor(0.0072, grad_fn=<SubBackward0>)\n",
      "squared loss: 11.729811496546963\n",
      "loss: 258206611.93828267\n",
      "penalty: 258206568.96090612\n",
      "h_val:  tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.922647887413323\n",
      "loss: 195626.22948382463\n",
      "penalty: 195588.05947363333\n",
      "h_val:  tensor(5.1313e-06, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.450348529961623\n",
      "loss: 169.7581997226055\n",
      "penalty: 132.06052262751297\n",
      "h_val:  tensor(8.7530e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.384026269196943\n",
      "loss: 37.676637195687384\n",
      "penalty: 0.045287990429688\n",
      "h_val:  tensor(4.7939e-10, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.373678894123323\n",
      "loss: 37.621040302921315\n",
      "penalty: 3.938011551031144e-05\n",
      "h_val:  tensor(3.7816e-09, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.372389296818734\n",
      "loss: 37.62008429499655\n",
      "penalty: 0.00037308595926194976\n",
      "h_val:  tensor(1.6252e-08, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.370252199093144\n",
      "loss: 37.62019063033533\n",
      "penalty: 0.002616719693794338\n",
      "h_val:  tensor(8.7294e-09, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.37135408277507\n",
      "loss: 37.61975306907426\n",
      "penalty: 0.0010771712370523916\n",
      "h_val:  tensor(9.1506e-09, grad_fn=<SubBackward0>)\n",
      "squared loss: 6.371281904516381\n",
      "loss: 37.61975213462023\n",
      "penalty: 0.0011484256234071495\n",
      "h_new:  9.150646018696307e-09\n",
      "[[0.00000000e+00 6.84336512e+00]\n",
      " [1.39783582e-05 0.00000000e+00]]\n",
      "[[0. 1.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "x = np.random.normal(10,2, 100)\n",
    "\n",
    "np.random.seed(24)\n",
    "l = np.random.normal(0,1, 100) \n",
    "\n",
    "# marker\n",
    "np.random.seed(25)\n",
    "b = np.random.normal(0,1, 100) \n",
    "\n",
    "\n",
    "y = [x**2 + l for x, l in zip(x, l)]\n",
    "\n",
    "X = np.column_stack((x, y))\n",
    "#X_torch = torch.from_numpy(X)\n",
    "\n",
    "n = X.shape[0]\n",
    "d = X.shape[1]\n",
    "\n",
    "print(n)\n",
    "print(d)\n",
    "\n",
    "model = NotearsMLP(dims=[d, 10, 1], bias=True)\n",
    "W_est, output = notears_nonlinear(model, X, lambda1=0.01, lambda2=0.01)\n",
    "print(W_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c364893210>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_hat = output[:, 1].detach().numpy()\n",
    "plt.figure(figsize=(10, 6))  # Optional: specifies the figure size\n",
    "plt.scatter(x, y, label='y1', color='blue', marker='o')  # Plot x vs. y1\n",
    "plt.scatter(x, y_hat, label='y2', color='red', marker='s') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_hat = output[:, 0].detach().numpy()\n",
    "\n",
    "plt.scatter(x, x_hat, color='red', marker='s')  # Plot x vs. y_hat\n",
    "\n",
    "plt.legend()  # Show legend to differentiate between actual and predicted values\n",
    "plt.title('Actual vs Predicted Values')  # Optional: Adds a title to the plot\n",
    "plt.xlabel('x-axis label')  # Optional: Label for the x-axis\n",
    "plt.ylabel('x_hat-axis label')  # Optional: Label for the y-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NOTEARS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
