{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from notears.locally_connected import LocallyConnected\n",
    "from lbfgsb_scipy import LBFGSBScipy\n",
    "from trace_expm import trace_expm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from locally_connected import LocallyConnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotearsMLP(nn.Module):\n",
    "    def __init__(self, dims, bias=True):\n",
    "        super(NotearsMLP, self).__init__()\n",
    "        assert len(dims) >= 2\n",
    "        assert dims[-1] == 1 # output dim of last layer must be 1\n",
    "        d = dims[0]\n",
    "        self.dims = dims\n",
    "        # fc1: variable splitting for l1\n",
    "        self.fc1_pos = nn.Linear(d, d * dims[1], bias=bias)\n",
    "        self.fc1_neg = nn.Linear(d, d * dims[1], bias=bias)\n",
    "        \n",
    "        self.fc1_pos.weight.bounds = self._bounds()\n",
    "        self.fc1_neg.weight.bounds = self._bounds()\n",
    "        # fc2: local linear layers\n",
    "        layers = []\n",
    "        for l in range(len(dims) - 2):\n",
    "            layers.append(LocallyConnected(d, dims[l + 1], dims[l + 2], bias=bias))\n",
    "        self.fc2 = nn.ModuleList(layers)\n",
    "\n",
    "    def _bounds(self):\n",
    "        d = self.dims[0]\n",
    "        bounds = []\n",
    "        for j in range(d):\n",
    "            for m in range(self.dims[1]):\n",
    "                for i in range(d):\n",
    "                    if i == j:\n",
    "                        bound = (0, 0) # self loop not allowed\n",
    "                    else:\n",
    "                        bound = (0, None)\n",
    "                    bounds.append(bound)\n",
    "        return bounds\n",
    "\n",
    "    def forward(self, x):  # [n, d] -> [n, d]\n",
    "        x = self.fc1_pos(x) - self.fc1_neg(x)  # [n, d * m1] pass linear layer through input x\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, self.dims[0], self.dims[1])  # [n, d, m1]\n",
    "        for fc in self.fc2:\n",
    "            x = torch.sigmoid(x)  # [n, d, m1]\n",
    "            x = fc(x)  # [n, d, m2]\n",
    "            #print(x.shape)\n",
    "        x = x.squeeze(dim=2)  # [n, d]\n",
    "        return x\n",
    "\n",
    "    def h_func(self):\n",
    "        \"\"\"Constrain 2-norm-squared of fc1 weights along m1 dim to be a DAG\"\"\"\n",
    "        d = self.dims[0]\n",
    "        fc1_weight = self.fc1_pos.weight - self.fc1_neg.weight  # [j * m1, i]\n",
    "        fc1_weight = fc1_weight.view(d, -1, d)  # [j, m1, i]\n",
    "        A = torch.sum(fc1_weight * fc1_weight, dim=1).t()  # [i, j]\n",
    "        h = trace_expm(A) - d  # (Zheng et al. 2018)\n",
    "        # A different formulation, slightly faster at the cost of numerical stability\n",
    "        # M = torch.eye(d) + A / d  # (Yu et al. 2019)\n",
    "        # E = torch.matrix_power(M, d - 1)\n",
    "        # h = (E.t() * M).sum() - d\n",
    "        return h\n",
    "\n",
    "    def l2_reg(self):\n",
    "        \"\"\"Take 2-norm-squared of all parameters\"\"\"\n",
    "        reg = 0.\n",
    "        fc1_weight = self.fc1_pos.weight - self.fc1_neg.weight  # [j * m1, i]\n",
    "        reg += torch.sum(fc1_weight ** 2)\n",
    "        for fc in self.fc2:\n",
    "            reg += torch.sum(fc.weight ** 2)\n",
    "        return reg\n",
    "\n",
    "    def fc1_l1_reg(self):\n",
    "        \"\"\"Take l1 norm of fc1 weight\"\"\"\n",
    "        reg = torch.sum(self.fc1_pos.weight + self.fc1_neg.weight)\n",
    "        return reg\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def fc1_to_adj(self) -> np.ndarray:  # [j * m1, i] -> [i, j]\n",
    "        \"\"\"Get W from fc1 weights, take 2-norm over m1 dim\"\"\"\n",
    "        d = self.dims[0]\n",
    "        fc1_weight = self.fc1_pos.weight - self.fc1_neg.weight  # [j * m1, i]\n",
    "        fc1_weight = fc1_weight.view(d, -1, d)  # [j, m1, i]\n",
    "        A = torch.sum(fc1_weight * fc1_weight, dim=1).t()  # [i, j]\n",
    "        W = torch.sqrt(A)  # [i, j]\n",
    "        W = W.cpu().detach().numpy()  # [i, j]\n",
    "        return W\n",
    "\n",
    "\n",
    "def squared_loss(output, target):\n",
    "    n = target.shape[0]\n",
    "    loss = 0.5 / n * torch.sum((output - target) ** 2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def dual_ascent_step(model, X, lambda1, lambda2, rho, alpha, h, rho_max):\n",
    "    \"\"\"Perform one step of dual ascent in augmented Lagrangian.\"\"\"\n",
    "    h_new = None\n",
    "    optimizer = LBFGSBScipy(model.parameters())\n",
    "    for idx, param in enumerate(model.parameters()):\n",
    "        print('layer:',idx,'shape:',param.shape)\n",
    "    #print(model.parameters().shape)\n",
    "    #print(\"model.parameters(): \", model.parameters().data())\n",
    "    X_torch = torch.from_numpy(X)\n",
    "    while rho < rho_max:\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            X_hat = model(X_torch)\n",
    "            loss = squared_loss(X_hat, X_torch)\n",
    "            h_val = model.h_func()\n",
    "            penalty = 0.5 * rho * h_val * h_val + alpha * h_val\n",
    "            l2_reg = 0.5 * lambda2 * model.l2_reg()\n",
    "            l1_reg = lambda1 * model.fc1_l1_reg()\n",
    "            primal_obj = loss + penalty + l2_reg + l1_reg\n",
    "            primal_obj.backward()\n",
    "            return primal_obj\n",
    "        optimizer.step(closure)  # NOTE: updates model in-place\n",
    "        with torch.no_grad():\n",
    "            h_new = model.h_func().item()\n",
    "        if h_new > 0.25 * h:\n",
    "            rho *= 10\n",
    "        else:\n",
    "            break\n",
    "    alpha += rho * h_new\n",
    "    return rho, alpha, h_new\n",
    "\n",
    "\n",
    "def notears_nonlinear(model: nn.Module,\n",
    "                      X: np.ndarray,\n",
    "                      lambda1: float = 0.,\n",
    "                      lambda2: float = 0.,\n",
    "                      max_iter: int = 100,\n",
    "                      h_tol: float = 1e-8,\n",
    "                      rho_max: float = 1e+16,\n",
    "                      w_threshold: float = 0.3):\n",
    "    rho, alpha, h = 1.0, 0.0, np.inf\n",
    "    for _ in range(max_iter):\n",
    "        rho, alpha, h = dual_ascent_step(model, X, lambda1, lambda2,\n",
    "                                         rho, alpha, h, rho_max)\n",
    "        if h <= h_tol or rho >= rho_max:\n",
    "            break\n",
    "    W_est = model.fc1_to_adj()\n",
    "    print(W_est)\n",
    "    W_est[np.abs(W_est) < w_threshold] = 0\n",
    "    W_est[np.abs(W_est) >= w_threshold] = 1\n",
    "    return W_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_true:  [[0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "X.dtype:  float64\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "layer: 0 shape: torch.Size([40, 4])\n",
      "layer: 1 shape: torch.Size([40])\n",
      "layer: 2 shape: torch.Size([40, 4])\n",
      "layer: 3 shape: torch.Size([40])\n",
      "layer: 4 shape: torch.Size([4, 10, 1])\n",
      "layer: 5 shape: torch.Size([4, 1])\n",
      "[[0.000e+00 2.911e+00 0.000e+00 0.000e+00]\n",
      " [1.657e-05 0.000e+00 0.000e+00 0.000e+00]\n",
      " [3.007e+00 1.860e-01 0.000e+00 0.000e+00]\n",
      " [2.108e-01 2.370e+00 0.000e+00 0.000e+00]]\n",
      "W_est [[0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "import utils as ut\n",
    "ut.set_random_seed(123)\n",
    "\n",
    "n, d, s0, graph_type, sem_type = 100, 4, 3, 'ER', 'mim'\n",
    "B_true = ut.simulate_dag(d, s0, graph_type)\n",
    "#np.savetxt('W_true.csv', B_true, delimiter=',')\n",
    "print(\"W_true: \", B_true)\n",
    "\n",
    "X = ut.simulate_nonlinear_sem(B_true, n, sem_type)\n",
    "#np.savetxt('X.csv', X, delimiter=',')\n",
    "print(\"X.dtype: \", X.dtype)\n",
    "\n",
    "model = NotearsMLP(dims=[d, 10, 1], bias=True)\n",
    "W_est = notears_nonlinear(model, X, lambda1=0.01, lambda2=0.01)\n",
    "#np.savetxt('W_est.csv', W_est, delimiter=',')\n",
    "print(\"W_est\", W_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "3\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "model.parameters():  <generator object Module.parameters at 0x00000183D91CB3E0>\n",
      "[[0.000e+00 3.445e+00 1.147e+00]\n",
      " [1.803e-05 0.000e+00 4.444e-02]\n",
      " [5.936e-05 4.221e-04 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "x = np.random.normal(10,2, 100)\n",
    "\n",
    "np.random.seed(24)\n",
    "l = np.random.normal(0,1, 100) \n",
    "\n",
    "\n",
    "np.random.seed(25)\n",
    "b = np.random.normal(0,1, 100) \n",
    "\n",
    "\n",
    "y = [8*x + l for x, l in zip(x, l)]\n",
    "z = [3*x + b for x, b in zip(x, b)]\n",
    "\n",
    "X = np.column_stack((x, y, z))\n",
    "n = X.shape[0]\n",
    "d = X.shape[1]\n",
    "\n",
    "print(n)\n",
    "print(d)\n",
    "\n",
    "model = NotearsMLP(dims=[d, 10, 1], bias=True)\n",
    "W_est = notears_nonlinear(model, X, lambda1=0.01, lambda2=0.01)\n",
    "# worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NOTEARS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
