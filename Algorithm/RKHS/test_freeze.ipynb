{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from lbfgsb_scipy import LBFGSBScipy\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define the three layers\n",
    "        torch.manual_seed(42)\n",
    "        # self.layer1 = nn.Linear(10, 5, bias = False)  # Example sizes, adjust as needed\n",
    "        # self.layer2 = nn.Linear(5, 3, bias = False)   # Example sizes, adjust as needed\n",
    "        # self.layer3 = nn.Linear(3, 1, bias = False)   # Example sizes, adjust as needed\n",
    "        self.layer1 = nn.Linear(10, 10)\n",
    "        self.layer2 = nn.Linear(5, 1)\n",
    "        self.weight = torch.einsum('ij, m -> ijm') #[10, 10, 5]\n",
    "        # Freeze the first layer by setting requires_grad to False for its parameters\n",
    "        for param in self.layer1.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.relu(self.layer1(x))\n",
    "        # x = torch.relu(self.layer2(x))\n",
    "        # x = self.layer3(x)\n",
    "        x = torch.einsum('i, ijm -> m')\n",
    "        return x\n",
    "    \n",
    "    def get_parameter(self) -> nn.Parameter:\n",
    "        return self.layer1.weight, self.layer2.weight, self.layer3.weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "einsum(): must specify the equation string and at least one operand, or at least one operand and its subscripts list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrand([\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m      3\u001b[0m mse_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMyModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer1: \u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mget_parameter()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer2: \u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mget_parameter()[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[45], line 16\u001b[0m, in \u001b[0;36mMyModel.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mij, m -> ijm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#[10, 10, 5]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Freeze the first layer by setting requires_grad to False for its parameters\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[1;32mc:\\Users\\yurou\\anaconda3\\envs\\RKHS\\Lib\\site-packages\\torch\\functional.py:331\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# This wrapper exists to support variadic args.\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meinsum(): must specify the equation string and at least one operand, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    332\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mor at least one operand and its subscripts list\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    334\u001b[0m equation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    335\u001b[0m operands \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: einsum(): must specify the equation string and at least one operand, or at least one operand and its subscripts list"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x = torch.randn([100, 10])\n",
    "target = 10*torch.rand([100, 5])\n",
    "mse_loss = nn.MSELoss()\n",
    "model = MyModel()\n",
    "print(\"layer1: \", model.get_parameter()[0])\n",
    "print(\"layer2: \", model.get_parameter()[1])\n",
    "print(\"layer3: \", model.get_parameter()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n",
      "squared loss: 37.2646598815918\n",
      "torch.Size([100, 1])\n",
      "squared loss: 33.05524444580078\n",
      "torch.Size([100, 1])\n",
      "squared loss: 32.082916259765625\n",
      "torch.Size([100, 1])\n",
      "squared loss: 27.392253875732422\n",
      "torch.Size([100, 1])\n",
      "squared loss: 21.160593032836914\n",
      "torch.Size([100, 1])\n",
      "squared loss: 21.274452209472656\n",
      "torch.Size([100, 1])\n",
      "squared loss: 20.836620330810547\n",
      "torch.Size([100, 1])\n",
      "squared loss: 22.703763961791992\n",
      "torch.Size([100, 1])\n",
      "squared loss: 20.285890579223633\n",
      "torch.Size([100, 1])\n",
      "squared loss: 20.261014938354492\n",
      "torch.Size([100, 1])\n",
      "squared loss: 20.150175094604492\n",
      "torch.Size([100, 1])\n",
      "squared loss: 20.06949806213379\n",
      "torch.Size([100, 1])\n",
      "squared loss: 20.00341796875\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.892196655273438\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.76331901550293\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.645845413208008\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.547870635986328\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.410829544067383\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.37413787841797\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.307716369628906\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.352027893066406\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.274682998657227\n",
      "torch.Size([100, 1])\n",
      "squared loss: 28.13229751586914\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.26498794555664\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.22518539428711\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.148836135864258\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.136396408081055\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.023561477661133\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.419754028320312\n",
      "torch.Size([100, 1])\n",
      "squared loss: 18.971372604370117\n",
      "torch.Size([100, 1])\n",
      "squared loss: 288.3661804199219\n",
      "torch.Size([100, 1])\n",
      "squared loss: 19.1885929107666\n",
      "torch.Size([100, 1])\n",
      "squared loss: 18.953670501708984\n",
      "torch.Size([100, 1])\n",
      "squared loss: 18.847780227661133\n",
      "torch.Size([100, 1])\n",
      "squared loss: 18.65093421936035\n",
      "torch.Size([100, 1])\n",
      "squared loss: 18.05388641357422\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.964078903198242\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.792821884155273\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.651535034179688\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.989343643188477\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.605873107910156\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.571029663085938\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.521411895751953\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.496583938598633\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.512779235839844\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.473220825195312\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.4373836517334\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.41327667236328\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.27080535888672\n",
      "torch.Size([100, 1])\n",
      "squared loss: 17.009658813476562\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.913772583007812\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.848752975463867\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.825973510742188\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.8016414642334\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.748876571655273\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.953882217407227\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.712383270263672\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.691913604736328\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.606456756591797\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.56894302368164\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.568397521972656\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.556745529174805\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.54733657836914\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.54201889038086\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.538623809814453\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.535629272460938\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.53333282470703\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.532581329345703\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.53089141845703\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.53049087524414\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.529319763183594\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.5280818939209\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.517744064331055\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.49837303161621\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.584720611572266\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.491270065307617\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.48147201538086\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.467605590820312\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.466354370117188\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.46538734436035\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.46475601196289\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.464420318603516\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.463136672973633\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.461782455444336\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.464441299438477\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.45154571533203\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.4677734375\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.45100975036621\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.460102081298828\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.446025848388672\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.44109344482422\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.434741973876953\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.43112564086914\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.430988311767578\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.429594039916992\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.4287052154541\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.686004638671875\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.428556442260742\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.42647361755371\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.424528121948242\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.423786163330078\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.42363929748535\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.42355728149414\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.42346954345703\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.42321014404297\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.422941207885742\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.422880172729492\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.422758102416992\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.42268943786621\n",
      "torch.Size([100, 1])\n",
      "squared loss: 16.42267417907715\n"
     ]
    }
   ],
   "source": [
    "optimizer = LBFGSBScipy(model.parameters())\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    output = model.forward(x)\n",
    "    print(output.shape)\n",
    "    loss = mse_loss(target, output)\n",
    "    primal_obj = loss \n",
    "    primal_obj.backward()\n",
    "    print('squared loss:', loss.item())\n",
    "    return primal_obj\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1:  Parameter containing:\n",
      "tensor([[ 0.2418,  0.2625, -0.0741,  0.2905, -0.0693,  0.0638, -0.1540,  0.1857,\n",
      "          0.2788, -0.2320],\n",
      "        [ 0.2749,  0.0592,  0.2336,  0.0428,  0.1525, -0.0446,  0.2438,  0.0467,\n",
      "         -0.1476,  0.0806],\n",
      "        [-0.1457, -0.0371, -0.1284,  0.2098, -0.2496, -0.1458, -0.0893, -0.1901,\n",
      "          0.0298, -0.3123],\n",
      "        [ 0.2856, -0.2686,  0.2441,  0.0526, -0.1027,  0.1954,  0.0493,  0.2555,\n",
      "          0.0346, -0.0997],\n",
      "        [ 0.0850, -0.0858,  0.1331,  0.2823,  0.1828, -0.1382,  0.1825,  0.0566,\n",
      "          0.1606, -0.1927]])\n",
      "layer2:  Parameter containing:\n",
      "tensor([[ -2.0491,   9.5738,   4.4370,   4.0391, -13.2500],\n",
      "        [ 13.6810, -16.6725,  -6.6664,  -2.1218,  31.8371],\n",
      "        [ -2.1259,  -0.3690,  -1.9344,  -0.4148,  -0.8183]],\n",
      "       requires_grad=True)\n",
      "layer3:  Parameter containing:\n",
      "tensor([[1.7254, 0.2419, 0.8785]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"layer1: \", model.get_parameter()[0])\n",
    "print(\"layer2: \", model.get_parameter()[1])\n",
    "print(\"layer3: \", model.get_parameter()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2418,  0.2625, -0.0741,  0.2905, -0.0693,  0.0638, -0.1540,  0.1857,\n",
      "          0.2788, -0.2320],\n",
      "        [ 0.2749,  0.0592,  0.2336,  0.0428,  0.1525, -0.0446,  0.2438,  0.0467,\n",
      "         -0.1476,  0.0806],\n",
      "        [-0.1457, -0.0371, -0.1284,  0.2098, -0.2496, -0.1458, -0.0893, -0.1901,\n",
      "          0.0298, -0.3123],\n",
      "        [ 0.2856, -0.2686,  0.2441,  0.0526, -0.1027,  0.1954,  0.0493,  0.2555,\n",
      "          0.0346, -0.0997],\n",
      "        [ 0.0850, -0.0858,  0.1331,  0.2823,  0.1828, -0.1382,  0.1825,  0.0566,\n",
      "          0.1606, -0.1927]])\n"
     ]
    }
   ],
   "source": [
    "for par in model.layer1.parameters():\n",
    "    print(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2625)\n"
     ]
    }
   ],
   "source": [
    "for par in model.layer1.parameters():\n",
    "    print(par[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RKHS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
